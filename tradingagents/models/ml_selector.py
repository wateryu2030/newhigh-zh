#!/usr/bin/env python3
"""
æœºå™¨å­¦ä¹ é€‰è‚¡å™¨
åŸºäºRandomForestç­‰æ¨¡å‹è¿›è¡Œæ™ºèƒ½é€‰è‚¡
"""

import pandas as pd
import numpy as np
from typing import Optional, List, Dict, Any
from pathlib import Path
import pickle
import joblib

try:
    from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

from tradingagents.utils.logging_init import get_logger
from tradingagents.models.ml_features import extract_features, select_features, normalize_features

logger = get_logger('models.ml_selector')


class SmartSelector:
    """
    æ™ºèƒ½é€‰è‚¡å™¨ï¼ˆåŸºäºæœºå™¨å­¦ä¹ ï¼‰
    """
    
    def __init__(
        self,
        model_type: str = "classifier",
        n_estimators: int = 100,
        max_depth: int = 10,
        model_path: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–æ™ºèƒ½é€‰è‚¡å™¨
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ï¼ˆclassifier/regressorï¼‰
            n_estimators: æ ‘çš„æ•°é‡
            max_depth: æ ‘çš„æœ€å¤§æ·±åº¦
            model_path: ä¿å­˜/åŠ è½½æ¨¡å‹çš„è·¯å¾„
        """
        if not SKLEARN_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£… scikit-learn: pip install scikit-learn")
        
        self.model_type = model_type
        self.model_path = Path(model_path) if model_path else None
        
        if model_type == "classifier":
            self.model = RandomForestClassifier(
                n_estimators=n_estimators,
                max_depth=max_depth,
                random_state=42,
                n_jobs=-1
            )
        else:
            self.model = RandomForestRegressor(
                n_estimators=n_estimators,
                max_depth=max_depth,
                random_state=42,
                n_jobs=-1
            )
        
        self.feature_cols = None
        self.is_trained = False
        
        # å°è¯•åŠ è½½å·²æœ‰æ¨¡å‹
        if self.model_path and self.model_path.exists():
            self.load_model(self.model_path)
        
        logger.info(f"âœ… SmartSelectoråˆå§‹åŒ–å®Œæˆ (model_type={model_type})")
    
    def train(
        self,
        features: pd.DataFrame,
        labels: pd.Series,
        test_size: float = 0.2,
        normalize: bool = True
    ) -> Dict[str, float]:
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            features: ç‰¹å¾DataFrame
            labels: æ ‡ç­¾Seriesï¼ˆåˆ†ç±»ï¼š0/1ï¼Œå›å½’ï¼šæ”¶ç›Šç‡ï¼‰
            test_size: æµ‹è¯•é›†æ¯”ä¾‹
            normalize: æ˜¯å¦å½’ä¸€åŒ–ç‰¹å¾
        
        Returns:
            è®­ç»ƒæŒ‡æ ‡å­—å…¸
        """
        if features.empty or labels.empty:
            logger.error("âŒ è®­ç»ƒæ•°æ®ä¸ºç©º")
            return {}
        
        # ç‰¹å¾å½’ä¸€åŒ–
        if normalize:
            features = normalize_features(features)
        
        # ä¿å­˜ç‰¹å¾åˆ—å
        self.feature_cols = features.columns.tolist()
        
        # å¤„ç†ç¼ºå¤±å€¼å’Œæ— ç©·å€¼
        features = features.replace([np.inf, -np.inf], np.nan).fillna(0)
        labels = labels.replace([np.inf, -np.inf], np.nan).fillna(0 if self.model_type == "classifier" else 0.0)
        
        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            features.values,
            labels.values,
            test_size=test_size,
            random_state=42,
            stratify=labels if self.model_type == "classifier" else None
        )
        
        logger.info(f"ğŸ“Š è®­ç»ƒæ•°æ®: {len(X_train)} æ¡ï¼Œæµ‹è¯•æ•°æ®: {len(X_test)} æ¡")
        
        # è®­ç»ƒæ¨¡å‹
        logger.info("ğŸ”§ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        self.model.fit(X_train, y_train)
        self.is_trained = True
        
        # è¯„ä¼°æ¨¡å‹
        train_pred = self.model.predict(X_train)
        test_pred = self.model.predict(X_test)
        
        metrics = {}
        
        if self.model_type == "classifier":
            # åˆ†ç±»æŒ‡æ ‡
            metrics['train_accuracy'] = accuracy_score(y_train, train_pred)
            metrics['test_accuracy'] = accuracy_score(y_test, test_pred)
            metrics['test_precision'] = precision_score(y_test, test_pred, zero_division=0)
            metrics['test_recall'] = recall_score(y_test, test_pred, zero_division=0)
            metrics['test_f1'] = f1_score(y_test, test_pred, zero_division=0)
            
            # ROC-AUCï¼ˆéœ€è¦æ¦‚ç‡ï¼‰
            try:
                test_proba = self.model.predict_proba(X_test)[:, 1]
                metrics['test_roc_auc'] = roc_auc_score(y_test, test_proba)
            except:
                metrics['test_roc_auc'] = 0.0
        else:
            # å›å½’æŒ‡æ ‡
            from sklearn.metrics import mean_squared_error, r2_score
            metrics['train_rmse'] = np.sqrt(mean_squared_error(y_train, train_pred))
            metrics['test_rmse'] = np.sqrt(mean_squared_error(y_test, test_pred))
            metrics['test_r2'] = r2_score(y_test, test_pred)
        
        logger.info(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæµ‹è¯•é›†æŒ‡æ ‡: {metrics}")
        
        # ä¿å­˜æ¨¡å‹
        if self.model_path:
            self.save_model(self.model_path)
        
        return metrics
    
    def predict_stocks(
        self,
        features: pd.DataFrame,
        return_proba: bool = False,
        normalize: bool = True
    ) -> pd.DataFrame:
        """
        é¢„æµ‹è‚¡ç¥¨æ”¶ç›Šæ¦‚ç‡
        
        Args:
            features: ç‰¹å¾DataFrame
            return_proba: æ˜¯å¦è¿”å›æ¦‚ç‡ï¼ˆä»…åˆ†ç±»å™¨ï¼‰
            normalize: æ˜¯å¦å½’ä¸€åŒ–ç‰¹å¾
        
        Returns:
            åŒ…å«é¢„æµ‹ç»“æœçš„DataFrame
        """
        if not self.is_trained:
            logger.error("âŒ æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•é¢„æµ‹")
            return pd.DataFrame()
        
        if features.empty:
            logger.error("âŒ ç‰¹å¾æ•°æ®ä¸ºç©º")
            return pd.DataFrame()
        
        # ç¡®ä¿ç‰¹å¾åˆ—ä¸€è‡´
        if self.feature_cols:
            missing_cols = [col for col in self.feature_cols if col not in features.columns]
            if missing_cols:
                logger.warning(f"âš ï¸ ç¼ºå°‘ç‰¹å¾åˆ—: {missing_cols}ï¼Œå°†ç”¨0å¡«å……")
                for col in missing_cols:
                    features[col] = 0
            features = features[self.feature_cols]
        
        # ç‰¹å¾å½’ä¸€åŒ–
        if normalize:
            features = normalize_features(features)
        
        # å¤„ç†ç¼ºå¤±å€¼å’Œæ— ç©·å€¼
        features = features.replace([np.inf, -np.inf], np.nan).fillna(0)
        
        # é¢„æµ‹
        if self.model_type == "classifier" and return_proba:
            predictions = self.model.predict_proba(features.values)[:, 1]
        else:
            predictions = self.model.predict(features.values)
        
        result = features.copy()
        result['prediction'] = predictions
        
        if self.model_type == "classifier" and return_proba:
            result['probability'] = predictions
            result['prediction_binary'] = (predictions > 0.5).astype(int)
        
        logger.info(f"âœ… é¢„æµ‹å®Œæˆ: {len(result)} åªè‚¡ç¥¨")
        return result
    
    def save_model(self, path: str):
        """ä¿å­˜æ¨¡å‹"""
        if not self.is_trained:
            logger.warning("âš ï¸ æ¨¡å‹æœªè®­ç»ƒï¼Œè·³è¿‡ä¿å­˜")
            return
        
        save_path = Path(path)
        save_path.parent.mkdir(parents=True, exist_ok=True)
        
        model_data = {
            'model': self.model,
            'feature_cols': self.feature_cols,
            'model_type': self.model_type,
            'is_trained': self.is_trained
        }
        
        joblib.dump(model_data, save_path)
        logger.info(f"âœ… æ¨¡å‹å·²ä¿å­˜: {save_path}")
    
    def load_model(self, path: str):
        """åŠ è½½æ¨¡å‹"""
        try:
            model_data = joblib.load(path)
            self.model = model_data['model']
            self.feature_cols = model_data.get('feature_cols')
            self.model_type = model_data.get('model_type', 'classifier')
            self.is_trained = model_data.get('is_trained', False)
            
            logger.info(f"âœ… æ¨¡å‹å·²åŠ è½½: {path}")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            self.is_trained = False
    
    def get_feature_importance(self, top_n: int = 20) -> pd.DataFrame:
        """
        è·å–ç‰¹å¾é‡è¦æ€§
        
        Args:
            top_n: è¿”å›å‰Nä¸ªé‡è¦ç‰¹å¾
        
        Returns:
            ç‰¹å¾é‡è¦æ€§DataFrame
        """
        if not self.is_trained or self.feature_cols is None:
            logger.error("âŒ æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•è·å–ç‰¹å¾é‡è¦æ€§")
            return pd.DataFrame()
        
        importances = self.model.feature_importances_
        
        result = pd.DataFrame({
            'feature': self.feature_cols,
            'importance': importances
        }).sort_values('importance', ascending=False).head(top_n)
        
        return result

