#!/usr/bin/env python3
"""
Aè‚¡åŸºç¡€æ•°æ®ä¸‹è½½å™¨
æ‰¹é‡ä¸‹è½½å¹¶å­˜å‚¨Aè‚¡åŸºæœ¬ä¿¡æ¯ï¼ˆä»£ç ã€åç§°ã€å¸‚ç›ˆç‡ã€å¸‚å€¼ç­‰ï¼‰
"""

import os
import sqlite3
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List
import time

from tradingagents.utils.logging_init import get_logger

logger = get_logger('dataflows.a_share_downloader')


class AShareDownloader:
    def __init__(self, db_path: Optional[str] = None):
        """
        åˆå§‹åŒ–Aè‚¡æ•°æ®ä¸‹è½½å™¨
        
        Args:
            db_path: SQLiteæ•°æ®åº“è·¯å¾„ï¼Œé»˜è®¤åœ¨é¡¹ç›®dataç›®å½•
        """
        if db_path is None:
            base = Path(__file__).resolve().parents[2]
            db_path = base / "data" / "a_share_basic.db"
        
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_db()

    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        
        # è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS stock_basic (
                ts_code TEXT PRIMARY KEY,
                symbol TEXT NOT NULL,
                name TEXT NOT NULL,
                area TEXT,
                industry TEXT,
                market TEXT,
                list_date TEXT,
                pe REAL,
                pb REAL,
                total_mv REAL,
                circ_mv REAL,
                update_time TEXT NOT NULL
            )
        """)
        
        # åˆ›å»ºç´¢å¼•
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_symbol ON stock_basic(symbol)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_name ON stock_basic(name)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_industry ON stock_basic(industry)")
        
        conn.commit()
        conn.close()
        logger.info(f"âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.db_path}")

    def download_all_stocks(self, use_cache: bool = True) -> pd.DataFrame:
        """
        ä¸‹è½½æ‰€æœ‰Aè‚¡åŸºæœ¬ä¿¡æ¯
        
        Args:
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼ˆæ£€æŸ¥æ›´æ–°æ—¶é—´ï¼‰
        
        Returns:
            åŒ…å«æ‰€æœ‰è‚¡ç¥¨ä¿¡æ¯çš„DataFrame
        """
        try:
            # å°è¯•ä½¿ç”¨Tushare
            from tradingagents.dataflows.tushare_adapter import get_tushare_adapter
            adapter = get_tushare_adapter()
            
            if not adapter.provider or not adapter.provider.connected:
                logger.warning("âš ï¸ Tushareæœªè¿æ¥ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æ•°æ®æº")
                return self._download_fallback()
            
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            logger.info("ğŸ“¥ å¼€å§‹ä¸‹è½½Aè‚¡åŸºæœ¬ä¿¡æ¯...")
            pro = adapter.provider.pro_api
            
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            stock_list = pro.stock_basic(exchange='', list_status='L', fields='ts_code,symbol,name,area,industry,market,list_date')
            
            if stock_list.empty:
                logger.warning("âš ï¸ æœªè·å–åˆ°è‚¡ç¥¨åˆ—è¡¨")
                return pd.DataFrame()
            
            logger.info(f"âœ… è·å–åˆ° {len(stock_list)} åªè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
            
            # è·å–æ¯æ—¥æŒ‡æ ‡ï¼ˆåŒ…å«PEã€PBã€å¸‚å€¼ï¼‰
            logger.info("ğŸ“¥ è·å–æ¯æ—¥æŒ‡æ ‡æ•°æ®ï¼ˆPEã€PBã€å¸‚å€¼ï¼‰...")
            
            # åˆ†æ‰¹è·å–ï¼Œé¿å…APIé™åˆ¶
            all_data = []
            batch_size = 500
            today = datetime.now().strftime('%Y%m%d')
            
            for i in range(0, len(stock_list), batch_size):
                batch = stock_list.iloc[i:i+batch_size]
                ts_codes = ','.join(batch['ts_code'].tolist())
                
                try:
                    # è·å–æ¯æ—¥æŒ‡æ ‡
                    daily_basic = pro.daily_basic(
                        trade_date=today,
                        ts_code=ts_codes,
                        fields='ts_code,pe,pb,total_mv,circ_mv'
                    )
                    
                    # åˆå¹¶æ•°æ®
                    merged = batch.merge(daily_basic, on='ts_code', how='left')
                    all_data.append(merged)
                    
                    time.sleep(0.2)  # æ§åˆ¶è¯·æ±‚é¢‘ç‡
                    
                    if (i + batch_size) % 1000 == 0:
                        logger.info(f"â³ å·²å¤„ç† {i + batch_size}/{len(stock_list)} åªè‚¡ç¥¨")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ æ‰¹æ¬¡ {i//batch_size + 1} è·å–å¤±è´¥: {e}")
                    # å³ä½¿å¤±è´¥ä¹Ÿä¿å­˜åŸºæœ¬ä¿¡æ¯
                    all_data.append(batch)
            
            # åˆå¹¶æ‰€æœ‰æ•°æ®
            if all_data:
                result = pd.concat(all_data, ignore_index=True)
                result['update_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
                # å¡«å……ç¼ºå¤±å€¼
                result['pe'] = pd.to_numeric(result['pe'], errors='coerce')
                result['pb'] = pd.to_numeric(result['pb'], errors='coerce')
                result['total_mv'] = pd.to_numeric(result['total_mv'], errors='coerce')
                result['circ_mv'] = pd.to_numeric(result['circ_mv'], errors='coerce')
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                self.save_to_db(result)
                
                logger.info(f"âœ… æˆåŠŸä¸‹è½½å¹¶ä¿å­˜ {len(result)} åªè‚¡ç¥¨æ•°æ®")
                return result
            else:
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}", exc_info=True)
            return self._download_fallback()

    def _download_fallback(self) -> pd.DataFrame:
        """å¤‡ç”¨ä¸‹è½½æ–¹æ³•ï¼ˆä½¿ç”¨AKShareç­‰ï¼‰"""
        try:
            import akshare as ak
            logger.info("ğŸ“¥ ä½¿ç”¨AKShareä½œä¸ºå¤‡ç”¨æ•°æ®æº...")
            
            # è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨
            stock_info = ak.stock_info_a_code_name()
            
            if stock_info.empty:
                return pd.DataFrame()
            
            # é‡å‘½ååˆ—ä»¥åŒ¹é…æ ‡å‡†æ ¼å¼
            result = pd.DataFrame({
                'ts_code': '',
                'symbol': stock_info['code'],
                'name': stock_info['name'],
                'area': '',
                'industry': '',
                'market': '',
                'list_date': '',
                'pe': None,
                'pb': None,
                'total_mv': None,
                'circ_mv': None,
                'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
            
            # å°è¯•è·å–è¡Œä¸šä¿¡æ¯
            try:
                for idx, row in result.iterrows():
                    code = row['symbol']
                    try:
                        # è·å–ä¸ªè‚¡åŸºæœ¬ä¿¡æ¯
                        info = ak.stock_individual_info_em(symbol=code)
                        if not info.empty:
                            industry = info[info['item'] == 'è¡Œä¸š']['value'].values
                            if len(industry) > 0:
                                result.loc[idx, 'industry'] = industry[0]
                        time.sleep(0.1)  # æ§åˆ¶é¢‘ç‡
                    except:
                        continue
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–è¡Œä¸šä¿¡æ¯å¤±è´¥: {e}")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            self.save_to_db(result)
            
            logger.info(f"âœ… ä½¿ç”¨AKShareä¸‹è½½äº† {len(result)} åªè‚¡ç¥¨æ•°æ®")
            return result
            
        except Exception as e:
            logger.error(f"âŒ å¤‡ç”¨ä¸‹è½½æ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
            return pd.DataFrame()

    def save_to_db(self, data: pd.DataFrame):
        """ä¿å­˜æ•°æ®åˆ°SQLiteæ•°æ®åº“"""
        if data.empty:
            return
        
        conn = sqlite3.connect(str(self.db_path))
        
        # å…ˆåˆ é™¤æ—§æ•°æ®ï¼ˆå¯é€‰ï¼šæ”¹ä¸ºæ›´æ–°æ¨¡å¼ï¼‰
        # conn.execute("DELETE FROM stock_basic")
        
        # æ’å…¥æˆ–æ›´æ–°æ•°æ®
        data.to_sql('stock_basic', conn, if_exists='replace', index=False)
        
        conn.commit()
        conn.close()
        logger.info(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“: {len(data)} æ¡è®°å½•")

    def search_stocks(self, 
                     keyword: Optional[str] = None,
                     industry: Optional[str] = None,
                     min_market_cap: Optional[float] = None,
                     max_pe: Optional[float] = None,
                     max_pb: Optional[float] = None,
                     limit: int = 100) -> pd.DataFrame:
        """
        æœç´¢è‚¡ç¥¨
        
        Args:
            keyword: å…³é”®å­—ï¼ˆä»£ç æˆ–åç§°ï¼‰
            industry: è¡Œä¸šç­›é€‰
            min_market_cap: æœ€å°å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰
            max_pe: æœ€å¤§å¸‚ç›ˆç‡
            max_pb: æœ€å¤§å¸‚å‡€ç‡
            limit: è¿”å›æ•°é‡é™åˆ¶
        
        Returns:
            ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨DataFrame
        """
        conn = sqlite3.connect(str(self.db_path))
        
        query = "SELECT * FROM stock_basic WHERE 1=1"
        params = []
        
        if keyword:
            query += " AND (symbol LIKE ? OR name LIKE ?)"
            params.extend([f"%{keyword}%", f"%{keyword}%"])
        
        if industry:
            query += " AND industry LIKE ?"
            params.append(f"%{industry}%")
        
        if min_market_cap:
            query += " AND (total_mv >= ? OR total_mv IS NULL)"
            params.append(min_market_cap * 1e8)  # è½¬æ¢ä¸ºå…ƒ
        
        if max_pe:
            query += " AND (pe <= ? OR pe IS NULL)"
            params.append(max_pe)
        
        if max_pb:
            query += " AND (pb <= ? OR pb IS NULL)"
            params.append(max_pb)
        
        query += f" ORDER BY update_time DESC LIMIT {limit}"
        
        result = pd.read_sql_query(query, conn, params=params)
        conn.close()
        
        return result

    def get_stock_info(self, symbol: str) -> Optional[Dict]:
        """è·å–å•åªè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯"""
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        
        cursor.execute(
            "SELECT * FROM stock_basic WHERE symbol = ?",
            (symbol,)
        )
        
        row = cursor.fetchone()
        conn.close()
        
        if row:
            columns = ['ts_code', 'symbol', 'name', 'area', 'industry', 'market',
                      'list_date', 'pe', 'pb', 'total_mv', 'circ_mv', 'update_time']
            return dict(zip(columns, row))
        
        return None

    def update_stock_data(self, symbols: List[str]) -> pd.DataFrame:
        """æ›´æ–°æŒ‡å®šè‚¡ç¥¨çš„æœ€æ–°æ•°æ®"""
        # å®ç°å¢é‡æ›´æ–°é€»è¾‘
        # å¯ä»¥è°ƒç”¨download_all_stocksæˆ–åªæ›´æ–°ç‰¹å®šè‚¡ç¥¨
        pass


def get_downloader(db_path: Optional[str] = None) -> AShareDownloader:
    """è·å–ä¸‹è½½å™¨å®ä¾‹"""
    return AShareDownloader(db_path)

