#!/usr/bin/env python3
"""
Aè‚¡åŸºç¡€æ•°æ®ä¸‹è½½å™¨
æ‰¹é‡ä¸‹è½½å¹¶å­˜å‚¨Aè‚¡åŸºæœ¬ä¿¡æ¯ï¼ˆä»£ç ã€åç§°ã€å¸‚ç›ˆç‡ã€å¸‚å€¼ç­‰ï¼‰
"""

import os
import sqlite3
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List
import time

from tradingagents.utils.logging_init import get_logger

logger = get_logger('dataflows.a_share_downloader')


class AShareDownloader:
    def __init__(self, db_path: Optional[str] = None):
        """
        åˆå§‹åŒ–Aè‚¡æ•°æ®ä¸‹è½½å™¨
        
        Args:
            db_path: SQLiteæ•°æ®åº“è·¯å¾„ï¼Œé»˜è®¤åœ¨é¡¹ç›®dataç›®å½•
        """
        if db_path is None:
            base = Path(__file__).resolve().parents[2]
            db_path = base / "data" / "a_share_basic.db"
        
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_db()

    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        
        # è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS stock_basic (
                ts_code TEXT PRIMARY KEY,
                symbol TEXT NOT NULL,
                name TEXT NOT NULL,
                area TEXT,
                industry TEXT,
                market TEXT,
                list_date TEXT,
                pe REAL,
                pb REAL,
                total_mv REAL,
                circ_mv REAL,
                update_time TEXT NOT NULL
            )
        """)
        
        # åˆ›å»ºç´¢å¼•
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_symbol ON stock_basic(symbol)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_name ON stock_basic(name)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_industry ON stock_basic(industry)")
        
        conn.commit()
        conn.close()
        logger.info(f"âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.db_path}")

    def download_all_stocks(self, use_cache: bool = True) -> pd.DataFrame:
        """
        ä¸‹è½½æ‰€æœ‰Aè‚¡åŸºæœ¬ä¿¡æ¯
        
        Args:
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼ˆæ£€æŸ¥æ›´æ–°æ—¶é—´ï¼‰
        
        Returns:
            åŒ…å«æ‰€æœ‰è‚¡ç¥¨ä¿¡æ¯çš„DataFrame
        """
        try:
            # å°è¯•ä½¿ç”¨Tushare
            from tradingagents.dataflows.tushare_adapter import get_tushare_adapter
            adapter = get_tushare_adapter()
            
            if not adapter.provider or not adapter.provider.connected:
                logger.warning("âš ï¸ Tushareæœªè¿æ¥ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æ•°æ®æº")
                return self._download_fallback()
            
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            logger.info("ğŸ“¥ å¼€å§‹ä¸‹è½½Aè‚¡åŸºæœ¬ä¿¡æ¯...")
            pro = adapter.provider.pro_api
            
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            stock_list = pro.stock_basic(exchange='', list_status='L', fields='ts_code,symbol,name,area,industry,market,list_date')
            
            if stock_list.empty:
                logger.warning("âš ï¸ æœªè·å–åˆ°è‚¡ç¥¨åˆ—è¡¨")
                return pd.DataFrame()
            
            logger.info(f"âœ… è·å–åˆ° {len(stock_list)} åªè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
            
            # è·å–æ¯æ—¥æŒ‡æ ‡ï¼ˆåŒ…å«PEã€PBã€å¸‚å€¼ï¼‰
            logger.info("ğŸ“¥ è·å–æ¯æ—¥æŒ‡æ ‡æ•°æ®ï¼ˆPEã€PBã€å¸‚å€¼ï¼‰...")
            
            # åˆ†æ‰¹è·å–ï¼Œé¿å…APIé™åˆ¶
            all_data = []
            batch_size = 500
            today = datetime.now().strftime('%Y%m%d')
            
            for i in range(0, len(stock_list), batch_size):
                batch = stock_list.iloc[i:i+batch_size]
                ts_codes = ','.join(batch['ts_code'].tolist())
                
                try:
                    # è·å–æ¯æ—¥æŒ‡æ ‡
                    daily_basic = pro.daily_basic(
                        trade_date=today,
                        ts_code=ts_codes,
                        fields='ts_code,pe,pb,total_mv,circ_mv'
                    )
                    
                    # åˆå¹¶æ•°æ®
                    merged = batch.merge(daily_basic, on='ts_code', how='left')
                    all_data.append(merged)
                    
                    time.sleep(0.2)  # æ§åˆ¶è¯·æ±‚é¢‘ç‡
                    
                    if (i + batch_size) % 1000 == 0:
                        logger.info(f"â³ å·²å¤„ç† {i + batch_size}/{len(stock_list)} åªè‚¡ç¥¨")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ æ‰¹æ¬¡ {i//batch_size + 1} è·å–å¤±è´¥: {e}")
                    # å³ä½¿å¤±è´¥ä¹Ÿä¿å­˜åŸºæœ¬ä¿¡æ¯
                    all_data.append(batch)
            
            # åˆå¹¶æ‰€æœ‰æ•°æ®
            if all_data:
                result = pd.concat(all_data, ignore_index=True)
                result['update_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
                # å¡«å……ç¼ºå¤±å€¼
                result['pe'] = pd.to_numeric(result['pe'], errors='coerce')
                result['pb'] = pd.to_numeric(result['pb'], errors='coerce')
                result['total_mv'] = pd.to_numeric(result['total_mv'], errors='coerce')
                result['circ_mv'] = pd.to_numeric(result['circ_mv'], errors='coerce')
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                self.save_to_db(result)
                
                logger.info(f"âœ… æˆåŠŸä¸‹è½½å¹¶ä¿å­˜ {len(result)} åªè‚¡ç¥¨æ•°æ®")
                return result
            else:
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}", exc_info=True)
            return self._download_fallback()

    def _download_fallback(self) -> pd.DataFrame:
        """
        å¤‡ç”¨ä¸‹è½½æ–¹æ³•ï¼ˆä½¿ç”¨AKShareç­‰ï¼‰
        ä¼˜åŒ–ï¼šæ‰¹é‡è·å–ï¼Œå‡å°‘APIè°ƒç”¨
        """
        try:
            import akshare as ak
            logger.info("ğŸ“¥ ä½¿ç”¨AKShareä½œä¸ºå¤‡ç”¨æ•°æ®æº...")
            
            # æ–¹æ³•1ï¼šå°è¯•ä½¿ç”¨ spot_em æ¥å£ï¼ˆæ›´å¿«ï¼Œä¸€æ¬¡æ€§è·å–æ‰€æœ‰Aè‚¡å®æ—¶æ•°æ®ï¼‰
            try:
                logger.info("ğŸ“Š å°è¯•ä½¿ç”¨ ak.stock_zh_a_spot_em() æ‰¹é‡è·å–...")
                # æ·»åŠ é‡è¯•æœºåˆ¶
                max_retries = 3
                delay = 2
                stock_spot = None
                for attempt in range(max_retries):
                    try:
                        stock_spot = ak.stock_zh_a_spot_em()
                        break
                    except Exception as e:
                        if attempt < max_retries - 1:
                            logger.warning(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}, {delay}ç§’åé‡è¯•...")
                            time.sleep(delay)
                            delay *= 2
                        else:
                            raise
                
                if not stock_spot.empty:
                    logger.info(f"âœ… é€šè¿‡spotæ¥å£è·å–åˆ° {len(stock_spot)} åªè‚¡ç¥¨")
                    
                    # æ˜ å°„åˆ—å
                    column_mapping = {
                        'ä»£ç ': 'symbol',
                        'åç§°': 'name',
                        'æœ€æ–°ä»·': 'close',
                        'æ¶¨è·Œå¹…': 'pct_chg',
                        'æ¶¨è·Œé¢': 'change',
                        'æˆäº¤é‡': 'volume',
                        'æˆäº¤é¢': 'amount',
                        'å¸‚ç›ˆç‡-åŠ¨æ€': 'pe',
                        'å¸‚å‡€ç‡': 'pb',
                        'æ€»å¸‚å€¼': 'total_mv',
                        'æµé€šå¸‚å€¼': 'circ_mv'
                    }
                    
                    result = pd.DataFrame()
                    for old_col, new_col in column_mapping.items():
                        if old_col in stock_spot.columns:
                            result[new_col] = stock_spot[old_col]
                    
                    # å¦‚æœæ²¡æœ‰ä»spotè·å–åˆ°è¡Œä¸šï¼Œå°è¯•ä»å…¶ä»–æ¥å£
                    if 'industry' not in result.columns:
                        # è·å–è¡Œä¸šä¿¡æ¯ï¼ˆå¯é€‰ï¼Œè¾ƒæ…¢ï¼‰
                        logger.info("ğŸ“Š è·å–è¡Œä¸šä¿¡æ¯...")
                        try:
                            # ä½¿ç”¨è‚¡ç¥¨ä¿¡æ¯æ¥å£æ‰¹é‡è·å–è¡Œä¸š
                            stock_info_all = ak.stock_info_a_code_name()
                            # åˆå¹¶è¡Œä¸šä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                            # æ³¨æ„ï¼šè¿™ä¸ªæ¥å£å¯èƒ½ä¸åŒ…å«è¡Œä¸šï¼Œéœ€è¦é€ä¸ªæŸ¥è¯¢
                            # ä¸ºäº†é€Ÿåº¦ï¼Œæˆ‘ä»¬è·³è¿‡è¯¦ç»†è¡Œä¸šè·å–ï¼Œä½¿ç”¨ç©ºå€¼
                            result['industry'] = ''
                        except:
                            result['industry'] = ''
                    
                    # è¡¥é½æ ‡å‡†åˆ—
                    if 'ts_code' not in result.columns:
                        result['ts_code'] = result['symbol'].apply(lambda x: f"{x}.SH" if x.startswith('6') else f"{x}.SZ")
                    if 'area' not in result.columns:
                        result['area'] = ''
                    if 'market' not in result.columns:
                        result['market'] = result['symbol'].apply(lambda x: 'SH' if x.startswith('6') else 'SZ')
                    if 'list_date' not in result.columns:
                        result['list_date'] = ''
                    if 'pe' not in result.columns:
                        result['pe'] = None
                    if 'pb' not in result.columns:
                        result['pb'] = None
                    if 'total_mv' not in result.columns:
                        result['total_mv'] = None
                    if 'circ_mv' not in result.columns:
                        result['circ_mv'] = None
                    
                    result['update_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    self.save_to_db(result)
                    logger.info(f"âœ… ä½¿ç”¨AKShare spotæ¥å£ä¸‹è½½äº† {len(result)} åªè‚¡ç¥¨æ•°æ®")
                    return result[['ts_code', 'symbol', 'name', 'area', 'industry', 'market', 
                                  'list_date', 'pe', 'pb', 'total_mv', 'circ_mv', 'update_time']]
            
            except Exception as e:
                logger.warning(f"âš ï¸ spotæ¥å£å¤±è´¥ï¼Œå°è¯•åŸºç¡€æ¥å£: {e}")
            
            # æ–¹æ³•2ï¼šé™çº§åˆ°åŸºç¡€æ¥å£
            logger.info("ğŸ“Š ä½¿ç”¨åŸºç¡€æ¥å£ ak.stock_info_a_code_name()...")
            # æ·»åŠ é‡è¯•æœºåˆ¶
            max_retries = 3
            delay = 2
            stock_info = None
            for attempt in range(max_retries):
                try:
                    stock_info = ak.stock_info_a_code_name()
                    break
                except Exception as e:
                    if attempt < max_retries - 1:
                        logger.warning(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}, {delay}ç§’åé‡è¯•...")
                        time.sleep(delay)
                        delay *= 2
                    else:
                        raise
            
            if stock_info.empty:
                logger.error("âŒ AKShareåŸºç¡€æ¥å£ä¹Ÿè¿”å›ç©ºæ•°æ®")
                return pd.DataFrame()
            
            logger.info(f"âœ… è·å–åˆ° {len(stock_info)} åªè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
            
            # é‡å‘½ååˆ—ä»¥åŒ¹é…æ ‡å‡†æ ¼å¼
            result = pd.DataFrame({
                'ts_code': '',
                'symbol': stock_info['code'] if 'code' in stock_info.columns else stock_info.iloc[:, 0],
                'name': stock_info['name'] if 'name' in stock_info.columns else stock_info.iloc[:, 1],
                'area': '',
                'industry': '',
                'market': '',
                'list_date': '',
                'pe': None,
                'pb': None,
                'total_mv': None,
                'circ_mv': None,
                'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
            
            # å¡«å……ts_codeå’Œmarket
            result['ts_code'] = result['symbol'].apply(
                lambda x: f"{x}.SH" if str(x).startswith('6') else f"{x}.SZ"
            )
            result['market'] = result['symbol'].apply(
                lambda x: 'SH' if str(x).startswith('6') else 'SZ'
            )
            
            # æ³¨æ„ï¼šä¸ºäº†é€Ÿåº¦ï¼Œè·³è¿‡é€ä¸ªæŸ¥è¯¢è¡Œä¸šä¿¡æ¯ï¼ˆ5000+è‚¡ç¥¨ä¼šéå¸¸æ…¢ï¼‰
            # å¦‚æœéœ€è¦è¡Œä¸šä¿¡æ¯ï¼Œå¯ä»¥åç»­å•ç‹¬æ‰¹é‡æ›´æ–°
            logger.info("ğŸ’¡ æç¤ºï¼šè¡Œä¸šä¿¡æ¯æœªè·å–ï¼ˆé¿å…5000+æ¬¡APIè°ƒç”¨ï¼‰ï¼Œå¯ä½¿ç”¨åç»­æ¥å£è¡¥å……")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            self.save_to_db(result)
            
            logger.info(f"âœ… ä½¿ç”¨AKShareåŸºç¡€æ¥å£ä¸‹è½½äº† {len(result)} åªè‚¡ç¥¨æ•°æ®")
            return result
            
        except ImportError:
            logger.error("âŒ AKShareæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install akshare")
            return pd.DataFrame()
        except ConnectionError as e:
            logger.error(f"âŒ ç½‘ç»œè¿æ¥é”™è¯¯: {e}")
            logger.info("ğŸ’¡ å»ºè®®: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–ç¨åé‡è¯•")
            return pd.DataFrame()
        except Exception as e:
            error_msg = str(e)
            if "connection" in error_msg.lower() or "timeout" in error_msg.lower():
                logger.error(f"âŒ ç½‘ç»œè¿æ¥é”™è¯¯: {e}")
                logger.info("ğŸ’¡ å»ºè®®: æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®šï¼Œæˆ–ç¨åé‡è¯•")
            elif "rate limit" in error_msg.lower() or "é¢‘ç‡" in error_msg:
                logger.error(f"âŒ è¯·æ±‚é¢‘ç‡è¿‡é«˜: {e}")
                logger.info("ğŸ’¡ å»ºè®®: ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•")
            else:
                logger.error(f"âŒ å¤‡ç”¨ä¸‹è½½æ–¹æ³•å¤±è´¥: {e}", exc_info=True)
            return pd.DataFrame()

    def save_to_db(self, data: pd.DataFrame):
        """ä¿å­˜æ•°æ®åˆ°SQLiteæ•°æ®åº“"""
        if data.empty:
            return
        
        conn = sqlite3.connect(str(self.db_path))
        
        # å…ˆåˆ é™¤æ—§æ•°æ®ï¼ˆå¯é€‰ï¼šæ”¹ä¸ºæ›´æ–°æ¨¡å¼ï¼‰
        # conn.execute("DELETE FROM stock_basic")
        
        # æ’å…¥æˆ–æ›´æ–°æ•°æ®
        data.to_sql('stock_basic', conn, if_exists='replace', index=False)
        
        conn.commit()
        conn.close()
        logger.info(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“: {len(data)} æ¡è®°å½•")

    def search_stocks(self, 
                     keyword: Optional[str] = None,
                     industry: Optional[str] = None,
                     min_market_cap: Optional[float] = None,
                     max_pe: Optional[float] = None,
                     max_pb: Optional[float] = None,
                     limit: int = 100) -> pd.DataFrame:
        """
        æœç´¢è‚¡ç¥¨
        
        Args:
            keyword: å…³é”®å­—ï¼ˆä»£ç æˆ–åç§°ï¼‰
            industry: è¡Œä¸šç­›é€‰
            min_market_cap: æœ€å°å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰
            max_pe: æœ€å¤§å¸‚ç›ˆç‡
            max_pb: æœ€å¤§å¸‚å‡€ç‡
            limit: è¿”å›æ•°é‡é™åˆ¶
        
        Returns:
            ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨DataFrame
        """
        conn = sqlite3.connect(str(self.db_path))
        
        query = "SELECT * FROM stock_basic WHERE 1=1"
        params = []
        
        if keyword:
            query += " AND (symbol LIKE ? OR name LIKE ?)"
            params.extend([f"%{keyword}%", f"%{keyword}%"])
        
        if industry:
            query += " AND industry LIKE ?"
            params.append(f"%{industry}%")
        
        if min_market_cap:
            query += " AND (total_mv >= ? OR total_mv IS NULL)"
            params.append(min_market_cap * 1e8)  # è½¬æ¢ä¸ºå…ƒ
        
        if max_pe:
            query += " AND (pe <= ? OR pe IS NULL)"
            params.append(max_pe)
        
        if max_pb:
            query += " AND (pb <= ? OR pb IS NULL)"
            params.append(max_pb)
        
        query += f" ORDER BY update_time DESC LIMIT {limit}"
        
        result = pd.read_sql_query(query, conn, params=params)
        conn.close()
        
        return result

    def get_stock_info(self, symbol: str) -> Optional[Dict]:
        """è·å–å•åªè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯"""
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        
        cursor.execute(
            "SELECT * FROM stock_basic WHERE symbol = ?",
            (symbol,)
        )
        
        row = cursor.fetchone()
        conn.close()
        
        if row:
            columns = ['ts_code', 'symbol', 'name', 'area', 'industry', 'market',
                      'list_date', 'pe', 'pb', 'total_mv', 'circ_mv', 'update_time']
            return dict(zip(columns, row))
        
        return None

    def update_stock_data(self, symbols: List[str]) -> pd.DataFrame:
        """æ›´æ–°æŒ‡å®šè‚¡ç¥¨çš„æœ€æ–°æ•°æ®"""
        # å®ç°å¢é‡æ›´æ–°é€»è¾‘
        # å¯ä»¥è°ƒç”¨download_all_stocksæˆ–åªæ›´æ–°ç‰¹å®šè‚¡ç¥¨
        pass


def get_downloader(db_path: Optional[str] = None) -> AShareDownloader:
    """è·å–ä¸‹è½½å™¨å®ä¾‹"""
    return AShareDownloader(db_path)

