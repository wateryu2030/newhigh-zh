#!/usr/bin/env python3
"""
LLMæä¾›å•†æ£€æŸ¥å·¥å…·
ç”¨äºæ£€æµ‹å’ŒéªŒè¯LLMé…ç½®ï¼Œå¹¶åœ¨é‡åˆ°é—®é¢˜æ—¶å»ºè®®åˆ‡æ¢
"""

import os
from typing import Dict, List, Tuple, Optional
from tradingagents.utils.logging_init import get_logger

logger = get_logger('web.llm_provider_checker')


class LLMProviderChecker:
    """LLMæä¾›å•†æ£€æŸ¥å’Œåˆ‡æ¢åŠ©æ‰‹"""
    
    @staticmethod
    def get_available_providers() -> List[Dict[str, str]]:
        """
        è·å–æ‰€æœ‰å¯ç”¨çš„LLMæä¾›å•†
        
        Returns:
            æä¾›å•†åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«name, key, configuredç­‰å­—æ®µ
        """
        providers = []
        
        # Dashscope
        dashscope_key = os.getenv("DASHSCOPE_API_KEY")
        providers.append({
            'id': 'dashscope',
            'name': 'ğŸ‡¨ğŸ‡³ é˜¿é‡Œç™¾ç‚¼',
            'display_name': 'é˜¿é‡Œç™¾ç‚¼ (Dashscope)',
            'api_key': dashscope_key,
            'configured': bool(dashscope_key and dashscope_key != 'your_dashscope_api_key_here'),
            'recommended': True,
            'models': ['qwen-plus-latest', 'qwen-max', 'qwen-turbo']
        })
        
        # Anthropic
        anthropic_key = os.getenv("ANTHROPIC_API_KEY")
        providers.append({
            'id': 'anthropic',
            'name': 'ğŸ¤– Anthropic Claude',
            'display_name': 'Anthropic Claude',
            'api_key': anthropic_key,
            'configured': bool(anthropic_key and anthropic_key != 'your_anthropic_api_key_here'),
            'recommended': False,
            'models': ['claude-3-5-sonnet-latest']
        })
        
        # DeepSeek
        deepseek_key = os.getenv("DEEPSEEK_API_KEY")
        providers.append({
            'id': 'deepseek',
            'name': 'ğŸš€ DeepSeek',
            'display_name': 'DeepSeek',
            'api_key': deepseek_key,
            'configured': bool(deepseek_key and deepseek_key != 'your_deepseek_api_key_here'),
            'recommended': False,
            'models': ['deepseek-chat']
        })
        
        # OpenAI
        openai_key = os.getenv("OPENAI_API_KEY")
        providers.append({
            'id': 'openai',
            'name': 'ğŸ¤– OpenAI',
            'display_name': 'OpenAI',
            'api_key': openai_key,
            'configured': bool(openai_key and openai_key not in ['your_openai_api_key_here', '']),
            'recommended': False,
            'models': ['gpt-4o', 'gpt-4o-mini']
        })
        
        return providers
    
    @staticmethod
    def get_recommended_provider() -> Optional[Dict[str, str]]:
        """
        è·å–æ¨èçš„LLMæä¾›å•†ï¼ˆä¼˜å…ˆDashscopeï¼‰
        
        Returns:
            æ¨èçš„æä¾›å•†ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        providers = LLMProviderChecker.get_available_providers()
        
        # ä¼˜å…ˆè¿”å›å·²é…ç½®çš„æ¨èæä¾›å•†
        for provider in providers:
            if provider['recommended'] and provider['configured']:
                return provider
        
        # å¦‚æœæ²¡æœ‰æ¨èæä¾›å•†ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå·²é…ç½®çš„
        for provider in providers:
            if provider['configured']:
                return provider
        
        return None
    
    @staticmethod
    def check_provider_status(provider_id: str) -> Tuple[bool, str]:
        """
        æ£€æŸ¥ç‰¹å®šæä¾›å•†çš„çŠ¶æ€
        
        Args:
            provider_id: æä¾›å•†IDï¼ˆdashscope/openai/anthropic/deepseekï¼‰
        
        Returns:
            (æ˜¯å¦å¯ç”¨, çŠ¶æ€æ¶ˆæ¯)
        """
        providers = LLMProviderChecker.get_available_providers()
        
        for provider in providers:
            if provider['id'] == provider_id:
                if provider['configured']:
                    return True, f"âœ… {provider['display_name']}: å·²é…ç½®"
                else:
                    return False, f"âŒ {provider['display_name']}: æœªé…ç½®APIå¯†é’¥"
        
        return False, f"âŒ æœªçŸ¥çš„æä¾›å•†: {provider_id}"
    
    @staticmethod
    def suggest_switch(current_provider: str, error_code: Optional[str] = None) -> Optional[Dict[str, str]]:
        """
        æ ¹æ®å½“å‰æä¾›å•†å’Œé”™è¯¯ä»£ç å»ºè®®åˆ‡æ¢åˆ°å…¶ä»–æä¾›å•†
        
        Args:
            current_provider: å½“å‰ä½¿ç”¨çš„æä¾›å•†
            error_code: é”™è¯¯ä»£ç ï¼ˆ402/401/429ç­‰ï¼‰
        
        Returns:
            å»ºè®®åˆ‡æ¢åˆ°çš„æä¾›å•†ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        # 402é”™è¯¯ï¼šä½™é¢ä¸è¶³ï¼Œå¼ºçƒˆå»ºè®®åˆ‡æ¢
        if error_code == "402" and current_provider == "openai":
            recommended = LLMProviderChecker.get_recommended_provider()
            if recommended and recommended['id'] != 'openai':
                return recommended
        
        # å…¶ä»–é”™è¯¯ï¼šä¹Ÿå»ºè®®åˆ‡æ¢åˆ°æ¨èæä¾›å•†
        if current_provider not in ["dashscope"]:
            recommended = LLMProviderChecker.get_recommended_provider()
            if recommended:
                return recommended
        
        return None
    
    @staticmethod
    def format_provider_list(providers: List[Dict[str, str]], show_all: bool = False) -> str:
        """
        æ ¼å¼åŒ–æä¾›å•†åˆ—è¡¨ç”¨äºæ˜¾ç¤º
        
        Args:
            providers: æä¾›å•†åˆ—è¡¨
            show_all: æ˜¯å¦æ˜¾ç¤ºæ‰€æœ‰æä¾›å•†ï¼ˆåŒ…æ‹¬æœªé…ç½®çš„ï¼‰
        
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æœ¬
        """
        lines = []
        for provider in providers:
            if provider['configured'] or show_all:
                status = "âœ…" if provider['configured'] else "âŒ"
                recommend = "â­æ¨è" if provider['recommended'] else ""
                lines.append(f"{status} {provider['display_name']} {recommend}")
        
        return "\n".join(lines) if lines else "æœªæ‰¾åˆ°å¯ç”¨çš„æä¾›å•†"


def get_current_provider_info() -> Dict[str, any]:
    """
    è·å–å½“å‰LLMæä¾›å•†ä¿¡æ¯ï¼ˆä»session stateï¼‰
    
    Returns:
        å½“å‰æä¾›å•†ä¿¡æ¯
    """
    try:
        import streamlit as st
        provider_id = st.session_state.get('llm_provider', 'dashscope')
        model = st.session_state.get('llm_model', 'qwen-plus-latest')
        
        return {
            'provider': provider_id,
            'model': model,
            'configured': LLMProviderChecker.check_provider_status(provider_id)[0]
        }
    except:
        return {
            'provider': 'unknown',
            'model': 'unknown',
            'configured': False
        }

