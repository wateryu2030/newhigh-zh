"""
Data Center - A-Share Basic Data
Download and manage A-share stock basic information
"""

import streamlit as st
import pandas as pd
from pathlib import Path
import subprocess
import sys
import os
import time
import re
try:
    import plotly.express as px
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼ˆå…ˆæ·»åŠ ï¼Œç¡®ä¿å¯¼å…¥è·¯å¾„æ­£ç¡®ï¼‰
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥æ•°æ®æ¸…æ´—æ¨¡å—
from web.utils.data_cleaner import safe_dataframe as clean_dataframe, clean_duplicate_columns

def safe_dataframe(df, **kwargs):
    """å®‰å…¨çš„st.dataframeåŒ…è£…å‡½æ•°ï¼Œç¡®ä¿æ²¡æœ‰é‡å¤åˆ—"""
    if df is None or df.empty:
        st.dataframe(df, **kwargs)
        return
    
    # ä½¿ç”¨æ•°æ®æ¸…æ´—æ¨¡å—æ¸…ç†DataFrame
    df_clean = clean_dataframe(df, normalize=False)
    st.dataframe(df_clean, **kwargs)

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Data Center - A-Share Basic Data",
    page_icon="ğŸ“¥",
    layout="wide"
)

# æ•°æ®è·¯å¾„ï¼ˆç”¨äºå‘åå…¼å®¹ï¼‰
DATA_PATH = project_root / "data" / "stock_basic.csv"

st.title("ğŸ“¥ Data Center - A-Share Basic Data")
st.markdown("**æ•°æ®ä¸­å¿ƒ - Aè‚¡åŸºç¡€èµ„æ–™**")  # ä¿ç•™ä¸­æ–‡æ˜¾ç¤ºæ ‡é¢˜
st.markdown("---")

# æ˜¾ç¤ºæ•°æ®æºä¿¡æ¯
st.info("ğŸ“Š **æ•°æ®æº**: BaoStockï¼ˆå…è´¹ã€ç¨³å®šã€æ— éœ€æ³¨å†Œï¼‰")

st.markdown("---")

# æ£€æŸ¥æ•°æ®åº“ï¼ˆåªä½¿ç”¨æ–°æ•°æ®åº“ï¼‰
DATA_ENGINE_DB_PATH = project_root / "data" / "stock_database.db"  # data_engineæ•°æ®åº“ï¼ˆå”¯ä¸€æ•°æ®æºï¼‰
DATA_PATH = project_root / "data" / "stock_basic.csv"  # CSVå¤‡ä»½ï¼ˆå·²åºŸå¼ƒï¼‰

data_engine_db_exists = DATA_ENGINE_DB_PATH.exists()
csv_exists = DATA_PATH.exists()

# å°è¯•ä»æ•°æ®åº“è¯»å–æ•°æ®ï¼ˆåªä½¿ç”¨æ–°æ•°æ®åº“ï¼‰
df = None
data_source = None

# è¯»å–data_engineæ•°æ®åº“ï¼ˆå”¯ä¸€æ•°æ®æºï¼‰
if data_engine_db_exists:
    try:
        import sqlite3
        conn = sqlite3.connect(str(DATA_ENGINE_DB_PATH))
        cursor = conn.cursor()
        
        # æ£€æŸ¥è¡¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [row[0] for row in cursor.fetchall()]
        
        # ä¼˜å…ˆè¯»å–stock_basic_info + èšåˆæ—¥Kæ•°æ®
        if 'stock_basic_info' in tables and 'stock_market_daily' in tables:
            # è¯»å–åŸºç¡€ä¿¡æ¯
            df_basic = pd.read_sql_query("SELECT * FROM stock_basic_info", conn)
            
            # è¯»å–æœ€æ–°çš„å¸‚åœºä»·æ ¼å’Œè´¢åŠ¡æ•°æ®
            # è·å–æœ€æ–°çš„äº¤æ˜“æ—¥æœŸ
            cursor.execute("SELECT MAX(trade_date) FROM stock_market_daily")
            latest_date = cursor.fetchone()[0]
            
            if latest_date:
                # è¯»å–å¸‚åœºæ•°æ®ï¼ˆä¸ºæ¯ä¸ªè‚¡ç¥¨è·å–æœ€æ–°æœ‰æ•°æ®çš„æ—¥æœŸï¼‰
                # ä½¿ç”¨LEFT JOINç¡®ä¿æ‰€æœ‰åŸºç¡€ä¿¡æ¯è‚¡ç¥¨éƒ½èƒ½æ˜¾ç¤ºï¼Œå³ä½¿æ²¡æœ‰å¸‚åœºæ•°æ®
                query_market = """
                    SELECT 
                        b.ts_code,
                        m.close as price,
                        m.volume,
                        m.amount as turnover,
                        m.pct_chg as change_pct,
                        m.peTTM as pe,
                        m.pbMRQ as pb,
                        m.psTTM as ps
                    FROM stock_basic_info b
                    LEFT JOIN (
                        SELECT 
                            m1.ts_code,
                            m1.close,
                            m1.volume,
                            m1.amount,
                            m1.pct_chg,
                            m1.peTTM,
                            m1.pbMRQ,
                            m1.psTTM
                        FROM stock_market_daily m1
                        INNER JOIN (
                            SELECT ts_code, MAX(trade_date) as max_date
                            FROM stock_market_daily
                            GROUP BY ts_code
                        ) latest ON m1.ts_code = latest.ts_code AND m1.trade_date = latest.max_date
                    ) m ON b.ts_code = m.ts_code
                    ORDER BY b.ts_code
                """
                df_market = pd.read_sql_query(query_market, conn)
                
                # è¯»å–è´¢åŠ¡æ•°æ®ï¼ˆä¸ºæ¯ä¸ªè‚¡ç¥¨è·å–æœ€æ–°æœ‰æ•°æ®çš„æ—¥æœŸï¼‰
                query_fin = """
                    SELECT 
                        b.ts_code,
                        f.total_mv,
                        f.circ_mv,
                        f.revenue_yoy,
                        f.net_profit_yoy,
                        f.gross_profit_margin,
                        f.roe,
                        f.roa
                    FROM stock_basic_info b
                    LEFT JOIN (
                        SELECT 
                            f1.ts_code,
                            f1.total_mv,
                            f1.circ_mv,
                            f1.revenue_yoy,
                            f1.net_profit_yoy,
                            f1.gross_profit_margin,
                            f1.roe,
                            f1.roa
                        FROM stock_financials f1
                        INNER JOIN (
                            SELECT ts_code, MAX(trade_date) as max_date
                            FROM stock_financials
                            GROUP BY ts_code
                        ) latest ON f1.ts_code = latest.ts_code AND f1.trade_date = latest.max_date
                    ) f ON b.ts_code = f.ts_code
                    ORDER BY b.ts_code
                """
                df_fin = pd.read_sql_query(query_fin, conn)
                
                # åˆå¹¶æ•°æ®ï¼šåŸºç¡€ä¿¡æ¯ + å¸‚åœºæ•°æ® + è´¢åŠ¡æ•°æ®
                # ä½¿ç”¨mergeç¡®ä¿æŒ‰ts_codeæ­£ç¡®åˆå¹¶
                df = df_basic.merge(df_market, on='ts_code', how='left')
                df = df.merge(df_fin, on='ts_code', how='left')
                df = df.rename(columns={'ts_code': 'stock_code', 'name': 'stock_name'})
                
                # ç«‹å³æ¸…ç†é‡å¤åˆ—ï¼ˆåœ¨åˆå¹¶åç«‹å³å¤„ç†ï¼Œé˜²æ­¢åç»­æ“ä½œäº§ç”Ÿé—®é¢˜ï¼‰
                df = clean_duplicate_columns(df, keep_first=False)
                
                # åŒé‡éªŒè¯ï¼šç¡®ä¿ç»å¯¹æ²¡æœ‰é‡å¤åˆ—
                if df.columns.duplicated().any():
                    unique_cols = list(dict.fromkeys(df.columns))
                    df = pd.DataFrame(df.values[:, :len(unique_cols)], columns=unique_cols)
                
                # æœ€ç»ˆç¡®ä¿ï¼šä½¿ç”¨æ•°æ®æ¸…æ´—æ¨¡å—å»é‡ï¼ˆæœ€åä¸€æ¬¡ç¡®è®¤ï¼‰
                df = clean_duplicate_columns(df, keep_first=False)
            else:
                df = df_basic.rename(columns={'ts_code': 'stock_code', 'name': 'stock_name'})
            
            conn.close()
            if df is not None and not df.empty:
                data_source = "data_engineæ•°æ®åº“"
                st.success(f"âœ… ä»data_engineæ•°æ®åº“è¯»å–: {len(df)} æ¡è®°å½•")
        elif 'stock_basic_info' in tables:
            # åªæœ‰åŸºç¡€ä¿¡æ¯
            df = pd.read_sql_query("SELECT * FROM stock_basic_info", conn)
            df = df.rename(columns={'ts_code': 'stock_code', 'name': 'stock_name'})
            conn.close()
            if df is not None and not df.empty:
                data_source = "data_engineæ•°æ®åº“(ä»…åŸºç¡€)"
                st.success(f"âœ… ä»data_engineæ•°æ®åº“è¯»å–: {len(df)} æ¡è®°å½•")
        conn.close()
    except Exception as e:
        st.warning(f"âš ï¸ è¯»å–data_engineæ•°æ®åº“å¤±è´¥: {e}")

# å¦‚æœdata_engineæ•°æ®åº“è¯»å–å¤±è´¥ï¼Œæç¤ºç”¨æˆ·ä¸‹è½½æ•°æ®
if (df is None or df.empty):
    st.warning("âš ï¸ æœªæ‰¾åˆ°æ•°æ®ï¼Œè¯·å…ˆä¸‹è½½æ•°æ®ã€‚")

# å¦‚æœæ•°æ®åº“è¯»å–å¤±è´¥ï¼Œå°è¯•ä»CSVè¯»å–
if df is None or df.empty:
    if csv_exists:
        try:
            df = pd.read_csv(DATA_PATH, encoding="utf-8-sig")
            if not df.empty:
                # ç¡®ä¿CSVæ•°æ®ä¹Ÿæ²¡æœ‰é‡å¤åˆ—ï¼ˆä½¿ç”¨æ•°æ®æ¸…æ´—æ¨¡å—ï¼‰
                df = clean_duplicate_columns(df, keep_first=False)
                data_source = "CSVæ–‡ä»¶"
                st.success(f"âœ… ä»CSVæ–‡ä»¶è¯»å–: {len(df)} æ¡è®°å½•")
            else:
                st.warning(f"âš ï¸ CSVæ–‡ä»¶å­˜åœ¨ä½†æ•°æ®ä¸ºç©º")
        except Exception as e:
            st.error(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")

# æ˜¾ç¤ºå½“å‰çŠ¶æ€
col1, col2 = st.columns([2, 1])
with col1:
    if df is not None and not df.empty:
        # æ˜¾ç¤ºæœ€åæ›´æ–°æ—¶é—´
        if 'update_time' in df.columns:
            latest_time = df['update_time'].max() if df['update_time'].notna().any() else None
            if latest_time:
                st.caption(f"ğŸ“… æœ€åæ›´æ–°æ—¶é—´: {latest_time}")
        elif csv_exists:
            import time
            mtime = os.path.getmtime(DATA_PATH)
            from datetime import datetime
            update_time = datetime.fromtimestamp(mtime).strftime("%Y-%m-%d %H:%M:%S")
            st.caption(f"ğŸ“… CSVæ–‡ä»¶æœ€åæ›´æ–°æ—¶é—´: {update_time}")
    else:
        st.info("â„¹ï¸ æœªæ£€æµ‹åˆ°æœ¬åœ°åŸºç¡€èµ„æ–™ï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹ä¸‹è½½ã€‚")

with col2:
    if st.button("ğŸ”„ åˆ·æ–°çŠ¶æ€", use_container_width=True):
        st.rerun()

st.markdown("---")

# ä¸‹è½½åŠŸèƒ½
st.subheader("ğŸ“¥ æ•°æ®ä¸‹è½½")
st.markdown("""
**ä½¿ç”¨BaoStock** è·å–å®Œæ•´çš„Aè‚¡è‚¡ç¥¨æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
- âœ… è‚¡ç¥¨ä»£ç å’Œåç§°
- âœ… æœ€æ–°ä»·æ ¼ã€æˆäº¤é‡ã€æˆäº¤é¢
- âœ… **PEã€PBã€PSç­‰è´¢åŠ¡æŒ‡æ ‡**ï¼ˆå®Œæ•´æ•°æ®ï¼‰
- âœ… 3å¹´å†å²Kçº¿æ•°æ®
- âœ… æŠ€æœ¯æŒ‡æ ‡ï¼ˆMA/RSI/MACD/KDJç­‰ï¼‰

**æ³¨æ„**: æ–°ç‰ˆæœ¬ä½¿ç”¨data_engineï¼Œæ•°æ®æ›´å®Œæ•´ä¸”æ”¯æŒå¢é‡æ›´æ–°ï¼
""")

# åªä½¿ç”¨BaoStock
data_source = "BaoStock"
st.info("âœ… ä½¿ç”¨BaoStockæ•°æ®æºï¼šå…è´¹ã€ç¨³å®šã€æ•°æ®å®Œæ•´ï¼ˆåŒ…å«PE/PB/PSç­‰è´¢åŠ¡æŒ‡æ ‡ï¼‰")

# ä½¿ç”¨data_engineè¿›è¡ŒBaoStockæ•°æ®ä¸‹è½½
script_path = project_root / "data_engine" / "update_all.py"
os.environ['USE_TUSHARE'] = 'false'
os.environ['USE_BAOSTOCK'] = 'true'

# åˆ›å»ºä¸‹è½½æŒ‰é’®
if st.button("ğŸš€ ä¸‹è½½/æ›´æ–° Aè‚¡åŸºç¡€èµ„æ–™", type="primary", use_container_width=True):
    data_source_name = data_source.replace("ï¼ˆæ¨èï¼‰", "")
    
    # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
    progress_container = st.container()
    with progress_container:
        st.markdown("### ğŸ“¥ ä¸‹è½½è¿›åº¦")
        progress_bar = st.progress(0)
        status_text = st.empty()
        log_output = st.empty()
    
    try:
        if not script_path.exists():
            st.error(f"âŒ æœªæ‰¾åˆ°ä¸‹è½½è„šæœ¬: {script_path}")
            st.stop()
        
        # ç¡®å®šæ­£ç¡®çš„Pythonå¯æ‰§è¡Œæ–‡ä»¶
        # ä¼˜å…ˆä½¿ç”¨å½“å‰Streamlitè¿›ç¨‹çš„Python
        python_exe = sys.executable
        # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•å¤šä¸ªå¯èƒ½çš„ä½ç½®
        if not os.path.exists(python_exe):
            for alt_python in [
                '/Library/Frameworks/Python.framework/Versions/3.12/bin/python3',
                '/Library/Frameworks/Python.framework/Versions/3.12/bin/python3.12',
                '/usr/local/bin/python3'
            ]:
                if os.path.exists(alt_python):
                    python_exe = alt_python
                    break
        
        # ä½¿ç”¨Popenå®æ—¶è¯»å–è¾“å‡º
        process = subprocess.Popen(
            [python_exe, str(script_path)],
            cwd=str(project_root),
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            universal_newlines=True
        )
        
        # å®æ—¶è¯»å–è¾“å‡º
        output_lines = []
        last_progress = 0
        current_status = "åˆå§‹åŒ–ä¸­..."
        
        status_text.info(f"ğŸ”„ **çŠ¶æ€**: {current_status}")
        
        for line in iter(process.stdout.readline, ''):
            if not line:
                break
            
            line = line.strip()
            if line:
                output_lines.append(line)
                
                # è§£æè¿›åº¦ä¿¡æ¯
                progress_match = re.search(r'è¿›åº¦:\s*(\d+)/(\d+)\s*\(([\d.]+)%\)', line)
                if progress_match:
                    processed = int(progress_match.group(1))
                    total = int(progress_match.group(2))
                    percentage = float(progress_match.group(3))
                    last_progress = percentage / 100.0
                    progress_bar.progress(min(last_progress, 1.0))
                    current_status = f"å·²å¤„ç† {processed}/{total} åªè‚¡ç¥¨ ({percentage:.1f}%)"
                    status_text.info(f"ğŸ”„ **çŠ¶æ€**: {current_status}")
                
                # æ›´æ–°çŠ¶æ€æ–‡æœ¬
                elif "âœ…" in line or "å®Œæˆ" in line:
                    if "è·å–åˆ°" in line and "åªè‚¡ç¥¨" in line:
                        status_text.success(f"âœ… {line}")
                    elif "ä¸‹è½½å®Œæˆ" in line or "æ•°æ®æ•´ç†å®Œæˆ" in line:
                        status_text.success(f"âœ… {line}")
                        progress_bar.progress(1.0)
                        current_status = "ä¸‹è½½å®Œæˆ"
                elif "âŒ" in line or "å¤±è´¥" in line:
                    status_text.error(f"âŒ {line}")
                elif "â³" in line:
                    status_text.info(f"â³ {line}")
                
                # æ˜¾ç¤ºæœ€åå‡ è¡Œæ—¥å¿—
                if len(output_lines) > 10:
                    log_output.text_area(
                        "ä¸‹è½½æ—¥å¿—",
                        "\n".join(output_lines[-10:]),
                        height=150,
                        disabled=True
                    )
                else:
                    log_output.text_area(
                        "ä¸‹è½½æ—¥å¿—",
                        "\n".join(output_lines),
                        height=150,
                        disabled=True
                    )
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆ
        process.wait()
        
        # è·å–æœ€ç»ˆè¾“å‡º
        final_output = "\n".join(output_lines)
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        if process.returncode == 0:
            st.success("âœ… ä¸‹è½½å®Œæˆï¼æ­£åœ¨åˆ·æ–°æ•°æ®...")
            status_text.success(f"âœ… ä¸‹è½½æˆåŠŸå®Œæˆï¼")
            progress_bar.progress(1.0)
            
            # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºæ–°æ•°æ®
            time.sleep(1)
            st.rerun()
        else:
            st.error(f"âŒ ä¸‹è½½å¤±è´¥")
            
            # åˆ†æé”™è¯¯ç±»å‹å¹¶ç»™å‡ºå‹å¥½æç¤º
            error_output = final_output
            if "proxy" in error_output.lower() or "ProxyError" in error_output:
                st.warning("ğŸ”§ **ä»£ç†é…ç½®é—®é¢˜**")
                st.info("""
                **é—®é¢˜è¯Šæ–­**: ç³»ç»Ÿæ£€æµ‹åˆ°ä»£ç†è¿æ¥é”™è¯¯
                
                **å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š**
                1. ç³»ç»Ÿå·²è‡ªåŠ¨å°è¯•ç¦ç”¨ä»£ç†ï¼Œè¯·é‡è¯•
                2. å¦‚æœä»æœ‰é—®é¢˜ï¼Œæ£€æŸ¥ç³»ç»Ÿä»£ç†è®¾ç½®ï¼š
                   - macOS: ç³»ç»Ÿè®¾ç½® â†’ ç½‘ç»œ â†’ ä»£ç†
                   - æ£€æŸ¥æ˜¯å¦æœ‰æ— æ•ˆçš„ä»£ç†é…ç½®
                3. ä¸´æ—¶ç¦ç”¨ä»£ç†ç¯å¢ƒå˜é‡ï¼š
                   ```bash
                   unset HTTP_PROXY
                   unset HTTPS_PROXY
                   unset http_proxy
                   unset https_proxy
                   ```
                4. å¦‚æœç¡®å®éœ€è¦ä»£ç†ï¼Œè¯·ç¡®ä¿ä»£ç†æœåŠ¡å™¨æ­£å¸¸è¿è¡Œ
                """)
                st.success("ğŸ’¡ **æç¤º**: ä¸‹è½½è„šæœ¬å·²è‡ªåŠ¨ç¦ç”¨ä»£ç†ï¼Œè¯·ç‚¹å‡»æŒ‰é’®é‡è¯•")
            elif "connection" in error_output.lower() or "Connection" in error_output:
                st.warning("ğŸŒ **ç½‘ç»œè¿æ¥é—®é¢˜**")
                st.info("""
                **å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š**
                1. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š
                2. æ£€æŸ¥æ˜¯å¦éœ€è¦é…ç½®ä»£ç†/VPN
                3. ç¨åé‡è¯•ï¼ˆæ•°æ®æºæœåŠ¡å™¨å¯èƒ½ä¸´æ—¶ä¸å¯ç”¨ï¼‰
                4. å°è¯•åœ¨ç½‘ç»œè¾ƒå¥½çš„ç¯å¢ƒä¸‹é‡è¯•
                """)
            elif "timeout" in error_output.lower():
                st.warning("â±ï¸ **è¯·æ±‚è¶…æ—¶**")
                st.info("""
                **å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š**
                1. æ•°æ®æºæœåŠ¡å™¨å“åº”è¾ƒæ…¢ï¼Œè¯·ç¨åé‡è¯•
                2. æ£€æŸ¥ç½‘ç»œè¿æ¥é€Ÿåº¦
                3. å¦‚æœæ˜¯é¦–æ¬¡ä¸‹è½½ï¼Œæ•°æ®é‡è¾ƒå¤§ï¼Œå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
                """)
            elif "rate limit" in error_output.lower() or "é¢‘ç‡" in error_output:
                st.warning("ğŸš¦ **è¯·æ±‚é¢‘ç‡è¿‡é«˜**")
                st.info("""
                **å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š**
                1. ç­‰å¾… 1-2 åˆ†é’Ÿåé‡è¯•
                2. æ•°æ®æºå¯èƒ½æœ‰è®¿é—®é¢‘ç‡é™åˆ¶
                """)
            elif "token" in error_output.lower() or "æƒé™" in error_output.lower() or "ç§¯åˆ†" in error_output.lower():
                st.warning("ğŸ”‘ **æ•°æ®æºæƒé™é—®é¢˜**")
                st.info("""
                **é—®é¢˜åˆ†æ**: æ•°æ®æºå¯èƒ½æœ‰é™åˆ¶æˆ–ç½‘ç»œé—®é¢˜
                
                **è§£å†³æ–¹æ¡ˆï¼š**
                1. **æ£€æŸ¥ç½‘ç»œè¿æ¥**: ç¡®ä¿èƒ½è®¿é—®BaoStockæ•°æ®æº
                2. **ç¨åé‡è¯•**: å¯èƒ½æ˜¯ä¸´æ—¶ç½‘ç»œé—®é¢˜
                3. **æŸ¥çœ‹æ—¥å¿—**: ç‚¹å‡»ä¸‹æ–¹å±•å¼€æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
                
                **æ³¨æ„**: BaoStockæ˜¯å…è´¹æ•°æ®æºï¼Œé€šå¸¸ä¸éœ€è¦ç‰¹æ®Šæƒé™
                """)
            
            # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼ˆå¯æŠ˜å ï¼‰
            with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                st.code(error_output, language="bash")
                
    except subprocess.TimeoutExpired:
        st.error("âŒ ä¸‹è½½è¶…æ—¶ï¼ˆè¶…è¿‡5åˆ†é’Ÿï¼‰ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
    except Exception as e:
        st.error(f"âŒ ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        st.code(traceback.format_exc(), language="python")

st.markdown("---")

# æ•°æ®å±•ç¤ºï¼ˆå³ä½¿æ•°æ®ä¸å®Œæ•´ä¹Ÿæ˜¾ç¤ºï¼Œè‡³å°‘æ˜¾ç¤ºä»£ç å’Œåç§°ï¼‰
# æ·»åŠ è°ƒè¯•ä¿¡æ¯
if 'df' not in locals():
    df = None

if df is not None and not df.empty:
    # ç¡®ä¿dfæœ¬èº«æ²¡æœ‰é‡å¤åˆ—ï¼ˆåœ¨æ˜¾ç¤ºå‰å†æ¬¡æ£€æŸ¥ï¼Œä½¿ç”¨æ•°æ®æ¸…æ´—æ¨¡å—ï¼‰
    df = clean_duplicate_columns(df, keep_first=False)
    
    st.subheader("ğŸ“Š å®Œæ•´æ•°æ®åˆ—è¡¨")
    st.info(f"ğŸ’¡ å…± {len(df)} æ¡è‚¡ç¥¨æ•°æ®ï¼Œä»¥ä¸‹ä¸ºå®Œæ•´åˆ—è¡¨ï¼ˆå¯æ»šåŠ¨æŸ¥çœ‹ï¼‰")
    
    try:
        # ä½¿ç”¨ä¹‹å‰è¯»å–çš„dfï¼ˆæ¥è‡ªæ•°æ®åº“æˆ–CSVï¼‰ï¼Œä¸å†é‡æ–°è¯»å–
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»è®°å½•æ•°", len(df))
        with col2:
            code_col = 'stock_code' if 'stock_code' in df.columns else 'code'
            if code_col in df.columns:
                st.metric("è‚¡ç¥¨ä»£ç æ•°", df[code_col].nunique())
        with col3:
            if "price" in df.columns:
                avg_price = df["price"].mean()
                st.metric("å¹³å‡ä»·æ ¼", f"ï¿¥{avg_price:.2f}" if not pd.isna(avg_price) else "N/A")
        with col4:
            if "total_mv" in df.columns:
                total_mcap = df["total_mv"].sum() / 1e12 if df["total_mv"].notna().any() else 0  # è½¬æ¢ä¸ºä¸‡äº¿å…ƒ
                st.metric("æ€»å¸‚å€¼", f"{total_mcap:.2f}ä¸‡äº¿" if total_mcap > 0 else "N/A")
        
        # ========== è‚¡ç¥¨ç­›é€‰åŠŸèƒ½ ==========
        st.markdown("---")
        st.subheader("ğŸ” ç»¼åˆè‚¡ç¥¨ç­›é€‰")
        
        # ç­›é€‰æ¨¡å¼é€‰æ‹©
        filter_mode = st.radio(
            "ç­›é€‰æ¨¡å¼",
            ["ğŸ“Š å¿«é€Ÿç­›é€‰", "ğŸ¯ é«˜çº§ç­›é€‰", "ğŸ“‹ é¢„è®¾æ¨¡æ¿"],
            horizontal=True,
            key="filter_mode"
        )
        
        if filter_mode == "ğŸ“‹ é¢„è®¾æ¨¡æ¿":
            # é¢„è®¾æ¨¡æ¿ç­›é€‰
            template_col1, template_col2 = st.columns([2, 1])
            with template_col1:
                template = st.selectbox(
                    "é€‰æ‹©é¢„è®¾æ¨¡æ¿",
                    [
                        "å…¨éƒ¨è‚¡ç¥¨",
                        "ğŸ’° ä»·å€¼è‚¡ï¼ˆä½PEä½PBï¼‰",
                        "ğŸš€ æˆé•¿è‚¡ï¼ˆé«˜ROEé«˜å¢é•¿ï¼‰",
                        "ğŸ’ ä¼˜è´¨è‚¡ï¼ˆROE>15%ï¼ŒPE<30ï¼‰",
                        "ğŸ“ˆ å°ç›˜è‚¡ï¼ˆå¸‚å€¼<100äº¿ï¼‰",
                        "ğŸ¢ å¤§ç›˜è‚¡ï¼ˆå¸‚å€¼>500äº¿ï¼‰",
                        "ğŸ’¹ æ´»è·ƒè‚¡ï¼ˆæ¢æ‰‹ç‡>3%ï¼‰",
                        "ğŸ“Š ä½æ³¢åŠ¨è‚¡ï¼ˆæ³¢åŠ¨ç‡<20%ï¼‰",
                        "ğŸ¯ é«˜è‚¡æ¯è‚¡ï¼ˆPB<2ï¼ŒROE>10%ï¼‰",
                        "ğŸ”¥ çƒ­é—¨è‚¡ï¼ˆæ¶¨å¹…>5%ï¼‰"
                    ],
                    key="template_selector"
                )
            with template_col2:
                st.markdown("<br>", unsafe_allow_html=True)
                if st.button("åº”ç”¨æ¨¡æ¿", use_container_width=True, type="primary"):
                    st.session_state.apply_template = True
            
            # åº”ç”¨é¢„è®¾æ¨¡æ¿
            if st.session_state.get("apply_template", False):
                display_df = df.copy()
                display_df = clean_duplicate_columns(display_df, keep_first=False)
                
                if template == "ğŸ’° ä»·å€¼è‚¡ï¼ˆä½PEä½PBï¼‰":
                    if 'pe' in display_df.columns:
                        display_df = display_df[(display_df['pe'] > 0) & (display_df['pe'] < 20)]
                    if 'pb' in display_df.columns:
                        display_df = display_df[(display_df['pb'] > 0) & (display_df['pb'] < 2)]
                elif template == "ğŸš€ æˆé•¿è‚¡ï¼ˆé«˜ROEé«˜å¢é•¿ï¼‰":
                    if 'roe' in display_df.columns:
                        display_df = display_df[(display_df['roe'] > 15)]
                    if 'revenue_yoy' in display_df.columns:
                        display_df = display_df[(display_df['revenue_yoy'] > 20)]
                elif template == "ğŸ’ ä¼˜è´¨è‚¡ï¼ˆROE>15%ï¼ŒPE<30ï¼‰":
                    if 'roe' in display_df.columns:
                        display_df = display_df[(display_df['roe'] > 15)]
                    if 'pe' in display_df.columns:
                        display_df = display_df[(display_df['pe'] > 0) & (display_df['pe'] < 30)]
                elif template == "ğŸ“ˆ å°ç›˜è‚¡ï¼ˆå¸‚å€¼<100äº¿ï¼‰":
                    if 'total_mv' in display_df.columns:
                        display_df = display_df[(display_df['total_mv'] / 1e8 < 100)]
                elif template == "ğŸ¢ å¤§ç›˜è‚¡ï¼ˆå¸‚å€¼>500äº¿ï¼‰":
                    if 'total_mv' in display_df.columns:
                        display_df = display_df[(display_df['total_mv'] / 1e8 > 500)]
                elif template == "ğŸ’¹ æ´»è·ƒè‚¡ï¼ˆæ¢æ‰‹ç‡>3%ï¼‰":
                    if 'turnover_rate' in display_df.columns:
                        display_df = display_df[(display_df['turnover_rate'] > 3)]
                elif template == "ğŸ“Š ä½æ³¢åŠ¨è‚¡ï¼ˆæ³¢åŠ¨ç‡<20%ï¼‰":
                    if 'amplitude' in display_df.columns:
                        display_df = display_df[(display_df['amplitude'] < 20)]
                elif template == "ğŸ¯ é«˜è‚¡æ¯è‚¡ï¼ˆPB<2ï¼ŒROE>10%ï¼‰":
                    if 'pb' in display_df.columns:
                        display_df = display_df[(display_df['pb'] > 0) & (display_df['pb'] < 2)]
                    if 'roe' in display_df.columns:
                        display_df = display_df[(display_df['roe'] > 10)]
                elif template == "ğŸ”¥ çƒ­é—¨è‚¡ï¼ˆæ¶¨å¹…>5%ï¼‰":
                    if 'change_pct' in display_df.columns:
                        display_df = display_df[(display_df['change_pct'] > 5)]
                
                st.session_state.apply_template = False
                st.success(f"âœ… åº”ç”¨æ¨¡æ¿ã€Œ{template}ã€ï¼Œæ‰¾åˆ° {len(display_df)} åªè‚¡ç¥¨")
        elif filter_mode == "ğŸ“Š å¿«é€Ÿç­›é€‰":
            # å¿«é€Ÿç­›é€‰æ¨¡å¼ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
            with st.expander("ğŸ“Š ç­›é€‰æ¡ä»¶", expanded=True):
                st.info("ğŸ’¡ å¿«é€Ÿç­›é€‰æ¨¡å¼ï¼šä½¿ç”¨ç®€å•çš„æ»‘å—å’Œä¸‹æ‹‰æ¡†è¿›è¡Œç­›é€‰")
                
                filter_col1, filter_col2, filter_col3 = st.columns(3)
            
            # å¸‚å€¼ç­›é€‰ï¼ˆæ³¨æ„ï¼šBaoStockä¸æä¾›å¸‚å€¼æ•°æ®ï¼Œæ­¤åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼‰
            with filter_col1:
                st.markdown("**ğŸ’° æ€»å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰**")
                has_mv = 'total_mv' in df.columns and df['total_mv'].notna().any()
                if not has_mv:
                    st.info("âš ï¸ å¸‚å€¼æ•°æ®æš‚ä¸å¯ç”¨ï¼ˆBaoStockä¸æä¾›ï¼‰ï¼Œç­›é€‰å°†è·³è¿‡å¸‚å€¼æ¡ä»¶")
                if has_mv:
                    mv_min = float(df['total_mv'].min() / 1e8) if df['total_mv'].notna().any() else 0
                    mv_max = float(df['total_mv'].max() / 1e8) if df['total_mv'].notna().any() else 10000
                    mv_range = st.slider(
                        "å¸‚å€¼èŒƒå›´",
                        min_value=0.0,
                        max_value=float(mv_max),
                        value=(0.0, float(mv_max)),
                        step=10.0,
                        key="mv_filter",
                        label_visibility="collapsed"
                    )
                else:
                    st.info("å¸‚å€¼æ•°æ®ä¸å¯ç”¨")
                    mv_range = (0.0, 10000.0)
            
            # å¸‚ç›ˆç‡ç­›é€‰
            with filter_col2:
                st.markdown("**ğŸ“ˆ å¸‚ç›ˆç‡ï¼ˆPEï¼‰**")
                has_pe = 'pe' in df.columns and df['pe'].notna().any()
                if has_pe:
                    pe_min = float(df['pe'].min()) if df['pe'].notna().any() else 0
                    pe_max = float(df['pe'].max()) if df['pe'].notna().any() else 100
                    pe_range = st.slider(
                        "PEèŒƒå›´",
                        min_value=0.0,
                        max_value=float(pe_max),
                        value=(0.0, float(pe_max)),
                        step=1.0,
                        key="pe_filter",
                        label_visibility="collapsed"
                    )
                else:
                    st.info("PEæ•°æ®ä¸å¯ç”¨")
                    pe_range = (0.0, 100.0)
            
            # å¸‚å‡€ç‡ç­›é€‰
            with filter_col3:
                st.markdown("**ğŸ“Š å¸‚å‡€ç‡ï¼ˆPBï¼‰**")
                has_pb = 'pb' in df.columns and df['pb'].notna().any()
                if has_pb:
                    pb_min = float(df['pb'].min()) if df['pb'].notna().any() else 0
                    pb_max = float(df['pb'].max()) if df['pb'].notna().any() else 10
                    pb_range = st.slider(
                        "PBèŒƒå›´",
                        min_value=0.0,
                        max_value=float(pb_max),
                        value=(0.0, float(pb_max)),
                        step=0.1,
                        key="pb_filter",
                        label_visibility="collapsed"
                    )
                else:
                    st.info("PBæ•°æ®ä¸å¯ç”¨")
                    pb_range = (0.0, 10.0)
            
            # ä»·æ ¼ç­›é€‰
            filter_col4, filter_col5 = st.columns(2)
            with filter_col4:
                st.markdown("**ğŸ’µ ä»·æ ¼ï¼ˆå…ƒï¼‰**")
                has_price = 'price' in df.columns and df['price'].notna().any()
                if has_price:
                    price_min = float(df['price'].min()) if df['price'].notna().any() else 0
                    price_max = float(df['price'].max()) if df['price'].notna().any() else 500
                    price_range = st.slider(
                        "ä»·æ ¼èŒƒå›´",
                        min_value=0.0,
                        max_value=float(price_max),
                        value=(0.0, float(price_max)),
                        step=1.0,
                        key="price_filter",
                        label_visibility="collapsed"
                    )
                else:
                    price_range = (0.0, 500.0)
            
            with filter_col5:
                st.markdown("**ğŸ“Š è¡Œä¸šç­›é€‰**")
                if 'industry' in df.columns:
                    industries = ['å…¨éƒ¨'] + sorted([str(x) for x in df['industry'].dropna().unique() if pd.notna(x)])
                    selected_industry = st.selectbox(
                        "é€‰æ‹©è¡Œä¸š",
                        industries,
                        key="industry_filter",
                        label_visibility="collapsed"
                    )
                else:
                    selected_industry = 'å…¨éƒ¨'
            
            # åº”ç”¨å¿«é€Ÿç­›é€‰
            display_df = df.copy()
            display_df = clean_duplicate_columns(display_df, keep_first=False)
            
            # å¸‚å€¼ç­›é€‰
            if has_mv and 'total_mv' in display_df.columns and display_df['total_mv'].notna().any():
                display_df = display_df[
                    (display_df['total_mv'] / 1e8 >= mv_range[0]) &
                    (display_df['total_mv'] / 1e8 <= mv_range[1])
                ]
            
            # PEç­›é€‰
            if has_pe and 'pe' in display_df.columns:
                display_df = display_df[
                    ((display_df['pe'] >= pe_range[0]) & (display_df['pe'] <= pe_range[1])) |
                    (display_df['pe'].isna())
                ]
            
            # PBç­›é€‰
            if has_pb and 'pb' in display_df.columns:
                display_df = display_df[
                    ((display_df['pb'] >= pb_range[0]) & (display_df['pb'] <= pb_range[1])) |
                    (display_df['pb'].isna())
                ]
            
            # ä»·æ ¼ç­›é€‰
            if has_price and 'price' in display_df.columns:
                display_df = display_df[
                    ((display_df['price'] >= price_range[0]) & (display_df['price'] <= price_range[1])) |
                    (display_df['price'].isna())
                ]
            
            # è¡Œä¸šç­›é€‰
            if selected_industry != 'å…¨éƒ¨' and 'industry' in display_df.columns:
                display_df = display_df[display_df['industry'] == selected_industry]
            
            display_df = clean_duplicate_columns(display_df, keep_first=False)
            st.success(f"âœ… å¿«é€Ÿç­›é€‰ç»“æœ: æ‰¾åˆ° {len(display_df)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼ˆå…± {len(df)} åªï¼‰")
        
        # å¦‚æœdisplay_dfæœªå®šä¹‰ï¼Œä½¿ç”¨åŸå§‹df
        if 'display_df' not in locals():
            display_df = df.copy()
            display_df = clean_duplicate_columns(display_df, keep_first=False)
        
        # æ‰€æœ‰ç­›é€‰æ“ä½œå®Œæˆåï¼Œå†æ¬¡å»é‡ï¼ˆé˜²æ­¢ç­›é€‰è¿‡ç¨‹ä¸­äº§ç”Ÿé‡å¤åˆ—ï¼‰
        display_df = clean_duplicate_columns(display_df, keep_first=False)
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•ç­›é€‰ç»“æœï¼Œæ˜¾ç¤ºæç¤º
        if len(display_df) == 0:
            st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œè¯·è°ƒæ•´ç­›é€‰æ¡ä»¶")
            st.stop()
        
        # ========== å¯è§†åŒ–å±•ç¤º ==========
        if len(display_df) > 0:
            # åœ¨å¯è§†åŒ–å‰ç¡®ä¿display_dfæ²¡æœ‰é‡å¤åˆ—
            display_df = clean_duplicate_columns(display_df, keep_first=False)
            
            st.markdown("---")
            st.subheader("ğŸ“Š æ•°æ®å¯è§†åŒ–")
            
            viz_tab1, viz_tab2, viz_tab3 = st.tabs(["ğŸ“ˆ PE/PBåˆ†å¸ƒ", "ğŸ’° å¸‚å€¼åˆ†å¸ƒ", "ğŸ’µ ä»·æ ¼åˆ†å¸ƒ"])
            
            with viz_tab1:
                if has_pe and has_pb:
                    if PLOTLY_AVAILABLE:
                        # ç¡®ä¿ä¼ é€’ç»™Plotlyçš„DataFrameæ²¡æœ‰é‡å¤åˆ—
                        plot_df = display_df.dropna(subset=['pe', 'pb']).copy()
                        plot_df = clean_duplicate_columns(plot_df, keep_first=False)
                        
                        # åŒé‡éªŒè¯ï¼šç¡®ä¿ç»å¯¹æ²¡æœ‰é‡å¤åˆ—ï¼ˆåœ¨ä¼ é€’ç»™Plotlyä¹‹å‰ï¼‰
                        if plot_df.columns.duplicated().any():
                            unique_cols = list(dict.fromkeys(plot_df.columns))
                            plot_df = pd.DataFrame(plot_df.values[:, :len(unique_cols)], columns=unique_cols)
                        
                        fig = px.scatter(
                            plot_df,
                            x='pe',
                            y='pb',
                            hover_data=['stock_code', 'stock_name', 'price'],
                            labels={'pe': 'å¸‚ç›ˆç‡ (PE)', 'pb': 'å¸‚å‡€ç‡ (PB)'},
                            title='PE vs PB æ•£ç‚¹å›¾'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.scatter_chart(display_df[['pe', 'pb']].dropna(), x='pe', y='pb')
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        if PLOTLY_AVAILABLE:
                            # ç¡®ä¿ä¼ é€’ç»™Plotlyçš„DataFrameæ²¡æœ‰é‡å¤åˆ—
                            plot_df_pe = display_df.dropna(subset=['pe']).copy()
                            plot_df_pe = clean_duplicate_columns(plot_df_pe, keep_first=False)
                            
                            # åŒé‡éªŒè¯ï¼šç¡®ä¿ç»å¯¹æ²¡æœ‰é‡å¤åˆ—ï¼ˆåœ¨ä¼ é€’ç»™Plotlyä¹‹å‰ï¼‰
                            if plot_df_pe.columns.duplicated().any():
                                unique_cols = list(dict.fromkeys(plot_df_pe.columns))
                                plot_df_pe = pd.DataFrame(plot_df_pe.values[:, :len(unique_cols)], columns=unique_cols)
                            
                            fig_pe = px.histogram(plot_df_pe, x='pe', nbins=30, title='PEåˆ†å¸ƒç›´æ–¹å›¾')
                            st.plotly_chart(fig_pe, use_container_width=True)
                        else:
                            st.bar_chart(display_df['pe'].value_counts().head(20))
                    
                    with col2:
                        if PLOTLY_AVAILABLE:
                            # ç¡®ä¿ä¼ é€’ç»™Plotlyçš„DataFrameæ²¡æœ‰é‡å¤åˆ—
                            plot_df_pb = display_df.dropna(subset=['pb']).copy()
                            plot_df_pb = clean_duplicate_columns(plot_df_pb, keep_first=False)
                            
                            # åŒé‡éªŒè¯ï¼šç¡®ä¿ç»å¯¹æ²¡æœ‰é‡å¤åˆ—ï¼ˆåœ¨ä¼ é€’ç»™Plotlyä¹‹å‰ï¼‰
                            if plot_df_pb.columns.duplicated().any():
                                unique_cols = list(dict.fromkeys(plot_df_pb.columns))
                                plot_df_pb = pd.DataFrame(plot_df_pb.values[:, :len(unique_cols)], columns=unique_cols)
                            
                            fig_pb = px.histogram(plot_df_pb, x='pb', nbins=30, title='PBåˆ†å¸ƒç›´æ–¹å›¾')
                            st.plotly_chart(fig_pb, use_container_width=True)
                        else:
                            st.bar_chart(display_df['pb'].value_counts().head(20))
                else:
                    st.info("PEæˆ–PBæ•°æ®ä¸è¶³ï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨")
            
            with viz_tab2:
                if has_mv and 'total_mv' in display_df.columns and display_df['total_mv'].notna().any():
                    mv_data = display_df.dropna(subset=['total_mv']).copy()
                    # ç¡®ä¿æ²¡æœ‰é‡å¤åˆ—ï¼ˆåœ¨dropnaåç«‹å³æ¸…ç†ï¼‰
                    mv_data = clean_duplicate_columns(mv_data, keep_first=False)
                    
                    # åŒé‡éªŒè¯ï¼šç¡®ä¿ç»å¯¹æ²¡æœ‰é‡å¤åˆ—
                    if mv_data.columns.duplicated().any():
                        unique_cols = list(dict.fromkeys(mv_data.columns))
                        mv_data = pd.DataFrame(mv_data.values[:, :len(unique_cols)], columns=unique_cols)
                    
                    mv_data['total_mv_billion'] = mv_data['total_mv'] / 1e8
                    top_mv = mv_data.nlargest(20, 'total_mv_billion')
                    
                    # å†æ¬¡éªŒè¯ï¼šç¡®ä¿nlargeståæ²¡æœ‰é‡å¤åˆ—
                    top_mv = clean_duplicate_columns(top_mv, keep_first=False)
                    
                    # æœ€ç»ˆéªŒè¯ï¼šåœ¨ä¼ é€’ç»™Plotlyä¹‹å‰ç»å¯¹ç¡®ä¿æ²¡æœ‰é‡å¤åˆ—
                    if top_mv.columns.duplicated().any():
                        unique_cols = list(dict.fromkeys(top_mv.columns))
                        top_mv = pd.DataFrame(top_mv.values[:, :len(unique_cols)], columns=unique_cols)
                    
                    # æœ€åä¸€æ¬¡å¼ºåˆ¶æ¸…ç†ï¼ˆç¡®ä¿ç»å¯¹æ²¡æœ‰é‡å¤åˆ—ï¼‰
                    top_mv = clean_duplicate_columns(top_mv, keep_first=False)
                    
                    if PLOTLY_AVAILABLE:
                        # åœ¨åˆ›å»ºå›¾è¡¨å‰å†æ¬¡éªŒè¯ï¼ˆç¡®ä¿ä¼ é€’ç»™Plotlyçš„DataFrameç»å¯¹å¹²å‡€ï¼‰
                        if top_mv.columns.duplicated().any():
                            unique_cols = list(dict.fromkeys(top_mv.columns))
                            top_mv = pd.DataFrame(top_mv.values[:, :len(unique_cols)], columns=unique_cols)
                        
                        fig_mv = px.bar(
                            top_mv,
                            x='stock_name',
                            y='total_mv_billion',
                            labels={'total_mv_billion': 'æ€»å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰', 'stock_name': 'è‚¡ç¥¨åç§°'},
                            title='å¸‚å€¼TOP20ï¼ˆäº¿å…ƒï¼‰'
                        )
                        fig_mv.update_layout(xaxis=dict(tickangle=45))
                        st.plotly_chart(fig_mv, use_container_width=True)
                    else:
                        st.bar_chart(top_mv.set_index('stock_name')['total_mv_billion'])
                else:
                    st.info("ğŸ’° å¸‚å€¼æ•°æ®æš‚ä¸å¯ç”¨ï¼ˆBaoStockä¸æä¾›å¸‚å€¼æ•°æ®ï¼‰")
                    st.info("ğŸ’¡ å¯ä»¥ä½¿ç”¨PE/PB/PSç­‰ä¼°å€¼æŒ‡æ ‡è¿›è¡Œç­›é€‰å’Œåˆ†æ")
                    
                    # æ˜¾ç¤ºä»·æ ¼åˆ†å¸ƒä½œä¸ºæ›¿ä»£
                    if 'price' in display_df.columns and display_df['price'].notna().any():
                        price_data = display_df.dropna(subset=['price']).copy()
                        # ç¡®ä¿æ²¡æœ‰é‡å¤åˆ—ï¼ˆåœ¨dropnaåç«‹å³æ¸…ç†ï¼‰
                        price_data = clean_duplicate_columns(price_data, keep_first=False)
                        
                        # åŒé‡éªŒè¯ï¼šç¡®ä¿ç»å¯¹æ²¡æœ‰é‡å¤åˆ—ï¼ˆåœ¨ä¼ é€’ç»™Plotlyä¹‹å‰ï¼‰
                        if price_data.columns.duplicated().any():
                            unique_cols = list(dict.fromkeys(price_data.columns))
                            price_data = pd.DataFrame(price_data.values[:, :len(unique_cols)], columns=unique_cols)
                        
                        price_data = price_data.nlargest(20, 'price')
                        
                        # å†æ¬¡éªŒè¯ï¼šç¡®ä¿nlargeståæ²¡æœ‰é‡å¤åˆ—
                        price_data = clean_duplicate_columns(price_data, keep_first=False)
                        
                        if PLOTLY_AVAILABLE:
                            fig_price_top = px.bar(
                                price_data,
                                x='stock_name',
                                y='price',
                                labels={'price': 'è‚¡ä»·ï¼ˆå…ƒï¼‰', 'stock_name': 'è‚¡ç¥¨åç§°'},
                                title='è‚¡ä»·TOP20ï¼ˆå…ƒï¼‰'
                            )
                            fig_price_top.update_layout(xaxis=dict(tickangle=45))
                            st.plotly_chart(fig_price_top, use_container_width=True)
            
            with viz_tab3:
                if has_price and 'price' in display_df.columns:
                    price_data = display_df.dropna(subset=['price']).copy()
                    # ç¡®ä¿æ²¡æœ‰é‡å¤åˆ—ï¼ˆåœ¨dropnaåç«‹å³æ¸…ç†ï¼‰
                    price_data = clean_duplicate_columns(price_data, keep_first=False)
                    
                    # åŒé‡éªŒè¯ï¼šç¡®ä¿ç»å¯¹æ²¡æœ‰é‡å¤åˆ—ï¼ˆåœ¨è®¿é—®columnsä¹‹å‰ï¼‰
                    if price_data.columns.duplicated().any():
                        unique_cols = list(dict.fromkeys(price_data.columns))
                        price_data = pd.DataFrame(price_data.values[:, :len(unique_cols)], columns=unique_cols)
                    
                    if PLOTLY_AVAILABLE:
                        fig_price = px.histogram(price_data, x='price', nbins=50, title='è‚¡ä»·åˆ†å¸ƒç›´æ–¹å›¾')
                        st.plotly_chart(fig_price, use_container_width=True)
                        
                        # ä»·æ ¼ä¸å¸‚å€¼å…³ç³»ï¼ˆåœ¨è®¿é—®columnså‰å†æ¬¡ç¡®ä¿æ— é‡å¤åˆ—ï¼‰
                        if price_data.columns.duplicated().any():
                            price_data = clean_duplicate_columns(price_data, keep_first=False)
                        
                        if 'total_mv' in price_data.columns:
                            price_mv = price_data.dropna(subset=['total_mv']).copy()
                            # ç¡®ä¿æ²¡æœ‰é‡å¤åˆ—ï¼ˆåœ¨dropnaåç«‹å³æ¸…ç†ï¼‰
                            price_mv = clean_duplicate_columns(price_mv, keep_first=False)
                            
                            # åŒé‡éªŒè¯ï¼šç¡®ä¿ç»å¯¹æ²¡æœ‰é‡å¤åˆ—ï¼ˆåœ¨ä¼ é€’ç»™Plotlyä¹‹å‰ï¼‰
                            if price_mv.columns.duplicated().any():
                                unique_cols = list(dict.fromkeys(price_mv.columns))
                                price_mv = pd.DataFrame(price_mv.values[:, :len(unique_cols)], columns=unique_cols)
                            
                            price_mv['total_mv_billion'] = price_mv['total_mv'] / 1e8
                            
                            # å†æ¬¡éªŒè¯ï¼šç¡®ä¿åˆ›å»ºæ–°åˆ—åæ²¡æœ‰é‡å¤åˆ—
                            price_mv = clean_duplicate_columns(price_mv, keep_first=False)
                            
                            fig_scatter = px.scatter(
                                price_mv,
                                x='price',
                                y='total_mv_billion',
                                hover_data=['stock_code', 'stock_name'],
                                labels={'price': 'è‚¡ä»·ï¼ˆå…ƒï¼‰', 'total_mv_billion': 'æ€»å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰'},
                                title='è‚¡ä»· vs å¸‚å€¼'
                            )
                            st.plotly_chart(fig_scatter, use_container_width=True)
                    else:
                        st.line_chart(price_data['price'])
                else:
                    st.info("ä»·æ ¼æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨")
        
        # æ•°æ®è¡¨æ ¼
        st.markdown("---")
        st.markdown("### ğŸ“‹ ç­›é€‰ç»“æœè¡¨æ ¼")
        
        # æœç´¢åŠŸèƒ½ï¼ˆåœ¨ç­›é€‰åçš„æ•°æ®ä¸­æœç´¢ï¼‰
        search_col1, search_col2 = st.columns([3, 1])
        with search_col1:
            search_keyword = st.text_input("ğŸ” åœ¨ç­›é€‰ç»“æœä¸­æœç´¢ï¼ˆä»£ç æˆ–åç§°ï¼‰", placeholder="ä¾‹å¦‚: 000001 æˆ– å¹³å®‰", value="")
        with search_col2:
            st.markdown("<br>", unsafe_allow_html=True)  # å ä½ç¬¦
        
        # åœ¨ç­›é€‰åçš„æ•°æ®ä¸­è¿›ä¸€æ­¥æœç´¢
        if search_keyword:
            code_col = 'stock_code' if 'stock_code' in display_df.columns else 'code'
            name_col = 'stock_name' if 'stock_name' in display_df.columns else 'name'
            mask = (
                display_df[code_col].astype(str).str.contains(search_keyword, case=False, na=False) |
                display_df[name_col].astype(str).str.contains(search_keyword, case=False, na=False)
            )
            display_df = display_df[mask]
            # æœç´¢åå†æ¬¡å»é‡ï¼ˆä½¿ç”¨æ•°æ®æ¸…æ´—æ¨¡å—ï¼‰
            display_df = clean_duplicate_columns(display_df, keep_first=False)
            st.info(f"ğŸ” æœç´¢åæ‰¾åˆ° {len(display_df)} æ¡åŒ¹é…è®°å½•")
        
        # æ˜¾ç¤ºæ•°æ®å®Œæ•´æ€§æç¤º
        code_col = 'stock_code' if 'stock_code' in display_df.columns else 'code'
        has_price = 'price' in display_df.columns and display_df['price'].notna().any()
        has_pe = 'pe' in display_df.columns and display_df['pe'].notna().any()
        has_pb = 'pb' in display_df.columns and display_df['pb'].notna().any()
        
        if not has_price or not has_pe or not has_pb:
            st.warning(f"""
            âš ï¸ **æ•°æ®ä¸å®Œæ•´æç¤º**:
            - ä»·æ ¼æ•°æ®: {'âœ…' if has_price else 'âŒ ç¼ºå¤±'}
            - PEæ•°æ®: {'âœ…' if has_pe else 'âŒ ç¼ºå¤±'}
            - PBæ•°æ®: {'âœ…' if has_pb else 'âŒ ç¼ºå¤±'}
            
            ğŸ’¡ **å»ºè®®**: é‡æ–°ç‚¹å‡»ã€Œä¸‹è½½/æ›´æ–° Aè‚¡åŸºç¡€èµ„æ–™ã€æŒ‰é’®ï¼Œç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®šã€‚
            """)
        
        # æ˜¾ç¤ºæ•°æ®ï¼ˆç¡®ä¿è‡³å°‘æ˜¾ç¤ºä»£ç å’Œåç§°ï¼‰
        # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—ï¼ˆä¼˜å…ˆæ˜¾ç¤ºæœ‰æ•°æ®çš„åˆ—ï¼‰
        
        # ç¡®ä¿display_dfæ²¡æœ‰é‡å¤åˆ—ï¼ˆä¸€æ¬¡æ€§å¤„ç†ï¼Œé¿å…é‡å¤æ£€æŸ¥ï¼Œä½¿ç”¨æ•°æ®æ¸…æ´—æ¨¡å—ï¼‰
        display_df = clean_duplicate_columns(display_df, keep_first=False)
        
        # å†æ¬¡éªŒè¯ï¼šç¡®ä¿ç»å¯¹æ²¡æœ‰é‡å¤åˆ—ï¼ˆåœ¨è®¿é—®columnsä¹‹å‰ï¼‰
        if display_df.columns.duplicated().any():
            unique_cols = list(dict.fromkeys(display_df.columns))
            display_df = pd.DataFrame(display_df.values[:, :len(unique_cols)], columns=unique_cols)
        
        display_columns = []
        
        # å¿…é¡»æ˜¾ç¤ºçš„åˆ—
        code_col = 'stock_code' if 'stock_code' in display_df.columns else 'code'
        name_col = 'stock_name' if 'stock_name' in display_df.columns else 'name'
        
        if code_col in display_df.columns:
            display_columns.append(code_col)
        if name_col in display_df.columns:
            display_columns.append(name_col)
        
        # å¯é€‰æ˜¾ç¤ºçš„åˆ—ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
        optional_cols = ['price', 'pe', 'pb', 'ps', 'total_mv', 'circ_mv', 'volume', 'turnover', 
                        'change_pct', 'industry', 'area', 'market', 
                        'list_date', 'update_time']
        
        for col in optional_cols:
            if col in display_df.columns:
                # å¦‚æœæœ‰æ•°æ®å°±æ˜¾ç¤ºï¼ˆè‡³å°‘æœ‰ä¸€æ¡éç©ºï¼‰
                if display_df[col].notna().any() or col in ['industry', 'area', 'market', 'list_date', 'update_time']:
                    display_columns.append(col)
        
        # å¦‚æœdisplay_columnsä¸ºç©ºï¼Œæ˜¾ç¤ºæ‰€æœ‰åˆ—
        if not display_columns:
            display_columns = list(display_df.columns)
        
        # å»é™¤é‡å¤åˆ—ï¼ˆä¿æŒé¡ºåºï¼‰
        display_columns = list(dict.fromkeys(display_columns))
        
        # åªé€‰æ‹©å­˜åœ¨çš„åˆ—
        display_columns = [col for col in display_columns if col in display_df.columns]
        
        # åˆ›å»ºæœ€ç»ˆçš„æ•°æ®æ¡†ï¼ˆç¡®ä¿æ²¡æœ‰é‡å¤åˆ—ï¼‰
        # å…ˆç¡®ä¿display_dfæœ¬èº«æ²¡æœ‰é‡å¤åˆ—
        display_df = clean_duplicate_columns(display_df, keep_first=False)
        
        # ç„¶ååˆ›å»ºfinal_df
        final_df = display_df[display_columns] if display_columns else display_df
        
        # æœ€ç»ˆç¡®ä¿æ²¡æœ‰é‡å¤åˆ—ï¼ˆä½¿ç”¨æ•°æ®æ¸…æ´—æ¨¡å—ï¼‰
        final_df = clean_duplicate_columns(final_df, keep_first=False)
        
        # æ˜¾ç¤ºå®Œæ•´æ•°æ®åˆ—è¡¨ï¼ˆç§»é™¤headé™åˆ¶ï¼Œæ˜¾ç¤ºå…¨éƒ¨ï¼‰
        safe_dataframe(
            final_df,
            use_container_width=True,
            height=600,  # è®¾ç½®å›ºå®šé«˜åº¦ï¼Œæ”¯æŒæ»šåŠ¨
            hide_index=True
        )
        
        # æ•°æ®ç»Ÿè®¡
        with st.expander("ğŸ“ˆ æ•°æ®ç»Ÿè®¡ä¿¡æ¯"):
            # ç¡®ä¿ç»Ÿè®¡æ—¶ä¹Ÿæ²¡æœ‰é‡å¤åˆ—ï¼ˆä½¿ç”¨æ•°æ®æ¸…æ´—æ¨¡å—ï¼‰
            stats_df = clean_duplicate_columns(display_df, keep_first=False)
            safe_dataframe(stats_df.describe(), use_container_width=True)
        
        # å¯¼å‡ºåŠŸèƒ½
        st.markdown("---")
        st.subheader("ğŸ’¾ æ•°æ®å¯¼å‡º")
        
        col1, col2 = st.columns(2)
        with col1:
            # ç¡®ä¿å¯¼å‡ºæ—¶ä¹Ÿæ²¡æœ‰é‡å¤åˆ—ï¼ˆä½¿ç”¨æ•°æ®æ¸…æ´—æ¨¡å—ï¼‰
            export_df = display_df[display_columns] if display_columns else display_df
            export_df = clean_duplicate_columns(export_df, keep_first=False)
            csv_data = export_df.to_csv(index=False, encoding="utf-8-sig")
            st.download_button(
                "ğŸ“¥ å¯¼å‡ºä¸º CSV",
                csv_data.encode("utf-8-sig"),
                file_name=f"stock_basic_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
        with col2:
            if st.button("ğŸ—‘ï¸ åˆ é™¤æ•°æ®åº“æ•°æ®", use_container_width=True):
                if st.session_state.get("confirm_delete"):
                    try:
                        # åˆ é™¤data_engineæ•°æ®åº“
                        if DATA_ENGINE_DB_PATH.exists():
                            DATA_ENGINE_DB_PATH.unlink()
                        # åŒæ—¶åˆ é™¤CSVå¤‡ä»½ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        if DATA_PATH.exists():
                            DATA_PATH.unlink()
                        st.success("âœ… æ•°æ®å·²åˆ é™¤ï¼ˆdata_engineæ•°æ®åº“å’ŒCSVå¤‡ä»½ï¼‰")
                        st.session_state.confirm_delete = False
                        st.rerun()
                    except Exception as e:
                        st.error(f"âŒ åˆ é™¤å¤±è´¥: {e}")
                else:
                    st.session_state.confirm_delete = True
                    st.warning("âš ï¸ ç¡®è®¤åˆ é™¤æ•°æ®åº“å’ŒCSVï¼Ÿè¯·å†æ¬¡ç‚¹å‡»æŒ‰é’®")

    except Exception as e:
        st.error(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
        import traceback
        st.code(traceback.format_exc(), language="python")

else:
    st.info("""
    ğŸ’¡ **ä½¿ç”¨è¯´æ˜**:
    1. ç‚¹å‡»ä¸Šæ–¹ã€Œä¸‹è½½/æ›´æ–° Aè‚¡åŸºç¡€èµ„æ–™ã€æŒ‰é’®
    2. ç­‰å¾…ä¸‹è½½å®Œæˆï¼ˆçº¦1-3åˆ†é’Ÿï¼‰
    3. ä¸‹è½½å®Œæˆåå³å¯æŸ¥çœ‹å’Œå¯¼å‡ºæ•°æ®
    
    âš ï¸ **æ³¨æ„äº‹é¡¹**:
    - æ•°æ®æ¥æºäºBaoStockï¼Œéœ€è¦ç¨³å®šçš„ç½‘ç»œè¿æ¥
    - å»ºè®®æ¯æ—¥æ›´æ–°ä¸€æ¬¡æ•°æ®ä»¥è·å–æœ€æ–°ä¿¡æ¯
    - é¦–æ¬¡ä¸‹è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼ˆçº¦10-15åˆ†é’Ÿï¼‰
    """)

# é¡µè„šä¿¡æ¯
st.markdown("---")
st.caption("ğŸ’¡ æç¤º: æ­¤æ•°æ®ç”¨äºæ™ºèƒ½é€‰è‚¡åŠŸèƒ½ï¼Œç¡®ä¿æ•°æ®æœ€æ–°å¯è·å¾—æ›´å‡†ç¡®çš„åˆ†æç»“æœ")

