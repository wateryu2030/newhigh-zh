"""
æ™ºèƒ½é€‰è‚¡ï¼ˆç®€åŒ–ç‰ˆï¼‰
åŸºäºdata_engineæ•°æ®åº“ + LLMçš„æ™ºèƒ½é€‰è‚¡ç³»ç»Ÿ
"""

import os
import streamlit as st
import pandas as pd
from pathlib import Path
import sys
from typing import List, Dict
from tradingagents.utils.logging_init import get_logger

logger = get_logger('web.smart_selection')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åŠ data_engine åˆ°è·¯å¾„
project_root = Path(__file__).resolve().parents[2]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
data_engine_root = project_root / "data_engine"
if str(data_engine_root) not in sys.path:
    sys.path.insert(0, str(data_engine_root))

from data_engine.config import DB_URL
from data_engine.utils.db_utils import get_engine
from sqlalchemy import text, inspect

st.set_page_config(
    page_title="æ™ºèƒ½é€‰è‚¡_ç®€åŒ–ç‰ˆ",
    page_icon="ğŸ§ ",
    layout="wide"
)

st.markdown(
    """
    <style>
    .hero-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 28px 32px;
        border-radius: 18px;
        display: flex;
        align-items: center;
        gap: 24px;
        box-shadow: 0 18px 36px rgba(102, 126, 234, 0.25);
        margin-bottom: 24px;
    }
    .hero-card .hero-icon {
        font-size: 42px;
        background: rgba(255, 255, 255, 0.2);
        width: 72px;
        height: 72px;
        border-radius: 18px;
        display: flex;
        align-items: center;
        justify-content: center;
    }
    .hero-card h1 {
        margin: 0;
        font-size: 28px;
        font-weight: 700;
    }
    .hero-card p {
        margin: 4px 0 0 0;
        font-size: 15px;
        opacity: 0.92;
    }
    </style>
    <div class="hero-card">
        <div class="hero-icon">ğŸš€</div>
        <div>
            <h1>æ™ºèƒ½é€‰è‚¡ï¼ˆåŸºäºæœ¬åœ°åŸºç¡€èµ„æ–™ + LLMï¼‰</h1>
            <p>ç»“åˆæœ¬åœ°è¡Œæƒ…ä¸è´¢æŠ¥æ•°æ®ï¼Œå¿«é€Ÿç­›é€‰å¹¶è°ƒç”¨ LLM ç”Ÿæˆå€™é€‰ç»„åˆå»ºè®®ã€‚</p>
        </div>
    </div>
    """,
    unsafe_allow_html=True,
)

# ä»æ•°æ®åº“åŠ è½½æ•°æ®ï¼ˆä½¿ç”¨MySQLæˆ–SQLiteï¼Œæ ¹æ®é…ç½®ï¼‰
df = None
try:
    engine = get_engine(DB_URL)
    inspector = inspect(engine)
    tables = inspector.get_table_names()

    with engine.connect() as conn:
        view_exists = 'vw_stock_basic_info_unique' in tables
        columns = "ts_code, code_name"
        has_industry_table = 'stock_basic_info_extra' in tables
        query_parts = ["SELECT", columns]
        query_parts.append("FROM vw_stock_basic_info_unique" if view_exists else "FROM stock_basic_info")
        basic_query = " ".join(query_parts)
        df_basic = pd.read_sql_query(basic_query, conn)
        df_basic = df_basic.rename(columns={"code_name": "name"})
        if 'ts_code' not in df_basic.columns:
            st.error("stock_basic_info ç¼ºå°‘ ts_code å­—æ®µï¼Œæ— æ³•ç»§ç»­")
            st.stop()
        before_dedup = len(df_basic)
        df_basic = df_basic.drop_duplicates(subset=["ts_code"], keep="first")
        if len(df_basic) < before_dedup:
            logger.info(
                "åŸºç¡€ä¿¡æ¯å»é‡: %s -> %s", before_dedup, len(df_basic)
            )
        # è·å–è¡Œä¸šæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        df_industry = None
        if 'stock_industry_classified' in tables:
            industry_query = text(
                """
                SELECT ts_code, industry
                FROM stock_industry_classified
                WHERE industry IS NOT NULL
                """
            )
            df_industry = pd.read_sql_query(industry_query, conn)
        elif 'stock_basic_info_extra' in tables:
            df_industry = pd.read_sql_query("SELECT ts_code, industry FROM stock_basic_info_extra", conn)
        if df_industry is not None:
            df_industry = df_industry.drop_duplicates(subset=['ts_code'], keep='first')
            df_basic = df_basic.merge(df_industry, on='ts_code', how='left')
        latest_date = conn.execute(text("SELECT MAX(trade_date) FROM stock_market_daily")).scalar()
        if latest_date:
            query_market = text(
                """
                    SELECT 
                        m.ts_code,
                        m.close AS price,
                        m.volume,
                        m.amount AS turnover,
                        m.turnover_rate,
                        m.pct_chg AS change_pct,
                        m.peTTM AS pe,
                        m.pbMRQ AS pb,
                        m.psTTM AS ps
                    FROM stock_market_daily m
                    WHERE m.trade_date = :latest_date
                """
            )
            df_market = pd.read_sql_query(query_market, conn, params={"latest_date": latest_date})
            if 'ts_code' in df_market.columns:
                df_market = df_market.drop_duplicates(subset=["ts_code"], keep="first")
            if 'stock_financials' in tables:
                query_fin = text(
                    """
                        SELECT 
                            f.ts_code,
                            f.total_mv,
                            f.circ_mv
                        FROM stock_financials f
                        WHERE f.trade_date = (
                            SELECT MAX(trade_date) FROM stock_financials
                        )
                    """
                )
                df_fin = pd.read_sql_query(query_fin, conn)
                if 'ts_code' in df_fin.columns:
                    df_fin = df_fin.drop_duplicates(subset=["ts_code"], keep="first")
            else:
                df_fin = None
        else:
            latest_date = None
            df_market = None
            df_fin = None
        if df_basic is not None and latest_date:
            df = df_basic.merge(df_market, on='ts_code', how='left')
            if df_fin is not None:
                df = df.merge(df_fin, on='ts_code', how='left')
            rename_map = {
                'ts_code': 'code',
                'name': 'name',
                'price': 'price',
                'total_mv': 'market_cap',
                'circ_mv': 'float_cap',
                'volume': 'volume',
                'turnover': 'turnover',
                'turnover_rate': 'turnover_rate',
                'change_pct': 'change_pct',
                'peTTM': 'pe',
                'pbMRQ': 'pb',
                'psTTM': 'ps',
            }
            df = df.rename(columns=rename_map)
            if 'market_cap' not in df.columns:
                df['market_cap'] = None
            if 'turnover_rate' not in df.columns:
                df['turnover_rate'] = None
            if 'pe' not in df.columns:
                df['pe'] = None
            if 'pb' not in df.columns:
                df['pb'] = None
            numeric_cols = [
                "market_cap",
                "float_cap",
                "price",
                "turnover",
                "turnover_rate",
                "pe",
                "pb",
                "volume",
                "ps",
            ]
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce")
            if {"market_cap", "turnover", "turnover_rate"}.issubset(df.columns):
                fallback_mask = (
                    (df["market_cap"].isna() | (df["market_cap"] <= 0))
                    & df["turnover"].notna()
                    & (df["turnover"] > 0)
                    & df["turnover_rate"].notna()
                    & (df["turnover_rate"] > 0)
                )
                if fallback_mask.any():
                    df.loc[fallback_mask, "market_cap"] = (
                        df.loc[fallback_mask, "turnover"] * 10000
                        / (df.loc[fallback_mask, "turnover_rate"] / 100)
                    )
                    logger.info(
                        "åŸºäºæˆäº¤é¢/æ¢æ‰‹ç‡ä¼°ç®—å¸‚å€¼: %s åªè‚¡ç¥¨",
                        int(fallback_mask.sum()),
                    )
            if "market_cap" in df.columns:
                missing_caps = df["market_cap"].isna() | (df["market_cap"] <= 0)
                if missing_caps.any():
                    st.info(
                        f"â„¹ï¸ å½“å‰ä»æœ‰ {int(missing_caps.sum())} åªè‚¡ç¥¨ç¼ºå°‘å¯é å¸‚å€¼æ•°æ®ï¼Œç­›é€‰æ—¶ä¼šå¿½ç•¥è¿™äº›è‚¡ç¥¨ã€‚"
                    )
            st.success(f"âœ… å·²åŠ è½½ {len(df)} æ¡è‚¡ç¥¨æ•°æ®ï¼ˆæœ€æ–°æ—¥æœŸ: {latest_date}ï¼‰")
        elif df_basic is not None and latest_date is None:
            st.error("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰å¸‚åœºæ•°æ®ï¼Œè¯·å…ˆä¸‹è½½æ•°æ®")
            st.stop()
        elif df_basic is not None:
            df = df_basic.rename(columns={'ts_code': 'code', 'name': 'name'})
            df['price'] = None
            df['market_cap'] = None
            df['pe'] = None
            df['pb'] = None
            st.warning(f"âš ï¸ åªæœ‰åŸºç¡€ä¿¡æ¯ï¼Œå…± {len(df)} æ¡ï¼Œå»ºè®®ä¸‹è½½å®Œæ•´æ•°æ®")
        else:
            st.error("âŒ æ•°æ®åº“è¡¨ç»“æ„ä¸æ­£ç¡®ï¼Œè¯·é‡æ–°ä¸‹è½½æ•°æ®")
            st.stop()
except Exception as e:
    st.error(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
    import traceback
    with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯"):
        st.code(traceback.format_exc())
    st.stop()

if df is None or df.empty:
    st.error("âŒ æœªèƒ½åŠ è½½æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“")
    st.stop()

st.markdown("---")

# LLMé…ç½®
st.subheader("ğŸ”§ LLMé…ç½®")
col1, col2 = st.columns(2)

with col1:
    # ä»ç¯å¢ƒå˜é‡è·å–é»˜è®¤APIå¯†é’¥
    default_key = os.getenv("DASHSCOPE_API_KEY") or os.getenv("OPENAI_API_KEY") or ""
    api_key = st.text_input(
        "LLM API Key",
        value=default_key,
        type="password",
        help="ä¼˜å…ˆä½¿ç”¨æ­¤å¤„å¡«å†™çš„ Keyï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡"
    )

with col2:
    provider = st.selectbox(
        "æ¨¡å‹æä¾›å•†",
        ["dashscope", "openai", "anthropic"],
        help="é€‰æ‹©LLMæä¾›å•†"
    )

# ç­–ç•¥é…ç½®
st.subheader("ğŸ“Š ç­–ç•¥é…ç½®")
col1, col2 = st.columns(2)

with col1:
    strategy = st.selectbox(
        "é¢„è®¾ç­–ç•¥",
        ["ä¿å®ˆ", "å¹³è¡¡", "æ¿€è¿›", "ä»·å€¼", "æˆé•¿"],
        index=1,
        help="é€‰æ‹©æŠ•èµ„ç­–ç•¥ç±»å‹"
    )

with col2:
    topk = st.slider("è¿”å›å€™é€‰æ•°é‡", 5, 50, 20, help="æœ€å¤šè¿”å›çš„è‚¡ç¥¨æ•°é‡")

# ç­›é€‰æ¡ä»¶
st.subheader("ğŸ” ç­›é€‰æ¡ä»¶")
col1, col2, col3 = st.columns(3)

with col1:
    max_weight = st.slider("å•ç¥¨ä¸Šé™(%)", 5, 20, 10, help="å•ä¸ªè‚¡ç¥¨åœ¨ç»„åˆä¸­çš„æœ€å¤§æƒé‡")

with col2:
    min_mcap = st.number_input(
        "æœ€å°æ€»å¸‚å€¼(äº¿å…ƒ)",
        value=50.0,
        min_value=0.0,
        step=10.0,
        help="è¿‡æ»¤æ‰å¸‚å€¼è¿‡å°çš„è‚¡ç¥¨"
    )

with col3:
    allow_st = st.checkbox("åŒ…å«STè‚¡ç¥¨ï¼Ÿ", value=False, help="æ˜¯å¦åŒ…å«STã€*STç­‰ç‰¹æ®Šå¤„ç†çš„è‚¡ç¥¨")

price_values = df["price"].dropna()
if not price_values.empty:
    min_price = float(price_values.min())
    max_price = float(price_values.max())
    if min_price == max_price:
        price_range = (min_price, max_price)
    else:
        price_step = max((max_price - min_price) / 100, 0.01)
        price_range = st.slider(
            "ä»·æ ¼åŒºé—´(å…ƒ)",
            min_value=round(min_price, 2),
            max_value=round(max_price, 2),
            value=(round(min_price, 2), round(min_price + (max_price - min_price) * 0.4, 2)),
            step=round(price_step, 2),
        )
else:
    price_range = None

change_values = df["change_pct"].dropna()
if not change_values.empty:
    min_change = float(change_values.min())
    max_change = float(change_values.max())
    if min_change == max_change:
        change_range = (min_change, max_change)
    else:
        change_range = st.slider(
            "æ¶¨è·Œå¹…åŒºé—´(%)",
            min_value=round(min_change, 2),
            max_value=round(max_change, 2),
            value=(round(max(min_change, -9.0), 2), round(min(max_change, 9.0), 2)),
            step=0.1,
            help="è¿‡æ»¤å½“æ—¥æ¶¨è·Œå¹…",
        )
else:
    change_range = None

industry_values = []
if "industry" in df.columns:
    industry_values = df["industry"].dropna().unique().tolist()
    industry_values = sorted([i for i in industry_values if isinstance(i, str) and i.strip()])
selected_industries = []
if industry_values:
    selected_industries = st.multiselect(
        "è¡Œä¸šç­›é€‰",
        options=industry_values,
        help="åªä¿ç•™æ‰€é€‰è¡Œä¸šçš„è‚¡ç¥¨",
    )

pe_values = df["pe"].dropna()
if not pe_values.empty:
    min_pe = float(max(pe_values.min(), 0))
    max_pe = float(min(pe_values.quantile(0.99), 200))
    if min_pe < max_pe:
        pe_range = st.slider(
            "PEåŒºé—´",
            min_value=round(min_pe, 1),
            max_value=round(max_pe, 1),
            value=(round(min(min_pe, 10.0), 1), round(min(max_pe, 40.0), 1)),
            step=0.1,
        )
    else:
        pe_range = None
else:
    pe_range = None

st.markdown("---")

# æ•°æ®é¢„å¤„ç†å‡½æ•°
def simple_score(row) -> float:
    """
    ç®€å•çš„è¯„åˆ†å‡½æ•°
    å®é™…åº”è¯¥ç»“åˆæ›´å¤šå› å­ï¼ˆPEã€PBã€ROEç­‰ï¼‰
    """
    price = row.get("price", 0) or 0
    mcap = row.get("market_cap", 0) or 0
    
    base = 0
    if price > 0:
        base += 1
    if mcap > min_mcap * 1e8:  # è½¬æ¢ä¸ºå…ƒ
        base += 1
    
    return float(base)


def llm_rerank(candidates: pd.DataFrame, api_key: str, provider: str, strategy: str, topk: int) -> List[Dict]:
    """
    LLMé‡æ–°æ’åºå€™é€‰è‚¡ç¥¨
    
    ä½¿ç”¨çœŸå®LLM APIè¿›è¡Œæ™ºèƒ½åˆ†æ
    """
    # å°è¯•ä½¿ç”¨LLMåˆ†æ
    if api_key:
        try:
            from web.utils.stock_llm_analyzer import StockLLMAnalyzer
            analyzer = StockLLMAnalyzer(api_key=api_key, provider=provider)
            results = analyzer.analyze_stocks(candidates, strategy, topk)
            return results
        except Exception as e:
            st.warning(f"âš ï¸ LLMåˆ†æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•è¯„åˆ†æ’åº: {e}")
    
    # é™çº§æ–¹æ¡ˆï¼šç®€å•è¯„åˆ†æ’åº
    if not api_key:
        st.warning("âš ï¸ æœªé…ç½®LLM API Keyï¼Œä½¿ç”¨ç®€å•è¯„åˆ†æ’åº")
    
    results = []
    for _, r in candidates.iterrows():
        # è·å–codeï¼ˆå…¼å®¹å¤šç§å­—æ®µåï¼‰
        code = r.get("code") or r.get("ts_code") or r.get("stock_code") or "N/A"
        
        results.append({
            "code": code,
            "name": r.get("name", "N/A"),
            "price": f"ï¿¥{r.get('price', 0):.2f}" if pd.notna(r.get("price")) and r.get("price", 0) > 0 else "N/A",
            "market_cap": f"{r.get('market_cap', 0) / 1e8:.2f}äº¿" if pd.notna(r.get("market_cap")) and r.get("market_cap", 0) > 0 else "N/A",
            "pe": f"{r.get('pe', 0):.2f}" if pd.notna(r.get("pe")) and r.get("pe", 0) > 0 else "N/A",
            "pb": f"{r.get('pb', 0):.2f}" if pd.notna(r.get("pb")) and r.get("pb", 0) > 0 else "N/A",
            "score": r.get("score", 0),
            "reason": f"{strategy}ç­–ç•¥ï¼šåŸºäºå¸‚å€¼å’Œä»·æ ¼ç­›é€‰"
        })
    
    # æŒ‰è¯„åˆ†æ’åº
    results.sort(key=lambda x: x["score"], reverse=True)
    return results[:topk]


# æ‰§è¡Œé€‰è‚¡
if st.button("ğŸš€ ç”Ÿæˆé€‰è‚¡å»ºè®®", type="primary", use_container_width=True):
    if not api_key:
        st.warning("âš ï¸ å»ºè®®é…ç½®LLM API Keyä»¥è·å¾—æ›´å¥½çš„é€‰è‚¡ç»“æœ")
    
    # æ•°æ®å¤„ç†
    with st.spinner("ğŸ”„ æ­£åœ¨å¤„ç†æ•°æ®..."):
        work = df.copy()
        filters_applied = []

        # è¿‡æ»¤STè‚¡ç¥¨
        if not allow_st:
            if "name" in work.columns:
                before = len(work)
                work = work[~work["name"].astype(str).str.contains("ST", case=False, na=False)]
                filters_applied.append(f"å‰”é™¤ST: {before}â†’{len(work)}")
        
        # ç¡®ä¿å­—æ®µåæ­£ç¡®ï¼ˆé€‚é…æ—§ä»£ç ï¼‰
        if "code" not in work.columns and "ts_code" in work.columns:
            work["code"] = work["ts_code"]
        if "code" not in work.columns and "stock_code" in work.columns:
            work["code"] = work["stock_code"]
        
        # å¸‚å€¼ç­›é€‰
        if "market_cap" in work.columns:
            work["market_cap"] = pd.to_numeric(work["market_cap"], errors="coerce").fillna(0)
            if {"turnover", "turnover_rate"}.issubset(work.columns):
                turnover_numeric = pd.to_numeric(work["turnover"], errors="coerce")
                turnover_rate_numeric = pd.to_numeric(work["turnover_rate"], errors="coerce")
                fallback_mask = (
                    (work["market_cap"] <= 0)
                    & turnover_numeric.notna()
                    & (turnover_numeric > 0)
                    & turnover_rate_numeric.notna()
                    & (turnover_rate_numeric > 0)
                )
                if fallback_mask.any():
                    work.loc[fallback_mask, "market_cap"] = (
                        turnover_numeric[fallback_mask] * 10000
                        / (turnover_rate_numeric[fallback_mask] / 100)
                    )
                    filters_applied.append(
                        f"æ¢æ‰‹ç‡ä¼°ç®—å¸‚å€¼ä¿®å¤ {fallback_mask.sum()} åª"
                    )
            before = len(work)
            work = work[work["market_cap"] >= min_mcap * 1e8]
            filters_applied.append(f"å¸‚å€¼â‰¥{min_mcap}äº¿: {before}â†’{len(work)}")
            if work.empty:
                st.warning("âš ï¸ å¸‚å€¼ç­›é€‰åæ²¡æœ‰ç»“æœï¼Œå»ºè®®æ”¾å®½é˜ˆå€¼æˆ–ç­‰å¾…å¸‚å€¼æ•°æ®è¡¥å…¨")
                st.stop()

        # ä»·æ ¼åŒºé—´
        if price_range and price_range[0] < price_range[1] and "price" in work.columns:
            lower, upper = price_range
            before = len(work)
            work = work[(work["price"].notna()) & (work["price"] >= lower) & (work["price"] <= upper)]
            filters_applied.append(f"ä»·æ ¼[{lower}~{upper}]å…ƒ: {before}â†’{len(work)}")

        # æ¶¨è·Œå¹…åŒºé—´
        if change_range and change_range[0] < change_range[1] and "change_pct" in work.columns:
            lower, upper = change_range
            before = len(work)
            work = work[(work["change_pct"].notna()) & (work["change_pct"] >= lower) & (work["change_pct"] <= upper)]
            filters_applied.append(f"æ¶¨è·Œå¹…[{lower}%~{upper}%]: {before}â†’{len(work)}")

        # è¡Œä¸šç­›é€‰
        if selected_industries:
            before = len(work)
            work = work[work["industry"].isin(selected_industries)]
            filters_applied.append(f"è¡Œä¸š {len(selected_industries)} é¡¹: {before}â†’{len(work)}")

        # PEåŒºé—´
        if pe_range and pe_range[0] < pe_range[1] and "pe" in work.columns:
            lower, upper = pe_range
            before = len(work)
            work = work[(work["pe"].notna()) & (work["pe"] >= lower) & (work["pe"] <= upper)]
            filters_applied.append(f"PE[{lower}~{upper}]: {before}â†’{len(work)}")
        
        # è®¡ç®—è¯„åˆ†ï¼ˆåŒ…å«è´¢åŠ¡æŒ‡æ ‡ï¼‰
        def enhanced_score(row) -> float:
            """å¢å¼ºè¯„åˆ†å‡½æ•°ï¼ŒåŒ…å«PEã€PBç­‰è´¢åŠ¡æŒ‡æ ‡"""
            base_score = simple_score(row)
            
            # PEè¯„åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼Œä½†åœ¨åˆç†èŒƒå›´å†…ï¼‰
            if pd.notna(row.get("pe")) and row.get("pe", 0) > 0:
                pe = row.get("pe")
                if 0 < pe < 30:  # åˆç†PEèŒƒå›´
                    base_score += 1
                elif pe < 50:
                    base_score += 0.5
            
            # PBè¯„åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼Œä½†åœ¨åˆç†èŒƒå›´å†…ï¼‰
            if pd.notna(row.get("pb")) and row.get("pb", 0) > 0:
                pb = row.get("pb")
                if 0 < pb < 3:  # åˆç†PBèŒƒå›´
                    base_score += 1
                elif pb < 5:
                    base_score += 0.5
            
            return base_score
        
        work["score"] = work.apply(enhanced_score, axis=1)
        
        # è¿‡æ»¤æ‰è¯„åˆ†ä¸º0çš„è‚¡ç¥¨
        before = len(work)
        work = work[work["score"] > 0]
        filters_applied.append(f"è¯„åˆ†>0: {before}â†’{len(work)}")
        
        if len(work) == 0:
            st.error("âŒ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œè¯·è°ƒæ•´ç­›é€‰æ¡ä»¶")
            st.stop()
        
        st.info(f"ğŸ“Š ç¬¦åˆç­›é€‰æ¡ä»¶çš„è‚¡ç¥¨: {len(work)} åª | " + "ï¼›".join(filters_applied))
        
        # LLMé‡æ–°æ’åº
        with st.spinner("ğŸ¤– LLMæ™ºèƒ½æ’åºä¸­..."):
            # å‡†å¤‡ä¼ é€’ç»™LLMçš„æ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰å¯ç”¨åˆ—ï¼‰
            columns_for_llm = ["code", "name", "price", "market_cap", "score"]
            if "pe" in work.columns:
                columns_for_llm.append("pe")
            if "pb" in work.columns:
                columns_for_llm.append("pb")
            if "ps" in work.columns:
                columns_for_llm.append("ps")
            if "industry" in work.columns:
                columns_for_llm.append("industry")
            
            ranked = llm_rerank(
                work[columns_for_llm], # Use columns_for_llm here
                api_key,
                provider,
                strategy,
                topk  # ä¼ é€’topkå‚æ•°
            )
        
        if ranked:
            st.success(f"âœ… å·²ç”Ÿæˆ {len(ranked)} æ¡å€™é€‰å»ºè®®")
            
            # ä¿å­˜é€‰è‚¡ç»“æœ
            try:
                from web.utils.stock_selection_storage import get_storage
                storage = get_storage()
                selection_id = storage.save_selection(
                    results=ranked,
                    strategy=strategy,
                    filter_conditions={
                        "max_weight": max_weight,
                        "min_mcap": min_mcap,
                        "allow_st": allow_st,
                        "total_candidates": len(work),
                        "provider": provider
                    },
                    metadata={
                        "topk": topk,
                        "api_key_used": bool(api_key)
                    }
                )
                st.session_state.last_selection_id = selection_id
            except Exception as e:
                logger.warning(f"ä¿å­˜é€‰è‚¡ç»“æœå¤±è´¥: {e}")
            
            # æ˜¾ç¤ºç»“æœ
            st.markdown("---")
            st.subheader("ğŸ“‹ é€‰è‚¡ç»“æœ")
            
            # è½¬æ¢ä¸ºDataFrameæ˜¾ç¤º
            result_df = pd.DataFrame(ranked)
            st.dataframe(
                result_df,
                use_container_width=True,
                hide_index=True
            )
            
            # ç»Ÿè®¡ä¿¡æ¯
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("å€™é€‰æ•°é‡", len(ranked))
            with col2:
                avg_score = result_df["score"].mean() if "score" in result_df.columns else 0
                st.metric("å¹³å‡è¯„åˆ†", f"{avg_score:.2f}")
            with col3:
                total_weight = len(ranked) * (max_weight / 100)
                st.metric("é¢„è®¡ç»„åˆæƒé‡", f"{min(total_weight, 1.0)*100:.1f}%")
            
            # å¯¼å‡ºå’Œä¿å­˜åŠŸèƒ½
            st.markdown("---")
            st.subheader("ğŸ’¾ å¯¼å‡ºç»“æœ")
            
            col1, col2 = st.columns(2)
            with col1:
                csv_data = result_df.to_csv(index=False, encoding="utf-8-sig")
                st.download_button(
                    "ğŸ“¥ å¯¼å‡ºä¸º CSV",
                    csv_data.encode("utf-8-sig"),
                    file_name=f"stock_selection_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            with col2:
                if st.session_state.get("last_selection_id"):
                    st.success(f"âœ… ç»“æœå·²è‡ªåŠ¨ä¿å­˜ï¼ˆID: {st.session_state.last_selection_id[:20]}...ï¼‰")
        else:
            st.error("âŒ æœªèƒ½ç”Ÿæˆé€‰è‚¡å»ºè®®")

# è¯´æ˜ä¿¡æ¯
st.markdown("---")
with st.expander("â„¹ï¸ ä½¿ç”¨è¯´æ˜"):
    st.markdown("""
    ### ğŸ“– åŠŸèƒ½è¯´æ˜
    
    1. **æ•°æ®å‡†å¤‡**: éœ€è¦å…ˆä¸‹è½½Aè‚¡åŸºç¡€èµ„æ–™ï¼ˆè§ã€Œæ•°æ®ä¸­å¿ƒ - åŸºç¡€èµ„æ–™ã€é¡µé¢ï¼‰
    
    2. **ç­›é€‰æ¡ä»¶**:
       - **å•ç¥¨ä¸Šé™**: æ§åˆ¶å•ä¸ªè‚¡ç¥¨åœ¨ç»„åˆä¸­çš„æœ€å¤§æƒé‡
       - **æœ€å°å¸‚å€¼**: è¿‡æ»¤æ‰å¸‚å€¼è¿‡å°çš„è‚¡ç¥¨ï¼ˆé™ä½é£é™©ï¼‰
       - **STè‚¡ç¥¨**: å¯é€‰æ‹©æ˜¯å¦åŒ…å«ç‰¹æ®Šå¤„ç†çš„è‚¡ç¥¨
    
    3. **ç­–ç•¥ç±»å‹**:
       - **ä¿å®ˆ**: ä¾§é‡ä½ä¼°å€¼ã€ç¨³å®šå¢é•¿
       - **å¹³è¡¡**: å…¼é¡¾æˆé•¿æ€§å’Œä»·å€¼
       - **æ¿€è¿›**: ä¾§é‡é«˜æˆé•¿ã€é«˜å¼¹æ€§
       - **ä»·å€¼**: ä¾§é‡ä½PEã€ä½PB
       - **æˆé•¿**: ä¾§é‡é«˜ROEã€é«˜å¢é•¿
    
    4. **LLMå¢å¼º**: 
       - é…ç½®LLM API Keyå¯è·å¾—æ›´æ™ºèƒ½çš„åˆ†æç»“æœ
       - ç›®å‰ä½¿ç”¨ç®€å•è¯„åˆ†ï¼Œåç»­ä¼šæ¥å…¥çœŸå®LLMåˆ†æ
    
    ### âš ï¸ æ³¨æ„äº‹é¡¹
    
    - æœ¬åŠŸèƒ½åŸºäºç®€å•çš„æŠ€æœ¯æŒ‡æ ‡ï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®
    - è¯·ç»“åˆå…¶ä»–åˆ†æå·¥å…·åšå‡ºæŠ•èµ„å†³ç­–
    - æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…
    """)

