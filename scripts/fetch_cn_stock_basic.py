#!/usr/bin/env python3
"""
æ‹‰å–Aè‚¡åŸºç¡€èµ„æ–™
ä½¿ç”¨AkShareè·å–Aè‚¡è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¹¶ä¿å­˜ä¸ºCSV
"""

from pathlib import Path
import pandas as pd
import sys
import os
import time
import sqlite3
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ç¦ç”¨ä»£ç†ï¼ˆé¿å…ä»£ç†è¿æ¥é”™è¯¯ï¼‰
def disable_proxy():
    """ä¸´æ—¶ç¦ç”¨ä»£ç†è®¾ç½®"""
    proxy_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 
                  'ALL_PROXY', 'all_proxy', 'NO_PROXY', 'no_proxy']
    saved_proxy = {}
    for var in proxy_vars:
        if var in os.environ:
            saved_proxy[var] = os.environ[var]
            del os.environ[var]
    return saved_proxy

def restore_proxy(saved_proxy):
    """æ¢å¤ä»£ç†è®¾ç½®"""
    for var, value in saved_proxy.items():
        os.environ[var] = value

# ä¸´æ—¶ç¦ç”¨ä»£ç†
saved_proxy_env = disable_proxy()

try:
    import akshare as ak
    # å¦‚æœakshareå†…éƒ¨ä½¿ç”¨requestsï¼Œä¹Ÿç¦ç”¨ä»£ç†
    try:
        import requests
        # ä¿å­˜åŸå§‹çš„getæ–¹æ³•
        original_get = requests.Session.get if hasattr(requests.Session, 'get') else None
    except:
        pass
except ImportError:
    print("âŒ é”™è¯¯: æœªå®‰è£… akshareï¼Œè¯·è¿è¡Œ: pip install akshare")
    sys.exit(1)

OUT = Path("data/stock_basic.csv")
OUT.parent.mkdir(parents=True, exist_ok=True)

# æ•°æ®åº“è·¯å¾„
DB_PATH = project_root / "data" / "a_share_basic.db"
DB_PATH.parent.mkdir(parents=True, exist_ok=True)


def retry_call(func, retries=6, backoff=1.5, allowed_exceptions=(Exception,), func_name="æœªçŸ¥å‡½æ•°"):
    """
    é‡è¯•åŒ…è£…å‡½æ•°ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿
    å‚è€ƒChatGPTæ¨èçš„æ–¹æ¡ˆï¼Œèƒ½å¤Ÿå¤§å¹…å‡å°‘RemoteDisconnectedé”™è¯¯å½±å“
    
    Args:
        func: è¦æ‰§è¡Œçš„å‡½æ•°ï¼ˆæ— å‚æ•°ï¼‰
        retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        backoff: åˆå§‹é€€é¿æ—¶é—´ï¼ˆç§’ï¼‰
        allowed_exceptions: å…è®¸é‡è¯•çš„å¼‚å¸¸ç±»å‹
        func_name: å‡½æ•°åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
    """
    for attempt in range(retries):
        try:
            return func()
        except allowed_exceptions as e:
            if attempt < retries - 1:
                wait = backoff * (2 ** attempt)  # æŒ‡æ•°é€€é¿ï¼š1.5s, 3s, 6s, 12s, 24s, 48s
                print(f"  âš ï¸  [{func_name}] ç¬¬ {attempt+1}/{retries} æ¬¡å°è¯•å¤±è´¥: {repr(e)[:80]}")
                print(f"  ğŸ’¤ ç­‰å¾… {wait:.1f} ç§’åé‡è¯•...")
                time.sleep(wait)
            else:
                print(f"  âŒ [{func_name}] æ‰€æœ‰ {retries} æ¬¡é‡è¯•å‡å¤±è´¥")
                raise RuntimeError(f"æ‰€æœ‰ {retries} æ¬¡é‡è¯•å‡å¤±è´¥: {func_name}") from e
    raise RuntimeError(f"é‡è¯•é€»è¾‘é”™è¯¯: {func_name}")


def fetch_cn_stock_basic(use_tushare: bool = False) -> pd.DataFrame:
    """
    è·å–Aè‚¡è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆä¼˜å…ˆä½¿ç”¨AKShareï¼Œç¨³å®šä¸”å…è´¹ï¼‰
    
    Args:
        use_tushare: æ˜¯å¦å°è¯•ä½¿ç”¨Tushareï¼ˆé»˜è®¤Falseï¼Œä½¿ç”¨AKShareï¼‰
    
    Returns:
        pd.DataFrame: åŒ…å«è‚¡ç¥¨ä»£ç ã€åç§°ã€æœ€æ–°ä»·ã€å¸‚å€¼ç­‰ä¿¡æ¯
    """
    print("ğŸ“¥ å¼€å§‹æ‹‰å–Aè‚¡åŸºç¡€èµ„æ–™...")
    
    # å½»åº•æ¸…é™¤ä»£ç†ç¯å¢ƒå˜é‡ï¼ˆé˜²æ­¢ä»£ç†å¯¼è‡´çš„è¿æ¥ä¸­æ–­ï¼‰
    print("  ğŸ”§ æ¸…é™¤ä»£ç†ç¯å¢ƒå˜é‡...")
    proxy_vars = ['HTTP_PROXY', 'http_proxy', 'HTTPS_PROXY', 'https_proxy', 
                  'ALL_PROXY', 'all_proxy', 'NO_PROXY', 'no_proxy']
    for var in proxy_vars:
        os.environ.pop(var, None)
    print("  âœ… ä»£ç†ç¯å¢ƒå˜é‡å·²æ¸…é™¤")
    
    # æ–¹æ³•1ï¼šä¼˜å…ˆä½¿ç”¨AKShareï¼ˆæ¨èï¼Œå…è´¹ä¸”ç¨³å®šï¼‰
    print("  ğŸ“Š ä½¿ç”¨AKShareè·å–æ•°æ®ï¼ˆå…è´¹ï¼Œæ— éœ€Tokenï¼‰...")
    
    # æ–¹æ³•2ï¼šå¯é€‰ï¼Œå¦‚æœç”¨æˆ·æ˜ç¡®è¦ä½¿ç”¨Tushare
    if use_tushare:
        try:
            from tradingagents.dataflows.tushare_adapter import get_tushare_adapter
            adapter = get_tushare_adapter()
            
            if adapter.provider and adapter.provider.connected:
                print("  âœ… æ£€æµ‹åˆ°Tushareé…ç½®ï¼Œå°è¯•ä½¿ç”¨Tushareè·å–å®Œæ•´æ•°æ®...")
                try:
                    return _fetch_with_tushare(adapter)
                except Exception as e:
                    print(f"  âš ï¸  Tushareè·å–å¤±è´¥: {e}")
                    print("  ğŸ’¡ é™çº§ä½¿ç”¨AKShare...")
        except Exception as e:
            print(f"  âš ï¸  Tushareåˆå§‹åŒ–å¤±è´¥: {e}")
            print("  ğŸ’¡ ä½¿ç”¨AKShareä½œä¸ºæ•°æ®æº...")
    
    # è®¾ç½®æ— ä»£ç†æ¨¡å¼ï¼ˆä¿®æ”¹requestsåº“é…ç½®ï¼‰
    def setup_no_proxy_requests():
        """è®¾ç½®requestsåº“ä¸ä½¿ç”¨ä»£ç†ï¼ˆå‚è€ƒChatGPTæ–¹æ¡ˆï¼‰"""
        try:
            import requests
            import urllib3
            
            # 1. ç¦ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ä»£ç†
            disable_proxy()
            
            # 2. ç¦ç”¨urllib3çš„ä»£ç†æ£€æµ‹
            try:
                urllib3.disable_warnings()
            except:
                pass
            
            # 3. ä¿®æ”¹requests.Sessionçš„requestæ–¹æ³•
            original_request = requests.Session.request
            def no_proxy_request(self, method, url, **kwargs):
                # å¼ºåˆ¶è®¾ç½®ä¸ä½¿ç”¨ä»£ç†
                kwargs['proxies'] = {'http': None, 'https': None}
                
                # æ·»åŠ æ›´çœŸå®çš„æµè§ˆå™¨è¯·æ±‚å¤´
                if 'headers' not in kwargs or kwargs['headers'] is None:
                    kwargs['headers'] = {}
                
                headers = kwargs['headers']
                if 'User-Agent' not in headers or not headers.get('User-Agent'):
                    headers['User-Agent'] = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                if 'Accept' not in headers:
                    headers['Accept'] = 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'
                if 'Accept-Language' not in headers:
                    headers['Accept-Language'] = 'zh-CN,zh;q=0.9,en;q=0.8'
                if 'Connection' not in headers:
                    headers['Connection'] = 'close'  # æ¯æ¬¡è¯·æ±‚åå…³é—­è¿æ¥
                
                # å¢åŠ è¶…æ—¶æ—¶é—´
                if 'timeout' not in kwargs or kwargs.get('timeout') is None:
                    kwargs['timeout'] = (10, 120)
                
                return original_request(self, method, url, **kwargs)
            
            requests.Session.request = no_proxy_request
            
            # 4. ä¿®æ”¹requests.get/postç­‰å¿«æ·æ–¹æ³•
            original_get = requests.get
            original_post = requests.post
            
            def patched_get(url, **kwargs):
                kwargs['proxies'] = {'http': None, 'https': None}
                return original_get(url, **kwargs)
            
            def patched_post(url, **kwargs):
                kwargs['proxies'] = {'http': None, 'https': None}
                return original_post(url, **kwargs)
            
            requests.get = patched_get
            requests.post = patched_post
            
            # 5. ä¿®æ”¹Sessionçš„é»˜è®¤é…ç½®
            original_init = requests.Session.__init__
            def new_init(self, *args, **kwargs):
                original_init(self, *args, **kwargs)
                if hasattr(self, 'trust_env'):
                    self.trust_env = False
                self.proxies = {'http': None, 'https': None}
            
            requests.Session.__init__ = new_init
            
            return True
        except Exception as e:
            print(f"  âš ï¸ è®¾ç½®æ— ä»£ç†æ¨¡å¼å¤±è´¥: {e}")
            return False
    
    # è®¾ç½®æ— ä»£ç†æ¨¡å¼
    setup_no_proxy_requests()
    
    # æ³¨æ„ï¼šretry_callå‡½æ•°å·²å®šä¹‰åœ¨å‡½æ•°å¤–éƒ¨ï¼Œä½¿ç”¨ChatGPTæ¨èçš„æŒ‡æ•°é€€é¿æ–¹æ¡ˆ
    
    try:
        # ä½¿ç”¨æ”¹è¿›çš„é‡è¯•æœºåˆ¶è·å–è‚¡ç¥¨ä»£ç ä¸åç§°
        print("  - è·å–è‚¡ç¥¨ä»£ç ä¸åç§°è¡¨ï¼ˆstock_info_a_code_nameï¼‰...")
        code_name = retry_call(
            lambda: ak.stock_info_a_code_name(),
            retries=6,
            backoff=1.5,
            func_name="stock_info_a_code_name"
        )
        print(f"  âœ… è·å–åˆ° {len(code_name)} æ¡è‚¡ç¥¨ä»£ç ")
        
        # åœ¨ä¸¤æ¬¡APIè°ƒç”¨ä¹‹é—´æ·»åŠ å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
        print("  - ç­‰å¾… 3 ç§’åè·å–å®æ—¶æ•°æ®ï¼ˆé¿å…è¯·æ±‚è¿‡å¿«ï¼‰...")
        time.sleep(3)
        
        # è·å–å½“æ—¥Aè‚¡ç°è´§è¡Œæƒ…ï¼ˆåŒ…å«ä»·æ ¼ã€å¸‚å€¼ç­‰ï¼‰
        print("  - è·å–å½“æ—¥Aè‚¡ç°è´§è¡Œæƒ…ï¼ˆstock_zh_a_spot_emï¼‰...")
        print("  âš ï¸  æ³¨æ„ï¼šæ­¤æ¥å£éœ€è¦è·å–æ‰€æœ‰Aè‚¡å®æ—¶æ•°æ®ï¼ˆ5000+åªï¼‰ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´...")
        
        spot = None
        try:
            spot = retry_call(
                lambda: ak.stock_zh_a_spot_em(),
                retries=6,
                backoff=2.0,  # å¯¹äºå¤§æ•°æ®é‡è¯·æ±‚ï¼Œåˆå§‹é€€é¿æ—¶é—´æ›´é•¿
                func_name="stock_zh_a_spot_em"
            )
            print(f"  âœ… è·å–åˆ° {len(spot)} æ¡å®æ—¶ä¿¡æ¯")
        except Exception as e:
            print(f"  âš ï¸  å®æ—¶æ•°æ®æ¥å£å¤±è´¥: {e}")
            print(f"  ğŸ’¡ ä½¿ç”¨é™çº§æ–¹æ¡ˆï¼šåªä½¿ç”¨åŸºç¡€ä¿¡æ¯ï¼ˆä»£ç å’Œåç§°ï¼‰")
            print(f"  ğŸ’¡ ä»·æ ¼ã€å¸‚å€¼ç­‰æ•°æ®å°†ç•™ç©ºï¼Œå¯åç»­å•ç‹¬è·å–")
            spot = pd.DataFrame()  # ç©ºDataFrameï¼Œåç»­åˆå¹¶æ—¶ä½¿ç”¨left join
        
        # åˆå¹¶æ•°æ®
        print("  - åˆå¹¶æ•°æ®...")
        if not spot.empty:
            df = code_name.merge(
                spot, 
                left_on="code", 
                right_on="ä»£ç ", 
                how="left"
            )
        else:
            # é™çº§æ–¹æ¡ˆï¼šåªä½¿ç”¨åŸºç¡€ä¿¡æ¯
            df = code_name.copy()
            print("  â„¹ï¸  ä½¿ç”¨é™çº§æ–¹æ¡ˆï¼šä»…åŒ…å«è‚¡ç¥¨ä»£ç å’Œåç§°")
        
        # å­—æ®µæ¸…æ´—ï¼Œé‡å‘½åï¼ˆå‚è€ƒa_share_downloader.pyçš„å®é™…åˆ—åï¼‰
        # AKShareçš„stock_zh_a_spot_emè¿”å›çš„åˆ—åå¯èƒ½æœ‰å¤šç§å˜ä½“
        column_mapping = {}
        available_columns = df.columns.tolist()
        
        # æ‰“å°å®é™…åˆ—åä»¥ä¾¿è°ƒè¯•
        print(f"  ğŸ“‹ å®é™…è·å–åˆ°çš„åˆ—å: {available_columns[:20]}...")
        
        # å®šä¹‰å¤šç§å¯èƒ½çš„åˆ—åæ˜ å°„ï¼ˆåº”å¯¹AKShareä¸åŒç‰ˆæœ¬æˆ–æ¥å£å˜åŒ–ï¼‰
        mapping_candidates = {
            "code": ["code", "ä»£ç ", "symbol", "è‚¡ç¥¨ä»£ç "],
            "name": ["name", "åç§°"],
            "price": ["æœ€æ–°ä»·", "ç°ä»·", "close", "price"],
            "market_cap": ["æ€»å¸‚å€¼", "æ€»å¸‚å€¼(å…ƒ)", "market_cap", "total_mv"],
            "float_cap": ["æµé€šå¸‚å€¼", "æµé€šå¸‚å€¼(å…ƒ)", "float_cap", "circ_mv"],
            "pe": ["å¸‚ç›ˆç‡-åŠ¨æ€", "å¸‚ç›ˆç‡", "PE", "åŠ¨æ€å¸‚ç›ˆç‡", "pe", "pe_ttm"],
            "pb": ["å¸‚å‡€ç‡", "PB", "pb"],
            "ps": ["å¸‚é”€ç‡", "PS", "ps"],
            "pcf": ["å¸‚ç°ç‡", "PCF", "pcf"],
            "change_pct": ["æ¶¨è·Œå¹…", "æ¶¨è·Œ%", "pct_chg", "change_pct"],
            "volume": ["æˆäº¤é‡", "volume"],
            "turnover": ["æˆäº¤é¢", "amount", "turnover"],
        }
        
        # åŒ¹é…åˆ—å
        for new_col, candidates in mapping_candidates.items():
            matched = False
            for candidate in candidates:
                if candidate in available_columns:
                    column_mapping[candidate] = new_col
                    matched = True
                    break
            if not matched:
                print(f"  âš ï¸  æœªæ‰¾åˆ° {new_col} çš„åˆ—ï¼Œå°†è®¾ä¸ºç©ºå€¼")
        
        # æ‰§è¡Œé‡å‘½å
        df = df.rename(columns=column_mapping)
        
        # ç¡®ä¿æ‰€æœ‰æœŸæœ›çš„åˆ—éƒ½å­˜åœ¨ï¼ˆå³ä½¿ä¸ºç©ºï¼‰
        expected_columns = ["code", "name", "price", "market_cap", "float_cap", 
                           "pe", "pb", "ps", "pcf", "change_pct", "volume", "turnover"]
        for col in expected_columns:
            if col not in df.columns:
                df[col] = None
                print(f"  â„¹ï¸  æ·»åŠ ç©ºåˆ—: {col}ï¼ˆæ•°æ®æºä¸­ä¸å­˜åœ¨ï¼‰")
        
        # å°è¯•è·å–è´¢åŠ¡æŒ‡æ ‡ï¼ˆROEç­‰ï¼‰
        print("  - å°è¯•è·å–è´¢åŠ¡æŒ‡æ ‡ï¼ˆROEç­‰ï¼‰...")
        try:
            # ä½¿ç”¨akshareè·å–åŸºæœ¬é¢æ•°æ®
            for idx, row in df.head(100).iterrows():  # å…ˆæµ‹è¯•å‰100åªè‚¡ç¥¨
                code = row.get("code", "")
                if not code:
                    continue
                try:
                    # è·å–è‚¡ç¥¨è´¢åŠ¡æŒ‡æ ‡
                    basic_info = ak.stock_individual_info_em(symbol=code)
                    if not basic_info.empty and "å‡€èµ„äº§æ”¶ç›Šç‡" in basic_info.values:
                        # è¿™é‡Œå¯ä»¥æ·»åŠ ROEç­‰è´¢åŠ¡æŒ‡æ ‡
                        pass
                except:
                    pass
        except Exception as e:
            print(f"  âš ï¸ è´¢åŠ¡æŒ‡æ ‡è·å–éƒ¨åˆ†å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
        
        # é€‰æ‹©éœ€è¦çš„åˆ—
        expected_columns = ["code", "name", "price", "market_cap", "float_cap", 
                           "pe", "pb", "ps", "pcf", "change_pct", "volume", "turnover"]
        columns_to_keep = [col for col in expected_columns if col in df.columns]
        df = df[columns_to_keep]
        
        # æ•°æ®æ¸…æ´—
        df = df.dropna(subset=["code", "name"]).drop_duplicates(subset=["code"])
        
        # æ•°å€¼åˆ—è½¬æ¢ï¼ˆå¤„ç†å„ç§æ ¼å¼ï¼šå­—ç¬¦ä¸²ã€å¸¦å•ä½ç­‰ï¼‰
        numeric_columns = ["price", "market_cap", "float_cap", "pe", "pb", "ps", "pcf", 
                         "change_pct", "volume", "turnover"]
        for col in numeric_columns:
            if col in df.columns:
                # å…ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œæ¸…ç†å•ä½
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str).str.replace('å…ƒ', '').str.replace('ä¸‡', '').str.replace(',', '').str.replace(' ', '')
                df[col] = pd.to_numeric(df[col], errors="coerce")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        print(f"\n  ğŸ“Š æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ï¼š")
        for col in ["pe", "pb", "market_cap", "price"]:
            if col in df.columns:
                non_null_count = df[col].notna().sum()
                print(f"     - {col}: {non_null_count}/{len(df)} æ¡æœ‰æ•°æ® ({non_null_count/len(df)*100:.1f}%)")
            else:
                print(f"     - {col}: åˆ—ä¸å­˜åœ¨")
        
        print(f"  âœ… æ•°æ®æ¸…æ´—å®Œæˆï¼Œå…± {len(df)} æ¡æœ‰æ•ˆè®°å½•")
        return df
        
    except ConnectionError as e:
        print(f"\nâŒ ç½‘ç»œè¿æ¥é”™è¯¯: {e}")
        print("ğŸ’¡ å»ºè®®:")
        print("  1. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š")
        print("  2. æ•°æ®æºæœåŠ¡å™¨å¯èƒ½ä¸´æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•")
        print("  3. å¦‚æœæ˜¯é¢‘ç¹çš„è¿æ¥ä¸­æ–­ï¼Œå¯èƒ½æ˜¯æ•°æ®æºé™æµï¼Œè¯·ç­‰å¾…5-10åˆ†é’Ÿåé‡è¯•")
        import traceback
        traceback.print_exc()
        raise
    except Exception as e:
        error_msg = str(e).lower()
        error_type = type(e).__name__
        
        if "disconnected" in error_msg or "aborted" in error_msg:
            print(f"\nâŒ è¿æ¥ä¸­æ–­: {e}")
            print("ğŸ’¡ é—®é¢˜åˆ†æ: æ•°æ®æºæœåŠ¡å™¨ä¸»åŠ¨å…³é—­äº†è¿æ¥")
            print("ğŸ’¡ å¯èƒ½åŸå› :")
            print("  1. æ•°æ®æºæœåŠ¡å™¨ä¸´æ—¶è´Ÿè½½è¿‡é«˜")
            print("  2. è¯·æ±‚é¢‘ç‡è¿‡å¿«è¢«é™æµ")
            print("  3. ç½‘ç»œä¸ç¨³å®šå¯¼è‡´è¿æ¥ä¸­æ–­")
            print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
            print("  1. ç­‰å¾…5-10åˆ†é’Ÿåé‡è¯•")
            print("  2. æ£€æŸ¥ç½‘ç»œè¿æ¥ç¨³å®šæ€§")
            print("  3. å¦‚æœé—®é¢˜æŒç»­ï¼Œå¯ä»¥å°è¯•åœ¨éé«˜å³°æ—¶æ®µä¸‹è½½")
        elif "connection" in error_msg or "timeout" in error_msg:
            print(f"\nâŒ ç½‘ç»œè¿æ¥é”™è¯¯: {e}")
            print("ğŸ’¡ å»ºè®®:")
            print("  1. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š")
            print("  2. æ£€æŸ¥é˜²ç«å¢™/ä»£ç†è®¾ç½®")
            print("  3. ç¨åé‡è¯•ï¼ˆå¯èƒ½æ˜¯æ•°æ®æºæœåŠ¡å™¨ç¹å¿™ï¼‰")
        elif "rate limit" in error_msg or "é¢‘ç‡" in error_msg:
            print(f"\nâŒ è¯·æ±‚é¢‘ç‡è¿‡é«˜: {e}")
            print("ğŸ’¡ å»ºè®®:")
            print("  1. ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•")
            print("  2. æ•°æ®æºå¯èƒ½æœ‰è®¿é—®é¢‘ç‡é™åˆ¶")
        else:
            print(f"\nâŒ ä¸‹è½½å¤±è´¥: {e}")
            print(f"ğŸ’¡ é”™è¯¯ç±»å‹: {error_type}")
            print("ğŸ’¡ è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶é‡è¯•")
        import traceback
        traceback.print_exc()
        raise


def _fetch_with_tushare(adapter) -> pd.DataFrame:
    """
    ä½¿ç”¨Tushareè·å–Aè‚¡å®Œæ•´æ•°æ®
    
    Args:
        adapter: TushareDataAdapterå®ä¾‹
    
    Returns:
        pd.DataFrame: åŒ…å«å®Œæ•´æ•°æ®çš„DataFrame
    """
    try:
        from datetime import datetime
        import pandas as pd
        
        # ä¿®å¤: ä½¿ç”¨apiè€Œä¸æ˜¯pro_api
        pro = adapter.provider.api
        today = datetime.now().strftime('%Y%m%d')
        
        print("  - æµ‹è¯•Tushareæ¥å£æƒé™...")
        
        # å…ˆæµ‹è¯•åŸºç¡€æ¥å£æ˜¯å¦å¯ç”¨
        try:
            test_basic = pro.stock_basic(exchange='', list_status='L', fields='ts_code,symbol,name', limit=5)
            if test_basic.empty:
                raise Exception("stock_basicæ¥å£è¿”å›ç©ºæ•°æ®")
            print("  âœ… stock_basicæ¥å£å¯ç”¨")
        except Exception as e:
            error_msg = str(e)
            if 'æƒé™' in error_msg or 'ç§¯åˆ†' in error_msg:
                print(f"  âš ï¸  Tushareæƒé™ä¸è¶³: {error_msg[:80]}")
                print(f"  ğŸ’¡ è¯·è®¿é—® https://tushare.pro å®Œæˆå®åè®¤è¯è·å–ç§¯åˆ†")
                raise Exception("Tushareæƒé™ä¸è¶³ï¼Œéœ€è¦å®åè®¤è¯")
            else:
                raise
        
        print("  - è·å–è‚¡ç¥¨åˆ—è¡¨...")
        # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        stock_list = pro.stock_basic(
            exchange='', 
            list_status='L', 
            fields='ts_code,symbol,name,area,industry,market,list_date'
        )
        
        if stock_list.empty:
            print("  âŒ æœªè·å–åˆ°è‚¡ç¥¨åˆ—è¡¨")
            return pd.DataFrame()
        
        print(f"  âœ… è·å–åˆ° {len(stock_list)} åªè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
        
        print("  - å°è¯•è·å–æ¯æ—¥æŒ‡æ ‡æ•°æ®ï¼ˆPEã€PBã€å¸‚å€¼ï¼‰...")
        # æµ‹è¯•daily_basicæ¥å£æ˜¯å¦å¯ç”¨
        daily_basic_available = False
        try:
            test_daily = pro.daily_basic(trade_date=today, fields='ts_code,pe,pb', limit=5)
            if not test_daily.empty:
                daily_basic_available = True
                print("  âœ… daily_basicæ¥å£å¯ç”¨ï¼Œå¯ä»¥è·å–PEã€PBã€å¸‚å€¼ç­‰æ•°æ®")
        except Exception as e:
            error_msg = str(e)
            if 'æƒé™' in error_msg or 'ç§¯åˆ†' in error_msg:
                print(f"  âš ï¸  daily_basicæ¥å£éœ€è¦æ›´é«˜æƒé™æˆ–ç§¯åˆ†")
                print(f"  ğŸ’¡ å°†åªä½¿ç”¨åŸºç¡€ä¿¡æ¯ï¼ˆä»£ç å’Œåç§°ï¼‰ï¼ŒPEã€PBç­‰æ•°æ®å°†ç•™ç©º")
                print(f"  ğŸ’¡ å®Œæˆå®åè®¤è¯åå¯è·å–å®Œæ•´æ•°æ®ï¼Œè®¿é—®ï¼šhttps://tushare.pro")
            else:
                print(f"  âš ï¸  daily_basicæ¥å£æµ‹è¯•å¤±è´¥: {error_msg[:80]}")
        
        # åˆ†æ‰¹è·å–æ¯æ—¥æŒ‡æ ‡ï¼ˆåŒ…å«PEã€PBã€å¸‚å€¼ï¼‰
        all_data = []
        batch_size = 500
        
        if daily_basic_available:
            for i in range(0, len(stock_list), batch_size):
                batch = stock_list.iloc[i:i+batch_size]
                ts_codes = ','.join(batch['ts_code'].tolist())
                
                try:
                    # è·å–æ¯æ—¥æŒ‡æ ‡
                    daily_basic = pro.daily_basic(
                        trade_date=today,
                        ts_code=ts_codes,
                        fields='ts_code,pe,pb,ps,total_mv,circ_mv'
                    )
                    
                    # åˆå¹¶æ•°æ®
                    merged = batch.merge(daily_basic, on='ts_code', how='left')
                    all_data.append(merged)
                    
                    # æ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼ˆTushareæœ‰é¢‘ç‡é™åˆ¶ï¼‰
                    if (i + batch_size) % 1000 == 0:
                        print(f"  â³ å·²å¤„ç† {i + batch_size}/{len(stock_list)} åªè‚¡ç¥¨")
                        time.sleep(0.5)  # æ¯1000åªè‚¡ç¥¨ç­‰å¾…0.5ç§’
                        
                except Exception as e:
                    error_msg = str(e)
                    if 'æƒé™' in error_msg or 'ç§¯åˆ†' in error_msg:
                        print(f"  âš ï¸  æ‰¹æ¬¡ {i//batch_size + 1} æƒé™ä¸è¶³ï¼Œä½¿ç”¨åŸºç¡€ä¿¡æ¯")
                        # åªä¿å­˜åŸºæœ¬ä¿¡æ¯
                        all_data.append(batch)
                        break  # å¦‚æœæƒé™ä¸è¶³ï¼Œä¸å†å°è¯•åç»­æ‰¹æ¬¡
                    else:
                        print(f"  âš ï¸  æ‰¹æ¬¡ {i//batch_size + 1} è·å–å¤±è´¥: {e}")
                        # å³ä½¿å¤±è´¥ä¹Ÿä¿å­˜åŸºæœ¬ä¿¡æ¯
                        all_data.append(batch)
                        time.sleep(1)  # å¤±è´¥åç­‰å¾…æ›´é•¿æ—¶é—´
        else:
            # å¦‚æœæ²¡æœ‰daily_basicæƒé™ï¼Œåªä½¿ç”¨åŸºç¡€ä¿¡æ¯
            print("  â„¹ï¸  ä»…ä½¿ç”¨åŸºç¡€ä¿¡æ¯ï¼ˆæ— PEã€PBã€å¸‚å€¼æ•°æ®ï¼‰")
            all_data = [stock_list]
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        if all_data:
            result = pd.concat(all_data, ignore_index=True)
            
            # æ˜ å°„å­—æ®µå
            column_mapping = {
                'ts_code': 'ts_code',
                'symbol': 'code',
                'name': 'name',
                'industry': 'industry',
                'pe': 'pe',
                'pb': 'pb',
                'ps': 'ps',
                'total_mv': 'market_cap',  # æ€»å¸‚å€¼ï¼ˆä¸‡å…ƒï¼‰
                'circ_mv': 'float_cap',     # æµé€šå¸‚å€¼ï¼ˆä¸‡å…ƒï¼‰
            }
            
            # é‡å‘½ååˆ—
            result = result.rename(columns=column_mapping)
            
            # è½¬æ¢å¸‚å€¼å•ä½ï¼ˆTushareè¿”å›çš„æ˜¯ä¸‡å…ƒï¼Œè½¬æ¢ä¸ºå…ƒï¼‰
            if 'market_cap' in result.columns:
                result['market_cap'] = result['market_cap'] * 10000
            if 'float_cap' in result.columns:
                result['float_cap'] = result['float_cap'] * 10000
            
            # å¡«å……ç¼ºå¤±å­—æ®µï¼ˆä¸ºäº†ä¸AKShareæ ¼å¼ä¸€è‡´ï¼‰
            for col in ['price', 'change_pct', 'volume', 'turnover', 'pcf']:
                if col not in result.columns:
                    result[col] = None
            
            # å¡«å……PEã€PBç­‰å­—æ®µï¼ˆå¦‚æœæƒé™ä¸è¶³å¯èƒ½ä¸ºç©ºï¼‰
            for col in ['pe', 'pb', 'ps', 'market_cap', 'float_cap']:
                if col not in result.columns:
                    result[col] = None
            
            print(f"  âœ… Tushareæ•°æ®è·å–å®Œæˆï¼Œå…± {len(result)} æ¡è®°å½•")
            print(f"  ğŸ“Š æ•°æ®å®Œæ•´æ€§ï¼š")
            
            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            has_pe = result['pe'].notna().sum() if 'pe' in result.columns else 0
            has_pb = result['pb'].notna().sum() if 'pb' in result.columns else 0
            has_mv = result['market_cap'].notna().sum() if 'market_cap' in result.columns else 0
            
            print(f"     - æœ‰PEæ•°æ®: {has_pe} åª")
            print(f"     - æœ‰PBæ•°æ®: {has_pb} åª")
            print(f"     - æœ‰å¸‚å€¼æ•°æ®: {has_mv} åª")
            
            if has_pe == 0 and has_pb == 0 and has_mv == 0:
                print(f"  âš ï¸  è­¦å‘Šï¼šè·å–çš„æ•°æ®ä¸å®Œæ•´ï¼ˆåªæœ‰ä»£ç å’Œåç§°ï¼‰")
                print(f"  ğŸ’¡ å»ºè®®ï¼šç™»å½• https://tushare.pro å®Œæˆå®åè®¤è¯ä»¥è·å–å®Œæ•´æ•°æ®")
            
            return result
        else:
            return pd.DataFrame()
            
    except Exception as e:
        print(f"  âŒ Tushareè·å–æ•°æ®å¤±è´¥: {e}")
        print(f"  ğŸ’¡ å°†ä½¿ç”¨AKShareä½œä¸ºå¤‡ç”¨...")
        raise


def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    conn = sqlite3.connect(str(DB_PATH))
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS stock_data (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            code TEXT NOT NULL UNIQUE,
            name TEXT NOT NULL,
            price REAL,
            market_cap REAL,
            float_cap REAL,
            pe REAL,
            pb REAL,
            ps REAL,
            pcf REAL,
            change_pct REAL,
            volume INTEGER,
            turnover REAL,
            industry TEXT,
            area TEXT,
            market TEXT,
            list_date TEXT,
            update_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_code ON stock_data(code)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_name ON stock_data(name)")
    conn.commit()
    conn.close()

def save_to_database(df):
    """ä¿å­˜åˆ°æ•°æ®åº“"""
    if df.empty:
        return
    conn = sqlite3.connect(str(DB_PATH))
    df.to_sql('stock_data', conn, if_exists='replace', index=False)
    conn.close()


if __name__ == "__main__":
    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        init_database()
        
        # ä¼˜å…ˆå°è¯•ä½¿ç”¨Tushareï¼ˆå¦‚æœé…ç½®äº†Tokenï¼‰
        use_tushare = os.getenv('TUSHARE_ENABLED', 'false').lower() == 'true'
        
        if use_tushare:
            print("ğŸ”‘ ä½¿ç”¨Tushareè·å–æ•°æ®ï¼ˆå®Œæ•´è´¢åŠ¡æŒ‡æ ‡ï¼‰")
        else:
            print("ğŸ“Š ä½¿ç”¨AKShareè·å–æ•°æ®ï¼ˆå…è´¹ï¼Œæ— éœ€Tokenï¼‰")
        
        # ä½¿ç”¨AKShareè·å–æ•°æ®ï¼ˆå…è´¹ï¼Œæ— éœ€Tokenï¼Œæ— éœ€å®åè®¤è¯ï¼‰
        # å¦‚æœç”¨æˆ·é…ç½®äº†Tushareä¸”æƒ³ä½¿ç”¨ï¼Œå¯ä»¥è®¾ç½®use_tushare=True
        df = fetch_cn_stock_basic(use_tushare=use_tushare)
        
        # ä¿å­˜åˆ°CSV
        df.to_csv(OUT, index=False, encoding="utf-8-sig")  # ä½¿ç”¨utf-8-sigç¡®ä¿Excelèƒ½æ­£ç¡®æ‰“å¼€
        print(f"âœ… å·²ä¿å­˜ {len(df)} æ¡è®°å½•åˆ° {OUT.absolute()}")
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        save_to_database(df)
        print(f"âœ… å·²ä¿å­˜ {len(df)} æ¡è®°å½•åˆ°æ•°æ®åº“ {DB_PATH}")
        
        # æ˜¾ç¤ºå‰å‡ æ¡æ•°æ®
        print("\nğŸ“Š æ•°æ®é¢„è§ˆ:")
        print(df.head(10).to_string(index=False))
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
        restore_proxy(saved_proxy_env)
        sys.exit(1)
    except Exception as e:
        restore_proxy(saved_proxy_env)
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)
    finally:
        # ç¡®ä¿æ¢å¤ä»£ç†è®¾ç½®
        restore_proxy(saved_proxy_env)

