#!/usr/bin/env python3
"""
å®Œæ•´çš„Aè‚¡åŸºç¡€æ•°æ®ä¸‹è½½è„šæœ¬
å‚è€ƒGitHubé¡¹ç›®æ–¹æ¡ˆï¼Œç¡®ä¿è·å–åŒ…å«PEã€PBç­‰å®Œæ•´è´¢åŠ¡æ•°æ®ï¼Œå¹¶ä¿å­˜åˆ°æ•°æ®åº“
"""

import os
import sys
import sqlite3
import pandas as pd
from datetime import datetime
from pathlib import Path
import time

# æ¸…é™¤ä»£ç†ç¯å¢ƒå˜é‡ï¼ˆé˜²æ­¢è¿æ¥ä¸­æ–­ï¼‰
proxy_vars = ['HTTP_PROXY', 'http_proxy', 'HTTPS_PROXY', 'https_proxy', 
              'ALL_PROXY', 'all_proxy', 'NO_PROXY', 'no_proxy']
for var in proxy_vars:
    os.environ.pop(var, None)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

# æ•°æ®åº“è·¯å¾„
DB_PATH = project_root / "data" / "a_share_basic.db"
DB_PATH.parent.mkdir(parents=True, exist_ok=True)

# CSVå¤‡ä»½è·¯å¾„
CSV_PATH = project_root / "data" / "stock_basic.csv"


def retry_call(func, retries=6, backoff=1.5, func_name="æœªçŸ¥å‡½æ•°"):
    """
    é‡è¯•åŒ…è£…å‡½æ•°ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿
    """
    for attempt in range(retries):
        try:
            return func()
        except Exception as e:
            if attempt < retries - 1:
                wait = backoff * (2 ** attempt)
                print(f"  âš ï¸  [{func_name}] ç¬¬ {attempt+1}/{retries} æ¬¡å°è¯•å¤±è´¥")
                print(f"  ğŸ’¤ ç­‰å¾… {wait:.1f} ç§’åé‡è¯•...")
                time.sleep(wait)
            else:
                print(f"  âŒ [{func_name}] æ‰€æœ‰ {retries} æ¬¡é‡è¯•å‡å¤±è´¥")
                raise RuntimeError(f"æ‰€æœ‰ {retries} æ¬¡é‡è¯•å‡å¤±è´¥: {func_name}") from e


def init_database():
    """
    åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„
    å‚è€ƒç”¨æˆ·æä¾›çš„æ–¹æ¡ˆ
    """
    print("ğŸ“Š åˆå§‹åŒ–æ•°æ®åº“...")
    conn = sqlite3.connect(str(DB_PATH))
    cursor = conn.cursor()
    
    # åˆ›å»ºè‚¡ç¥¨æ•°æ®è¡¨ï¼ˆå‚è€ƒç”¨æˆ·æä¾›çš„SQLç»“æ„ï¼‰
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS stock_data (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            stock_code TEXT NOT NULL,
            stock_name TEXT NOT NULL,
            price REAL,
            market_cap REAL,
            float_cap REAL,
            pe REAL,
            pb REAL,
            ps REAL,
            pcf REAL,
            change_pct REAL,
            volume INTEGER,
            turnover REAL,
            update_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(stock_code)
        )
    """)
    
    # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢é€Ÿåº¦
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_stock_code ON stock_data(stock_code)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_stock_name ON stock_data(stock_name)")
    
    conn.commit()
    conn.close()
    print(f"  âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {DB_PATH}")
    return True


def setup_no_proxy_requests():
    """
    å½»åº•è®¾ç½®requestsåº“ä¸ä½¿ç”¨ä»£ç†
    ç¡®ä¿åœ¨AKShareå†…éƒ¨è°ƒç”¨æ—¶ä¹Ÿç”Ÿæ•ˆ
    """
    try:
        import requests
        import urllib3
        
        # ç¦ç”¨urllib3è­¦å‘Š
        urllib3.disable_warnings()
        
        # ä¿å­˜åŸå§‹æ–¹æ³•
        original_request = requests.Session.request
        original_get = requests.get
        original_post = requests.post
        original_init = requests.Session.__init__
        
        # åŒ…è£…requestæ–¹æ³•
        def no_proxy_request(self, method, url, **kwargs):
            kwargs['proxies'] = {'http': None, 'https': None}
            kwargs['verify'] = False  # ç¦ç”¨SSLéªŒè¯ï¼ˆæŸäº›æƒ…å†µä¸‹éœ€è¦ï¼‰
            if 'headers' not in kwargs or kwargs['headers'] is None:
                kwargs['headers'] = {}
            headers = kwargs['headers']
            if 'User-Agent' not in headers:
                headers['User-Agent'] = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            if 'timeout' not in kwargs:
                kwargs['timeout'] = (10, 120)
            return original_request(self, method, url, **kwargs)
        
        # åŒ…è£…get/postæ–¹æ³•
        def no_proxy_get(url, **kwargs):
            kwargs['proxies'] = {'http': None, 'https': None}
            kwargs['verify'] = False
            return original_get(url, **kwargs)
        
        def no_proxy_post(url, **kwargs):
            kwargs['proxies'] = {'http': None, 'https': None}
            kwargs['verify'] = False
            return original_post(url, **kwargs)
        
        # ä¿®æ”¹Sessionåˆå§‹åŒ–
        def new_init(self, *args, **kwargs):
            original_init(self, *args, **kwargs)
            self.trust_env = False
            self.proxies = {'http': None, 'https': None}
            self.verify = False
        
        # åº”ç”¨ä¿®æ”¹
        requests.Session.request = no_proxy_request
        requests.get = no_proxy_get
        requests.post = no_proxy_post
        requests.Session.__init__ = new_init
        
        # ä¿®æ”¹requestsæ¨¡å—çº§åˆ«çš„é…ç½®
        requests.packages.urllib3.disable_warnings()
        
        print("  âœ… ä»£ç†å·²å½»åº•ç¦ç”¨")
        return True
    except Exception as e:
        print(f"  âš ï¸ è®¾ç½®æ— ä»£ç†æ¨¡å¼å¤±è´¥: {e}")
        return False


def fetch_stock_data_complete():
    """
    è·å–å®Œæ•´çš„Aè‚¡æ•°æ®ï¼ˆåŒ…å«PEã€PBç­‰è´¢åŠ¡æŒ‡æ ‡ï¼‰
    å‚è€ƒç”¨æˆ·æä¾›çš„æ–¹æ¡ˆ
    """
    print("ğŸ“¥ å¼€å§‹è·å–Aè‚¡å®Œæ•´æ•°æ®...")
    
    # è®¾ç½®æ— ä»£ç†æ¨¡å¼
    setup_no_proxy_requests()
    
    try:
        import akshare as ak
    except ImportError:
        print("âŒ AKShareæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install akshare")
        return pd.DataFrame()
    
    # æ­¥éª¤1: è·å–Aè‚¡åŸºç¡€ä¿¡æ¯ï¼ˆä»£ç ã€åç§°ï¼‰
    print("\n1ï¸âƒ£ è·å–Aè‚¡è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
    try:
        stock_info = retry_call(
            lambda: ak.stock_info_a_code_name(),
            retries=6,
            backoff=1.5,
            func_name="stock_info_a_code_name"
        )
        print(f"  âœ… è·å–åˆ° {len(stock_info)} åªè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
        
        # æ£€æŸ¥åˆ—å
        print(f"  ğŸ“‹ åŸºç¡€ä¿¡æ¯åˆ—å: {list(stock_info.columns)}")
    except Exception as e:
        print(f"  âŒ è·å–åŸºç¡€ä¿¡æ¯å¤±è´¥: {e}")
        return pd.DataFrame()
    
    # ç­‰å¾…3ç§’ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
    print("  â³ ç­‰å¾…3ç§’åè·å–å®æ—¶è¡Œæƒ…æ•°æ®...")
    time.sleep(3)
    
    # æ­¥éª¤2: è·å–Aè‚¡å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆåŒ…å«å¸‚ç›ˆç‡ã€PBã€PSç­‰ï¼‰
    print("\n2ï¸âƒ£ è·å–Aè‚¡å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆåŒ…å«PEã€PBã€PSç­‰è´¢åŠ¡æŒ‡æ ‡ï¼‰...")
    print("  âš ï¸  æ³¨æ„ï¼šæ­¤æ¥å£éœ€è¦è·å–æ‰€æœ‰Aè‚¡å®æ—¶æ•°æ®ï¼ˆ5000+åªï¼‰ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´...")
    print("  ğŸ”§ ç¡®ä¿ä»£ç†å·²ç¦ç”¨...")
    
    # å†æ¬¡ç¡®ä¿ä»£ç†ç¦ç”¨ï¼ˆåœ¨AKShareè°ƒç”¨å‰ï¼‰
    setup_no_proxy_requests()
    
    stock_fundamentals = None
    max_retries = 8  # å¢åŠ é‡è¯•æ¬¡æ•°
    retry_success = False
    
    for attempt in range(max_retries):
        try:
            print(f"  ğŸ”„ å°è¯• {attempt + 1}/{max_retries}...")
            stock_fundamentals = ak.stock_zh_a_spot_em()
            
            if stock_fundamentals is not None and not stock_fundamentals.empty:
                retry_success = True
                print(f"  âœ… è·å–åˆ° {len(stock_fundamentals)} æ¡å®æ—¶è¡Œæƒ…æ•°æ®")
                print(f"  ğŸ“‹ å®æ—¶è¡Œæƒ…åˆ—å ({len(stock_fundamentals.columns)}ä¸ª):")
                for i, col in enumerate(stock_fundamentals.columns[:30], 1):
                    print(f"      {i:2d}. {col}")
                
                # æŸ¥æ‰¾åŒ…å«PEã€PBçš„åˆ—
                pe_pb_cols = [col for col in stock_fundamentals.columns 
                             if 'pe' in col.lower() or 'pb' in col.lower() or 'å¸‚ç›ˆ' in col or 'å¸‚å‡€' in col]
                print(f"\n  ğŸ¯ åŒ…å«PE/PBç›¸å…³çš„åˆ—: {pe_pb_cols}")
                
                # æ˜¾ç¤ºå‰2è¡Œæ•°æ®ç¤ºä¾‹
                if len(stock_fundamentals) > 0:
                    print(f"\n  ğŸ“Š å‰2è¡Œæ•°æ®ç¤ºä¾‹ï¼ˆå…³é”®åˆ—ï¼‰:")
                    key_cols = ['ä»£ç ', 'åç§°', 'æœ€æ–°ä»·', 'æ€»å¸‚å€¼', 'æµé€šå¸‚å€¼', 'å¸‚ç›ˆç‡-åŠ¨æ€', 'å¸‚å‡€ç‡']
                    available_key_cols = [col for col in key_cols if col in stock_fundamentals.columns]
                    if available_key_cols:
                        print(stock_fundamentals[available_key_cols].head(2).to_string())
                
                break  # æˆåŠŸè·å–ï¼Œé€€å‡ºå¾ªç¯
        except Exception as e:
            error_msg = str(e).lower()
            if attempt < max_retries - 1:
                wait_time = 2.0 * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                print(f"  âš ï¸  ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {str(e)[:100]}")
                print(f"  ğŸ’¤ ç­‰å¾… {wait_time:.1f} ç§’åé‡è¯•...")
                
                # å¦‚æœæ˜¯å› ä¸ºä»£ç†é—®é¢˜ï¼Œé‡æ–°è®¾ç½®ä»£ç†ç¦ç”¨
                if 'proxy' in error_msg:
                    print(f"  ğŸ”§ æ£€æµ‹åˆ°ä»£ç†é—®é¢˜ï¼Œé‡æ–°ç¦ç”¨ä»£ç†...")
                    setup_no_proxy_requests()
                
                time.sleep(wait_time)
            else:
                print(f"  âŒ æ‰€æœ‰ {max_retries} æ¬¡å°è¯•å‡å¤±è´¥")
                print(f"  ğŸ’¡ å°†åªä½¿ç”¨åŸºç¡€ä¿¡æ¯ï¼ˆä»£ç å’Œåç§°ï¼‰")
                stock_fundamentals = pd.DataFrame()
    
    if not retry_success:
        print(f"  âš ï¸  å®æ—¶è¡Œæƒ…æ¥å£å¤±è´¥ï¼Œå°†åªä½¿ç”¨åŸºç¡€ä¿¡æ¯")
        stock_fundamentals = pd.DataFrame()
    
    # æ­¥éª¤3: åˆå¹¶æ•°æ®
    print("\n3ï¸âƒ£ åˆå¹¶æ•°æ®...")
    
    # ç¡®å®šåˆå¹¶é”®
    if 'code' in stock_info.columns:
        info_code_col = 'code'
    elif stock_info.columns[0] == 'code':
        info_code_col = 'code'
    else:
        info_code_col = stock_info.columns[0]  # ä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºä»£ç 
    
    if not stock_fundamentals.empty and 'ä»£ç ' in stock_fundamentals.columns:
        # åˆå¹¶æ•°æ®
        df = stock_info.merge(
            stock_fundamentals,
            left_on=info_code_col,
            right_on='ä»£ç ',
            how='left'
        )
        print(f"  âœ… åˆå¹¶å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
    else:
        # é™çº§æ–¹æ¡ˆï¼šåªä½¿ç”¨åŸºç¡€ä¿¡æ¯
        df = stock_info.copy()
        print(f"  âš ï¸  ä½¿ç”¨é™çº§æ–¹æ¡ˆï¼šä»…åŒ…å«è‚¡ç¥¨ä»£ç å’Œåç§°")
    
    # æ­¥éª¤4: å­—æ®µæ˜ å°„å’Œæ¸…æ´—
    print("\n4ï¸âƒ£ å­—æ®µæ˜ å°„å’Œæ¸…æ´—...")
    
    # å®šä¹‰åˆ—åæ˜ å°„ï¼ˆå‚è€ƒa_share_downloader.pyçš„å®é™…åˆ—åï¼‰
    column_mapping = {}
    available_columns = df.columns.tolist()
    
    # ä»£ç å’Œåç§°
    if info_code_col in available_columns:
        column_mapping[info_code_col] = 'stock_code'
    if 'ä»£ç ' in available_columns:
        column_mapping['ä»£ç '] = 'stock_code'
    if 'name' in available_columns:
        column_mapping['name'] = 'stock_name'
    if 'åç§°' in available_columns:
        column_mapping['åç§°'] = 'stock_name'
    
    # è´¢åŠ¡æŒ‡æ ‡æ˜ å°„
    mapping_candidates = {
        "price": ["æœ€æ–°ä»·", "ç°ä»·", "close"],
        "market_cap": ["æ€»å¸‚å€¼", "æ€»å¸‚å€¼(å…ƒ)", "market_cap"],
        "float_cap": ["æµé€šå¸‚å€¼", "æµé€šå¸‚å€¼(å…ƒ)", "float_cap", "circ_mv"],
        "pe": ["å¸‚ç›ˆç‡-åŠ¨æ€", "å¸‚ç›ˆç‡", "PE", "åŠ¨æ€å¸‚ç›ˆç‡", "pe"],
        "pb": ["å¸‚å‡€ç‡", "PB", "pb"],
        "ps": ["å¸‚é”€ç‡", "PS", "ps"],
        "pcf": ["å¸‚ç°ç‡", "PCF", "pcf"],
        "change_pct": ["æ¶¨è·Œå¹…", "æ¶¨è·Œ%", "pct_chg"],
        "volume": ["æˆäº¤é‡", "volume"],
        "turnover": ["æˆäº¤é¢", "amount", "turnover"],
    }
    
    # åŒ¹é…åˆ—å
    for new_col, candidates in mapping_candidates.items():
        for candidate in candidates:
            if candidate in available_columns and candidate not in column_mapping:
                column_mapping[candidate] = new_col
                break
    
    # æ‰§è¡Œé‡å‘½å
    df = df.rename(columns=column_mapping)
    
    # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
    required_columns = {
        'stock_code': None,
        'stock_name': None,
        'price': None,
        'market_cap': None,
        'float_cap': None,
        'pe': None,
        'pb': None,
        'ps': None,
        'pcf': None,
        'change_pct': None,
        'volume': None,
        'turnover': None,
    }
    
    for col in required_columns:
        if col not in df.columns:
            df[col] = None
            print(f"  âš ï¸  æ·»åŠ ç©ºåˆ—: {col}ï¼ˆæ•°æ®æºä¸­ä¸å­˜åœ¨ï¼‰")
    
    # åªä¿ç•™éœ€è¦çš„åˆ—
    df = df[[col for col in required_columns.keys() if col in df.columns]]
    
    # æ­¥éª¤5: æ•°æ®æ¸…æ´—å’Œç±»å‹è½¬æ¢
    print("\n5ï¸âƒ£ æ•°æ®æ¸…æ´—å’Œç±»å‹è½¬æ¢...")
    
    # åˆ é™¤é‡å¤å’Œç©ºè®°å½•
    df = df.dropna(subset=['stock_code', 'stock_name']).drop_duplicates(subset=['stock_code'])
    
    # æ•°å€¼åˆ—è½¬æ¢
    numeric_columns = ['price', 'market_cap', 'float_cap', 'pe', 'pb', 'ps', 'pcf', 
                      'change_pct', 'volume', 'turnover']
    
    for col in numeric_columns:
        if col in df.columns:
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œæ¸…ç†å•ä½
            if df[col].dtype == 'object':
                df[col] = (df[col].astype(str)
                          .str.replace('å…ƒ', '')
                          .str.replace('ä¸‡', '')
                          .str.replace(',', '')
                          .str.replace(' ', '')
                          .str.replace('--', '')
                          .str.replace('-', ''))
            # è½¬æ¢ä¸ºæ•°å€¼
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # æ·»åŠ æ›´æ–°æ—¶é—´
    df['update_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # æ­¥éª¤6: æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
    print("\n6ï¸âƒ£ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ï¼š")
    for col in ['pe', 'pb', 'market_cap', 'price']:
        if col in df.columns:
            non_null_count = df[col].notna().sum()
            total_count = len(df)
            coverage = (non_null_count / total_count * 100) if total_count > 0 else 0
            print(f"     - {col}: {non_null_count}/{total_count} æ¡æœ‰æ•°æ® ({coverage:.1f}%)")
    
    print(f"\n  âœ… æ•°æ®æ¸…æ´—å®Œæˆï¼Œå…± {len(df)} æ¡æœ‰æ•ˆè®°å½•")
    return df


def save_to_database(df: pd.DataFrame):
    """
    å°†æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“
    å‚è€ƒç”¨æˆ·æä¾›çš„æ–¹æ¡ˆï¼ˆä½¿ç”¨SQLAlchemyæˆ–ç›´æ¥ä½¿ç”¨pandasï¼‰
    """
    if df.empty:
        print("  âš ï¸  æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜")
        return
    
    print("\nğŸ’¾ ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“...")
    
    try:
        conn = sqlite3.connect(str(DB_PATH))
        
        # ä½¿ç”¨pandasç›´æ¥ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå‚è€ƒç”¨æˆ·æ–¹æ¡ˆï¼‰
        df.to_sql('stock_data', conn, if_exists='replace', index=False)
        
        conn.commit()
        conn.close()
        
        print(f"  âœ… æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“: {len(df)} æ¡è®°å½•")
        print(f"  ğŸ“ æ•°æ®åº“è·¯å¾„: {DB_PATH}")
        
    except Exception as e:
        print(f"  âŒ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        raise


def save_to_csv(df: pd.DataFrame):
    """åŒæ—¶ä¿å­˜åˆ°CSVæ–‡ä»¶ä½œä¸ºå¤‡ä»½"""
    if df.empty:
        return
    
    try:
        df.to_csv(CSV_PATH, index=False, encoding='utf-8-sig')
        print(f"  âœ… æ•°æ®å·²ä¿å­˜åˆ°CSV: {CSV_PATH}")
    except Exception as e:
        print(f"  âš ï¸  ä¿å­˜åˆ°CSVå¤±è´¥: {e}")


if __name__ == "__main__":
    try:
        print("=" * 60)
        print("ğŸš€ Aè‚¡åŸºç¡€æ•°æ®å®Œæ•´ä¸‹è½½è„šæœ¬")
        print("=" * 60)
        
        # åˆå§‹åŒ–æ•°æ®åº“
        init_database()
        
        # è·å–å®Œæ•´æ•°æ®
        df = fetch_stock_data_complete()
        
        if df.empty:
            print("\nâŒ æœªè·å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œæ•°æ®æº")
            sys.exit(1)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        save_to_database(df)
        
        # ä¿å­˜åˆ°CSV
        save_to_csv(df)
        
        print("\n" + "=" * 60)
        print("âœ…âœ…âœ… æ•°æ®ä¸‹è½½å®Œæˆï¼")
        print("=" * 60)
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼š")
        print(f"   - æ€»è®°å½•æ•°: {len(df)}")
        print(f"   - æ•°æ®åº“è·¯å¾„: {DB_PATH}")
        print(f"   - CSVå¤‡ä»½è·¯å¾„: {CSV_PATH}")
        print("\nğŸ’¡ æç¤ºï¼šæ•°æ®å·²ä¿å­˜ï¼Œå¯ä»¥åœ¨Webç•Œé¢ä¸­æŸ¥çœ‹")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

