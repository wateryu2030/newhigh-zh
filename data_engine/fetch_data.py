"""
BaoStockæ•°æ®ä¸‹è½½æ¨¡å—
åªä½¿ç”¨BaoStockä½œä¸ºå”¯ä¸€æ•°æ®æºï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§
"""
import os
import sys
import time
from datetime import datetime, timedelta
import pandas as pd
from pathlib import Path

# Add data_engine directory to path for imports
data_engine_dir = Path(__file__).parent
sys.path.insert(0, str(data_engine_dir))

from utils.logger import setup_logger
from utils.retry import retry
from utils.db_utils import get_engine, upsert_df

from config import DB_URL, START_DATE, END_DATE, SLEEP_SEC_WEB

import baostock as bs

logger = setup_logger(log_file=os.path.join(os.path.dirname(__file__), "data_cache/update.log"))
engine = get_engine(DB_URL)


# ------------------ åŸºç¡€ä¿¡æ¯ ------------------
@retry(tries=5, delay=1.0)
def fetch_stock_basic_info():
    """è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼Œåªä¿ç•™type=1çš„è‚¡ç¥¨ï¼Œæ’é™¤æŒ‡æ•°"""
    logger.info("å¼€å§‹è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯...")
    lg = bs.login()
    if lg.error_code != '0':
        raise RuntimeError(f"baostock ç™»å½•å¤±è´¥: {lg.error_msg}")
    
    rs = bs.query_stock_basic()
    rows = []
    while rs.error_code == '0' and rs.next():
        rows.append(rs.get_row_data())
    
    if not rows:
        bs.logout()
        raise RuntimeError("æœªè·å–åˆ°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯")
    
    df = pd.DataFrame(rows, columns=rs.fields)
    bs.logout()
    
    # è¿‡æ»¤ï¼šåªä¿ç•™è‚¡ç¥¨ï¼ˆtype=1ï¼‰ï¼Œæ’é™¤æŒ‡æ•°ï¼ˆtype=2ï¼‰
    if 'type' in df.columns:
        df = df[df['type'] == '1']
        logger.info(f"è¿‡æ»¤åå‰©ä½™è‚¡ç¥¨: {len(df)} åªï¼ˆæ’é™¤äº†æŒ‡æ•°ï¼‰")
    
    # baostockçš„codeè½¬ts_codeé£æ ¼
    def to_ts(code):
        p = str(code).split('.')
        return (p[1] + ('.SH' if p[0]=='sh' else '.SZ')) if len(p)==2 else code
    
    df['ts_code'] = df['code'].map(to_ts)
    
    # å­—æ®µæ˜ å°„
    column_mapping = {
        'code_name': 'name',
        'ipoDate': 'list_date',
        'outDate': 'delist_date'
    }
    df = df.rename(columns=column_mapping)
    
    # åˆ é™¤ä¸éœ€è¦çš„åˆ—
    for col in ['code', 'type', 'status']:
        if col in df.columns:
            df = df.drop(columns=[col])
    
    # æ·»åŠ ç¼ºå¤±åˆ—
    for col in ['symbol', 'area', 'industry', 'market', 'is_hs']:
        if col not in df.columns:
            df[col] = None
    
    # ç¡®ä¿åˆ—é¡ºåº
    expected_fields = ['ts_code', 'symbol', 'name', 'area', 'industry', 'market', 'list_date', 'delist_date', 'is_hs']
    for field in expected_fields:
        if field not in df.columns:
            df[field] = None
    df = df[expected_fields]
    
    df = df.drop_duplicates(subset=['ts_code'])
    # ä½¿ç”¨upserté€»è¾‘ï¼Œæ”¯æŒå¢é‡æ›´æ–°
    upsert_df(df, "stock_basic_info", engine, if_exists="append")
    logger.info(f"stock_basic_info å†™å…¥ {len(df)} æ¡")
    return df[['ts_code']].dropna()


# ------------------ æ—¥è¡Œæƒ…ï¼ˆKçº¿+è´¢åŠ¡æŒ‡æ ‡ï¼‰ ------------------
@retry(tries=5, delay=1.0)
def fetch_market_daily(ts_codes: pd.Series):
    """è·å–æ—¥Kçº¿æ•°æ®ï¼ŒåŒ…å«PE/PB/PSç­‰è´¢åŠ¡æŒ‡æ ‡"""
    logger.info(f"å¼€å§‹ä¸‹è½½æ—¥Kè¡Œæƒ…æ•°æ®ï¼Œå…±{len(ts_codes)}åªè‚¡ç¥¨")
    lg = bs.login()
    if lg.error_code != '0':
        raise RuntimeError(f"baostock ç™»å½•å¤±è´¥: {lg.error_msg}")
    
    # BaoStockæ ‡å‡†å­—æ®µåˆ—è¡¨
    fields = "date,code,open,high,low,close,preclose,volume,amount,turn,pctChg,peTTM,pbMRQ,psTTM"
    
    total = 0
    for i, row in ts_codes.reset_index(drop=True).iterrows():
        ts_code = row['ts_code']
        # è½¬baostockä»£ç é£æ ¼
        if ts_code.endswith(".SH"):
            code = "sh." + ts_code.split('.')[0]
        else:
            code = "sz." + ts_code.split('.')[0]
        
        # è·å–Kçº¿æ•°æ®å’Œè´¢åŠ¡æŒ‡æ ‡
        rs = bs.query_history_k_data_plus(
            code,
            fields,
            start_date=START_DATE,
            end_date=END_DATE,
            frequency="d",
            adjustflag="3"
        )
        
        rows = []
        while rs.error_code == '0' and rs.next():
            rows.append(rs.get_row_data())
        
        if rows:
            df = pd.DataFrame(rows, columns=rs.fields)
            # æ ‡å‡†åˆ—åæ˜ å°„
            df.rename(columns={
                "date": "trade_date",
                "pctChg": "pct_chg",
                "turn": "turnover_rate"
            }, inplace=True)
            df["ts_code"] = ts_code
            
            # åˆ é™¤codeåˆ—
            if 'code' in df.columns:
                df = df.drop(columns=['code'])
            
            # ç¡®ä¿æ‰€æœ‰æ•°å€¼åˆ—ä¸ºæ•°å€¼ç±»å‹
            numeric_cols = ['open', 'high', 'low', 'close', 'preclose', 'pct_chg', 'volume', 
                          'amount', 'turnover_rate', 'peTTM', 'pbMRQ', 'psTTM']
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # è®¡ç®—æŒ¯å¹…
            df['amplitude'] = ((df['high'] - df['low']) / df['preclose'] * 100).round(2)
            
            # ç¡®ä¿åˆ—é¡ºåºï¼ˆåŒ¹é…æ•°æ®åº“ï¼‰
            expected_fields = ['ts_code', 'trade_date', 'open', 'high', 'low', 'close', 'preclose',
                             'pct_chg', 'volume', 'amount', 'turnover_rate', 'amplitude', 
                             'peTTM', 'pbMRQ', 'psTTM']
            for field in expected_fields:
                if field not in df.columns:
                    df[field] = None
            df = df[expected_fields]
            
            upsert_df(df, "stock_market_daily", engine, if_exists="append")
            total += len(df)
            
            # åŒæ—¶å°†PE/PB/PSæ•°æ®å†™å…¥è´¢åŠ¡è¡¨
            if 'peTTM' in df.columns or 'pbMRQ' in df.columns:
                df_fin = df[['ts_code', 'trade_date']].copy()
                if 'peTTM' in df.columns:
                    df_fin['pe'] = df['peTTM']
                if 'pbMRQ' in df.columns:
                    df_fin['pb'] = df['pbMRQ']
                if 'psTTM' in df.columns:
                    df_fin['ps'] = df['psTTM']
                
                # è¡¥å……å…¶ä»–å­—æ®µ
                for col in ['pcf', 'roe', 'roa', 'eps', 'bps', 'total_mv', 'circ_mv', 
                          'revenue_yoy', 'net_profit_yoy', 'gross_profit_margin']:
                    df_fin[col] = None
                
                df_fin = df_fin.dropna(subset=['pe', 'pb'], how='all')
                if not df_fin.empty:
                    upsert_df(df_fin, "stock_financials", engine, if_exists="append")
        else:
            logger.warning(f"  âš ï¸ {ts_code} æ— æ•°æ®")
        
        if (i+1) % 20 == 0:
            logger.info(f"æ—¥Kè¿›åº¦ {i+1}/{len(ts_codes)}")
        
        time.sleep(SLEEP_SEC_WEB)
    
    bs.logout()
    logger.info(f"stock_market_daily å…±å†™å…¥ {total} è¡Œ")
    return total


def main():
    """ä¸»å‡½æ•°ï¼šä¸‹è½½æ‰€æœ‰æ•°æ®"""
    logger.info("ğŸš€ å¼€å§‹æ›´æ–° Aè‚¡æ™ºèƒ½é€‰è‚¡åŸºç¡€æ•°æ®åº“")
    logger.info(f"æŠ“å–çª—å£: {START_DATE} ~ {END_DATE}")
    
    # 1. è·å–åŸºç¡€ä¿¡æ¯ï¼ˆé™æ€æ•°æ®ï¼Œå…¨é‡æ›´æ–°ï¼‰
    codes_df = fetch_stock_basic_info()
    
    # 2. ä¸‹è½½æ—¥Kè¡Œæƒ…ï¼ˆå¢é‡æ›´æ–°ï¼Œæ”¯æŒå¤šæ¬¡è¿è¡Œï¼‰
    # BATCH_SIZE=400è¡¨ç¤ºé™åˆ¶400åªï¼Œè®¾ç½®ä¸ºnone/fullè¡¨ç¤ºå…¨é‡
    batch_size = os.getenv("BATCH_SIZE", "400")
    if batch_size and batch_size.lower() not in ["none", "null", "full"]:
        try:
            limit = int(batch_size)
            head_codes = codes_df.head(limit)
            logger.info(f"é™åˆ¶æ‰¹é‡å¤§å°: {limit}åªè‚¡ç¥¨")
        except ValueError:
            logger.warning(f"BATCH_SIZEå€¼æ— æ•ˆ: {batch_size}ï¼Œä½¿ç”¨é»˜è®¤400")
            head_codes = codes_df.head(400)
    else:
        head_codes = codes_df
        logger.info(f"å…¨é‡ä¸‹è½½æ‰€æœ‰è‚¡ç¥¨æ—¥Kæ•°æ®ï¼ˆå…±{len(codes_df)}åªï¼‰")
    
    fetch_market_daily(head_codes)
    
    logger.info("âœ… å…¨éƒ¨å®Œæˆ")


if __name__ == "__main__":
    main()
