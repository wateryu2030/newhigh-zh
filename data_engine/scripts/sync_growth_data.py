#!/usr/bin/env python3
"""Incremental sync tool for stock_financials_growth data."""
from __future__ import annotations

import argparse
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Iterable, List

import pandas as pd
from sqlalchemy import text

PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PROJECT_ROOT / ".."))

from config import DB_URL  # noqa: E402
from utils.db_utils import get_engine  # noqa: E402
from fetch_extended_data import fetch_growth_data  # noqa: E402

DEFAULT_LIMIT = 50


def current_year() -> int:
    return datetime.now().year


def compute_min_year(freshness_years: int) -> int:
    year = current_year() - max(freshness_years - 1, 0)
    return max(2005, year)  # BaoStock earliest year


def fetch_missing_codes(engine, min_year: int, limit: int, offset: int = 0) -> List[str]:
    query = f"""
        WITH latest AS (
            SELECT ts_code, MAX(year) AS max_year
            FROM stock_financials_growth
            GROUP BY ts_code
        )
        SELECT b.ts_code
        FROM vw_stock_basic_info_unique b
        LEFT JOIN latest lg ON b.ts_code = lg.ts_code
        WHERE lg.max_year IS NULL OR lg.max_year < :min_year
        ORDER BY b.ts_code
        LIMIT {limit} OFFSET {offset}
    """
    with engine.connect() as conn:
        rows = conn.execute(text(query), {"min_year": min_year}).fetchall()
    return [row[0] for row in rows]


def count_pending(engine, min_year: int) -> int:
    with engine.connect() as conn:
        total = conn.execute(
            text(
                """
                WITH latest AS (
                    SELECT ts_code, MAX(year) AS max_year
                    FROM stock_financials_growth
                    GROUP BY ts_code
                )
                SELECT COUNT(*)
                FROM vw_stock_basic_info_unique b
                LEFT JOIN latest lg ON b.ts_code = lg.ts_code
                WHERE lg.max_year IS NULL OR lg.max_year < :min_year
                """
            ),
            {"min_year": min_year},
        ).scalar()
    return int(total or 0)


def run_batch(engine, codes: Iterable[str]) -> int:
    codes = list(dict.fromkeys(codes))
    if not codes:
        return 0
    series = pd.Series(codes, name="ts_code")
    fetch_growth_data(series)
    return len(codes)


def parse_args():
    parser = argparse.ArgumentParser(description="Incremental growth-data synchronizer")
    parser.add_argument("--limit", type=int, default=DEFAULT_LIMIT, help="Max stocks per batch")
    parser.add_argument("--offset", type=int, default=0, help="Offset inside pending list")
    parser.add_argument(
        "--freshness-years",
        type=int,
        default=1,
        help="Require latest growth data to be within this number of years",
    )
    parser.add_argument("--loop", action="store_true", help="Process continuously until queue exhausted")
    parser.add_argument("--sleep", type=int, default=60, help="Delay between loop iterations (seconds)")
    parser.add_argument(
        "--codes",
        nargs="*",
        help="Optional explicit ts_code list (skip DB scan)",
    )
    parser.add_argument(
        "--codes-file",
        type=Path,
        help="Path to text file containing ts_codes (one per line) to process",
    )
    return parser.parse_args()


def load_codes_from_file(path: Path) -> List[str]:
    if not path.exists():
        raise FileNotFoundError(path)
    return [line.strip() for line in path.read_text().splitlines() if line.strip()]


def main():
    args = parse_args()
    engine = get_engine(DB_URL)

    if args.codes or args.codes_file:
        codes: List[str] = []
        if args.codes:
            codes.extend(args.codes)
        if args.codes_file:
            codes.extend(load_codes_from_file(args.codes_file))
        codes = list(dict.fromkeys([code.strip().upper() for code in codes if code.strip()]))
        if not codes:
            print("âœ… æ²¡æœ‰æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç å¯å¤„ç†")
            return
        print(f"ğŸš€ æ‰‹åŠ¨åŒæ­¥ {len(codes)} æ”¯è‚¡ç¥¨ï¼š{codes[:5]}{'...' if len(codes) > 5 else ''}")
        run_batch(engine, codes)
        print("âœ… æ‰‹åŠ¨åŒæ­¥å®Œæˆ")
        return

    min_year = compute_min_year(args.freshness_years)
    loop = args.loop
    iteration = 0

    while True:
        pending_total = count_pending(engine, min_year)
        if pending_total == 0:
            print("ğŸ‰ æˆé•¿æ•°æ®å·²æ»¡è¶³æŒ‡å®šçš„æ—¶é—´èŒƒå›´ï¼Œæ— éœ€åŒæ­¥")
            break

        print(
            f"ğŸ“ å¾…åŒæ­¥è‚¡ç¥¨ï¼š{pending_total} æ”¯ï¼ˆéœ€è¦è‡³å°‘ {min_year} å¹´çš„æ•°æ®ï¼‰"
        )
        codes = fetch_missing_codes(engine, min_year, args.limit, args.offset)
        if not codes:
            print("âœ… å½“å‰æ‰¹æ¬¡æ²¡æœ‰å¯åŒæ­¥çš„è‚¡ç¥¨")
            break

        iteration += 1
        print(
            f"ğŸš€ ç¬¬ {iteration} æ‰¹ï¼ˆ{len(codes)} æ”¯ï¼‰ï¼š"
            f"{', '.join(codes[:min(5, len(codes))])}{'...' if len(codes) > 5 else ''}"
        )
        start = time.time()
        try:
            run_batch(engine, codes)
        except Exception as exc:
            print(f"âŒ åŒæ­¥å¤±è´¥: {exc}")
        else:
            elapsed = time.time() - start
            print(f"âœ… æ‰¹æ¬¡å®Œæˆï¼Œç”¨æ—¶ {elapsed:.1f} ç§’")

        if not loop:
            break

        print(f"â±ï¸ {args.sleep} ç§’åå¤„ç†ä¸‹ä¸€æ‰¹...")
        time.sleep(max(args.sleep, 1))

    print("ğŸ åŒæ­¥æµç¨‹ç»“æŸ")


if __name__ == "__main__":
    main()
